{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ici j'ai:\n",
    "# 1)continué mon analyse descriptive\n",
    "# 2)fait feature engineering pour les categories avec le pire score (funny,conpiracy,AskReddit)\n",
    "# 3) feature engineering general pour toutest les categories avec chiffres, http ou .gif .jpg dans le commentaries\n",
    "# 4) testes avec LienarSVC\n",
    "# 5) dummy search pour les hyperparametres avec scikit-optimizer\n",
    "# 6) Baysean search pour les hyperparametres avec scikit-optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wc_df = pd.read_csv('train.csv') \n",
    "comment_data =wc_df\n",
    "\n",
    "comment_data['prep'] = comment_data['comment'].str.replace(r'[^\\w\\s]+', '') # tira td que nao palavra e espaco em branco\n",
    "comment_data['prep'] = comment_data['prep'].str.lower()\n",
    "comment_data['prep'] = comment_data['prep'].str.replace('(\\d+)', ' num ')\n",
    "#comment_data['prep'] = comment_data['prep'].str.replace(r'http(?<=http).*', ' ')\n",
    "comment_data['prep'] = comment_data['prep'].str.replace(r'\\s+', \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# natural language toolkit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tag import pos_tag_sents\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tt = TweetTokenizer()\n",
    "def lemmatize_col(row):\n",
    "    row = tt.tokenize(row)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in row])\n",
    "\n",
    "comment_data['prep'] = comment_data['prep'].apply(lemmatize_col)\n",
    "#test_data['prep'] = test_data['prep'].apply(lemmatize_col) \n",
    "\n",
    "# stopwords\n",
    "stop = stopwords.words('english')\n",
    "comment_data['prep'] = comment_data['prep'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "#test_data['prep'] = test_data['prep'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I think prestige points should not expire ever...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>think prestige point expire ever skin buy avai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Whats going to happen with them if they will b...</td>\n",
       "      <td>europe</td>\n",
       "      <td>whats going happen refused asilum appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Anecdotal evidence is anecdotal. Clearly by “e...</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>anecdotal evidence anecdotal clearly everyone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Look dude, with all due respect, your music is...</td>\n",
       "      <td>Music</td>\n",
       "      <td>look dude due respect music isnt people look l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hope he gets the doomhammer back!</td>\n",
       "      <td>wow</td>\n",
       "      <td>hope get doomhammer back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment        subreddit  \\\n",
       "0   0  I think prestige points should not expire ever...  leagueoflegends   \n",
       "1   1  Whats going to happen with them if they will b...           europe   \n",
       "2   2  Anecdotal evidence is anecdotal. Clearly by “e...    gameofthrones   \n",
       "3   3  Look dude, with all due respect, your music is...            Music   \n",
       "4   4                  Hope he gets the doomhammer back!              wow   \n",
       "\n",
       "                                                prep  \n",
       "0  think prestige point expire ever skin buy avai...  \n",
       "1           whats going happen refused asilum appeal  \n",
       "2  anecdotal evidence anecdotal clearly everyone ...  \n",
       "3  look dude due respect music isnt people look l...  \n",
       "4                           hope get doomhammer back  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  comment  prep\n",
       "subreddit                   \n",
       "nba         3        3     3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imur=wc_df.loc[wc_df['comment'].str.contains('imur')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "imur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  comment  prep\n",
       "subreddit                         \n",
       "gameofthrones    25       25    25\n",
       "conspiracy       21       21    21\n",
       "europe           21       21    21\n",
       "trees            19       19    19\n",
       "movies           19       19    19\n",
       "funny            18       18    18\n",
       "AskReddit        12       12    12\n",
       "canada           12       12    12\n",
       "worldnews        11       11    11\n",
       "anime            10       10    10\n",
       "wow              10       10    10\n",
       "Music             9        9     9\n",
       "hockey            6        6     6\n",
       "baseball          4        4     4\n",
       "GlobalOffensive   4        4     4\n",
       "Overwatch         4        4     4\n",
       "nfl               4        4     4\n",
       "soccer            2        2     2\n",
       "leagueoflegends   1        1     1\n",
       "nba               1        1     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "picture=wc_df.loc[wc_df['comment'].str.contains('picture')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "picture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  comment  prep\n",
       "subreddit                         \n",
       "anime            22       22    22\n",
       "gameofthrones    19       19    19\n",
       "wow              14       14    14\n",
       "conspiracy       13       13    13\n",
       "Overwatch        12       12    12\n",
       "GlobalOffensive  12       12    12\n",
       "leagueoflegends  12       12    12\n",
       "europe           11       11    11\n",
       "baseball         10       10    10\n",
       "nfl               9        9     9\n",
       "soccer            9        9     9\n",
       "movies            7        7     7\n",
       "Music             6        6     6\n",
       "AskReddit         5        5     5\n",
       "canada            4        4     4\n",
       "nba               4        4     4\n",
       "trees             3        3     3\n",
       "worldnews         3        3     3\n",
       "hockey            1        1     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "meme=wc_df.loc[wc_df['comment'].str.contains('meme')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "meme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  comment  prep\n",
       "subreddit                          \n",
       "nba              106      106   106\n",
       "trees             90       90    90\n",
       "GlobalOffensive   83       83    83\n",
       "leagueoflegends   71       71    71\n",
       "nfl               67       67    67\n",
       "hockey            60       60    60\n",
       "Overwatch         53       53    53\n",
       "soccer            53       53    53\n",
       "anime             52       52    52\n",
       "wow               45       45    45\n",
       "gameofthrones     44       44    44\n",
       "baseball          42       42    42\n",
       "Music             39       39    39\n",
       "conspiracy        37       37    37\n",
       "worldnews         35       35    35\n",
       "movies            32       32    32\n",
       "funny             30       30    30\n",
       "canada            27       27    27\n",
       "AskReddit         25       25    25\n",
       "europe            18       18    18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lol=wc_df.loc[wc_df['comment'].str.contains('lol')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "lol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  comment  prep\n",
       "subreddit                         \n",
       "trees            38       38    38\n",
       "gameofthrones    16       16    16\n",
       "funny            14       14    14\n",
       "leagueoflegends  14       14    14\n",
       "hockey           13       13    13\n",
       "wow              13       13    13\n",
       "Music            13       13    13\n",
       "Overwatch        12       12    12\n",
       "soccer           12       12    12\n",
       "conspiracy       11       11    11\n",
       "GlobalOffensive  11       11    11\n",
       "anime            11       11    11\n",
       "baseball         10       10    10\n",
       "nba               9        9     9\n",
       "canada            8        8     8\n",
       "movies            8        8     8\n",
       "worldnews         8        8     8\n",
       "europe            7        7     7\n",
       "nfl               6        6     6\n",
       "AskReddit         5        5     5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rs=wc_df.loc[wc_df['comment'].str.contains('haha')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  comment  prep\n",
       "subreddit                          \n",
       "conspiracy       144      144   144\n",
       "worldnews        126      126   126\n",
       "anime            116      116   116\n",
       "europe           116      116   116\n",
       "Overwatch        112      112   112\n",
       "canada           112      112   112\n",
       "gameofthrones    107      107   107\n",
       "movies           106      106   106\n",
       "leagueoflegends  105      105   105\n",
       "GlobalOffensive  103      103   103\n",
       "wow              103      103   103\n",
       "AskReddit         84       84    84\n",
       "trees             58       58    58\n",
       "funny             56       56    56\n",
       "soccer            54       54    54\n",
       "nba               53       53    53\n",
       "nfl               52       52    52\n",
       "Music             50       50    50\n",
       "baseball          44       44    44\n",
       "hockey            36       36    36"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "why=wc_df.loc[wc_df['comment'].str.contains('why')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  comment  prep\n",
       "subreddit                          \n",
       "anime            389      389   389\n",
       "Music            205      205   205\n",
       "conspiracy       203      203   203\n",
       "europe           172      172   172\n",
       "worldnews        144      144   144\n",
       "canada           118      118   118\n",
       "wow              100      100   100\n",
       "GlobalOffensive   91       91    91\n",
       "funny             90       90    90\n",
       "movies            88       88    88\n",
       "hockey            77       77    77\n",
       "leagueoflegends   77       77    77\n",
       "Overwatch         74       74    74\n",
       "gameofthrones     65       65    65\n",
       "soccer            55       55    55\n",
       "baseball          55       55    55\n",
       "nba               49       49    49\n",
       "AskReddit         45       45    45\n",
       "trees             39       39    39\n",
       "nfl               36       36    36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "https=wc_df.loc[wc_df['comment'].str.contains('https')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "https"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "http=wc_df.loc[wc_df['comment'].str.contains('http')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  comment  prep\n",
       "subreddit                          \n",
       "anime            392      392   392\n",
       "conspiracy       216      216   216\n",
       "Music            205      205   205\n",
       "europe           183      183   183\n",
       "worldnews        152      152   152\n",
       "canada           130      130   130\n",
       "wow              103      103   103\n",
       "funny             99       99    99\n",
       "hockey            94       94    94\n",
       "GlobalOffensive   93       93    93\n",
       "movies            88       88    88\n",
       "leagueoflegends   77       77    77\n",
       "Overwatch         75       75    75\n",
       "gameofthrones     70       70    70\n",
       "baseball          59       59    59\n",
       "soccer            57       57    57\n",
       "nba               50       50    50\n",
       "AskReddit         49       49    49\n",
       "trees             41       41    41\n",
       "nfl               38       38    38"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "http"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif=wc_df.loc[wc_df['comment'].str.contains('gif')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  comment  prep\n",
       "subreddit                         \n",
       "anime            19       19    19\n",
       "funny            14       14    14\n",
       "hockey           10       10    10\n",
       "nfl              10       10    10\n",
       "leagueoflegends  10       10    10\n",
       "soccer            9        9     9\n",
       "wow               7        7     7\n",
       "europe            6        6     6\n",
       "Music             5        5     5\n",
       "worldnews         4        4     4\n",
       "AskReddit         4        4     4\n",
       "GlobalOffensive   4        4     4\n",
       "baseball          4        4     4\n",
       "nba               3        3     3\n",
       "canada            3        3     3\n",
       "Overwatch         3        3     3\n",
       "gameofthrones     3        3     3\n",
       "conspiracy        2        2     2\n",
       "movies            2        2     2\n",
       "trees             1        1     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  comment  prep\n",
       "subreddit                         \n",
       "anime            55       55    55\n",
       "baseball         13       13    13\n",
       "conspiracy       13       13    13\n",
       "europe           11       11    11\n",
       "gameofthrones     9        9     9\n",
       "wow               9        9     9\n",
       "Overwatch         8        8     8\n",
       "funny             8        8     8\n",
       "hockey            7        7     7\n",
       "nfl               6        6     6\n",
       "GlobalOffensive   5        5     5\n",
       "movies            5        5     5\n",
       "nba               5        5     5\n",
       "canada            4        4     4\n",
       "leagueoflegends   4        4     4\n",
       "Music             3        3     3\n",
       "worldnews         3        3     3\n",
       "AskReddit         3        3     3\n",
       "trees             2        2     2\n",
       "soccer            1        1     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpg=wc_df.loc[wc_df['comment'].str.contains('jpg')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  comment  prep\n",
       "subreddit                         \n",
       "nba              50       50    50\n",
       "soccer           32       32    32\n",
       "leagueoflegends  29       29    29\n",
       "GlobalOffensive  27       27    27\n",
       "trees            26       26    26\n",
       "nfl              24       24    24\n",
       "baseball         21       21    21\n",
       "hockey           20       20    20\n",
       "anime            17       17    17\n",
       "Overwatch        15       15    15\n",
       "gameofthrones    10       10    10\n",
       "conspiracy       10       10    10\n",
       "wow               9        9     9\n",
       "worldnews         8        8     8\n",
       "movies            7        7     7\n",
       "europe            7        7     7\n",
       "canada            7        7     7\n",
       "AskReddit         5        5     5\n",
       "Music             4        4     4\n",
       "funny             2        2     2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmao=wc_df.loc[wc_df['comment'].str.contains('lmao')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  comment  prep\n",
       "subreddit                         \n",
       "wow               6        6     6\n",
       "GlobalOffensive   3        3     3\n",
       "Overwatch         3        3     3\n",
       "baseball          2        2     2\n",
       "hockey            2        2     2\n",
       "nba               2        2     2\n",
       "trees             2        2     2\n",
       "AskReddit         1        1     1\n",
       "canada            1        1     1\n",
       "conspiracy        1        1     1\n",
       "funny             1        1     1\n",
       "nfl               1        1     1\n",
       "soccer            1        1     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omg=wc_df.loc[wc_df['comment'].str.contains('omg')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "omg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  comment  prep\n",
       "subreddit                         \n",
       "europe            9        9     9\n",
       "canada            6        6     6\n",
       "worldnews         5        5     5\n",
       "trees             5        5     5\n",
       "GlobalOffensive   5        5     5\n",
       "gameofthrones     4        4     4\n",
       "anime             4        4     4\n",
       "conspiracy        4        4     4\n",
       "soccer            4        4     4\n",
       "leagueoflegends   4        4     4\n",
       "movies            3        3     3\n",
       "nba               3        3     3\n",
       "wow               3        3     3\n",
       "funny             3        3     3\n",
       "hockey            2        2     2\n",
       "nfl               1        1     1\n",
       "Overwatch         1        1     1\n",
       "Music             1        1     1\n",
       "AskReddit         1        1     1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whats=wc_df.loc[wc_df['comment'].str.contains('whats')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "whats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  comment  prep\n",
       "subreddit                          \n",
       "canada           360      360   360\n",
       "worldnews        351      351   351\n",
       "conspiracy       346      346   346\n",
       "gameofthrones    293      293   293\n",
       "anime            291      291   291\n",
       "europe           289      289   289\n",
       "movies           284      284   284\n",
       "wow              256      256   256\n",
       "Overwatch        248      248   248\n",
       "leagueoflegends  226      226   226\n",
       "GlobalOffensive  223      223   223\n",
       "AskReddit        207      207   207\n",
       "Music            194      194   194\n",
       "trees            182      182   182\n",
       "funny            171      171   171\n",
       "soccer           161      161   161\n",
       "hockey           132      132   132\n",
       "baseball         124      124   124\n",
       "nfl              124      124   124\n",
       "nba              120      120   120"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what=wc_df.loc[wc_df['comment'].str.contains('what')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  comment  prep\n",
       "subreddit                          \n",
       "wow              129      129   129\n",
       "anime            122      122   122\n",
       "GlobalOffensive   82       82    82\n",
       "leagueoflegends   78       78    78\n",
       "Overwatch         76       76    76\n",
       "europe            69       69    69\n",
       "Music             68       68    68\n",
       "canada            68       68    68\n",
       "worldnews         67       67    67\n",
       "conspiracy        63       63    63\n",
       "gameofthrones     56       56    56\n",
       "soccer            40       40    40\n",
       "movies            37       37    37\n",
       "AskReddit         36       36    36\n",
       "trees             34       34    34\n",
       "hockey            32       32    32\n",
       "nfl               29       29    29\n",
       "nba               24       24    24\n",
       "baseball          23       23    23\n",
       "funny             21       21    21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "since=wc_df.loc[wc_df['comment'].str.contains('since')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>518</td>\n",
       "      <td>518</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>473</td>\n",
       "      <td>473</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>321</td>\n",
       "      <td>321</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>273</td>\n",
       "      <td>273</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>267</td>\n",
       "      <td>267</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  comment  prep\n",
       "subreddit                          \n",
       "anime            518      518   518\n",
       "gameofthrones    473      473   473\n",
       "movies           323      323   323\n",
       "conspiracy       321      321   321\n",
       "Music            291      291   291\n",
       "canada           273      273   273\n",
       "worldnews        267      267   267\n",
       "europe           266      266   266\n",
       "wow              265      265   265\n",
       "leagueoflegends  245      245   245\n",
       "GlobalOffensive  218      218   218\n",
       "Overwatch        205      205   205\n",
       "AskReddit        187      187   187\n",
       "funny            162      162   162\n",
       "trees            154      154   154\n",
       "soccer           152      152   152\n",
       "nfl              151      151   151\n",
       "hockey           144      144   144\n",
       "nba              141      141   141\n",
       "baseball         117      117   117"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "how=wc_df.loc[wc_df['comment'].str.contains('how')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  comment  prep\n",
       "subreddit                          \n",
       "europe           223      223   223\n",
       "canada           148      148   148\n",
       "wow              130      130   130\n",
       "Music            120      120   120\n",
       "anime            116      116   116\n",
       "worldnews        116      116   116\n",
       "conspiracy       116      116   116\n",
       "movies           112      112   112\n",
       "leagueoflegends  109      109   109\n",
       "Overwatch        109      109   109\n",
       "gameofthrones    104      104   104\n",
       "GlobalOffensive   80       80    80\n",
       "AskReddit         69       69    69\n",
       "trees             54       54    54\n",
       "funny             48       48    48\n",
       "soccer            44       44    44\n",
       "nfl               31       31    31\n",
       "hockey            29       29    29\n",
       "nba               26       26    26\n",
       "baseball          13       13    13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which=wc_df.loc[wc_df['comment'].str.contains('which')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>317</td>\n",
       "      <td>317</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>287</td>\n",
       "      <td>287</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  comment  prep\n",
       "subreddit                          \n",
       "conspiracy       317      317   317\n",
       "canada           316      316   316\n",
       "worldnews        287      287   287\n",
       "movies           260      260   260\n",
       "gameofthrones    246      246   246\n",
       "anime            235      235   235\n",
       "Music            234      234   234\n",
       "europe           218      218   218\n",
       "Overwatch        215      215   215\n",
       "wow              209      209   209\n",
       "AskReddit        187      187   187\n",
       "leagueoflegends  177      177   177\n",
       "funny            148      148   148\n",
       "trees            133      133   133\n",
       "GlobalOffensive  119      119   119\n",
       "soccer           114      114   114\n",
       "nba               95       95    95\n",
       "hockey            89       89    89\n",
       "nfl               88       88    88\n",
       "baseball          77       77    77"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who=wc_df.loc[wc_df['comment'].str.contains('who')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  comment  prep\n",
       "subreddit                         \n",
       "worldnews        80       80    80\n",
       "AskReddit        74       74    74\n",
       "canada           72       72    72\n",
       "anime            69       69    69\n",
       "nba              62       62    62\n",
       "conspiracy       58       58    58\n",
       "europe           53       53    53\n",
       "trees            52       52    52\n",
       "gameofthrones    49       49    49\n",
       "funny            48       48    48\n",
       "wow              47       47    47\n",
       "movies           43       43    43\n",
       "Music            41       41    41\n",
       "Overwatch        33       33    33\n",
       "leagueoflegends  31       31    31\n",
       "GlobalOffensive  30       30    30\n",
       "hockey           23       23    23\n",
       "nfl              23       23    23\n",
       "baseball         22       22    22\n",
       "soccer           13       13    13"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask=wc_df.loc[wc_df['comment'].str.contains('ask')].groupby(['subreddit']).count().sort_values(by='prep', ascending=False)\n",
    "ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hope he gets the doomhammer back!</td>\n",
       "      <td>wow</td>\n",
       "      <td>hope get doomhammer back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>Disc is also rewarded by your group knowing en...</td>\n",
       "      <td>wow</td>\n",
       "      <td>disc also rewarded group knowing encounter wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>I mean I had every class at 100 and 110 and di...</td>\n",
       "      <td>wow</td>\n",
       "      <td>mean every class num num leveling process ha c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>The Ebon Blade vowed to fight Arthas for reven...</td>\n",
       "      <td>wow</td>\n",
       "      <td>ebon blade vowed fight arthas revenge cause se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>I don't have any money at all due to 0 income,...</td>\n",
       "      <td>wow</td>\n",
       "      <td>dont money due num income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59955</th>\n",
       "      <td>59955</td>\n",
       "      <td>&amp;gt; Do you want infinite dragonflights? \\n\\nY...</td>\n",
       "      <td>wow</td>\n",
       "      <td>gt want infinite dragonflights yes please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59957</th>\n",
       "      <td>59957</td>\n",
       "      <td>no. they're just different! artifacts are that...</td>\n",
       "      <td>wow</td>\n",
       "      <td>theyre different artifact goldybrown colour ic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59974</th>\n",
       "      <td>59974</td>\n",
       "      <td>Isn't 4.4 the stock boost clock of the 4790K?</td>\n",
       "      <td>wow</td>\n",
       "      <td>isnt num stock boost clock num k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59978</th>\n",
       "      <td>59978</td>\n",
       "      <td>Stoned elves man, get it right</td>\n",
       "      <td>wow</td>\n",
       "      <td>stoned elf man get right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59989</th>\n",
       "      <td>59989</td>\n",
       "      <td>The thing is, before legion it had no power an...</td>\n",
       "      <td>wow</td>\n",
       "      <td>thing legion power anyways thrall held symbol ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment subreddit  \\\n",
       "4          4                  Hope he gets the doomhammer back!       wow   \n",
       "57        57  Disc is also rewarded by your group knowing en...       wow   \n",
       "60        60  I mean I had every class at 100 and 110 and di...       wow   \n",
       "70        70  The Ebon Blade vowed to fight Arthas for reven...       wow   \n",
       "74        74  I don't have any money at all due to 0 income,...       wow   \n",
       "...      ...                                                ...       ...   \n",
       "59955  59955  &gt; Do you want infinite dragonflights? \\n\\nY...       wow   \n",
       "59957  59957  no. they're just different! artifacts are that...       wow   \n",
       "59974  59974      Isn't 4.4 the stock boost clock of the 4790K?       wow   \n",
       "59978  59978                     Stoned elves man, get it right       wow   \n",
       "59989  59989  The thing is, before legion it had no power an...       wow   \n",
       "\n",
       "                                                    prep  \n",
       "4                               hope get doomhammer back  \n",
       "57     disc also rewarded group knowing encounter wel...  \n",
       "60     mean every class num num leveling process ha c...  \n",
       "70     ebon blade vowed fight arthas revenge cause se...  \n",
       "74                             dont money due num income  \n",
       "...                                                  ...  \n",
       "59955          gt want infinite dragonflights yes please  \n",
       "59957  theyre different artifact goldybrown colour ic...  \n",
       "59974                   isnt num stock boost clock num k  \n",
       "59978                           stoned elf man get right  \n",
       "59989  thing legion power anyways thrall held symbol ...  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df_wow=wc_df.loc[wc_df['subreddit']=='wow']\n",
    "wc_df_wow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num          1705\n",
       "wa            753\n",
       "like          614\n",
       "get           455\n",
       "one           425\n",
       "             ... \n",
       "badlazy         1\n",
       "flesh           1\n",
       "illogical       1\n",
       "crotch          1\n",
       "dmgor           1\n",
       "Length: 9357, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df_wow_words=wc_df_wow['prep'].str.split(expand=True).stack().value_counts()\n",
    "wc_df_wow_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I think prestige points should not expire ever...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>think prestige point expire ever skin buy avai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Only reason anyone even remembers Marth and Ik...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>reason anyone even remembers marth ike cause s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>Only the affected team should get to chose, mi...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>affected team get chose misfit team doesnt get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>i love the yasuo crying face</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>love yasuo cry face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>Eve mains hate Blood Moon because it was a ski...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>eve main hate blood moon wa skin always wanted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59917</th>\n",
       "      <td>59917</td>\n",
       "      <td>And they are a totally different beast when it...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>totally different beast come bo num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59926</th>\n",
       "      <td>59926</td>\n",
       "      <td>Rick Fox is actually at a TV show set right no...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>rick fox actually tv show set right guess mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59960</th>\n",
       "      <td>59960</td>\n",
       "      <td>Renekton doesn't get outscaled midgame with Sh...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>renekton doesnt get outscaled midgame shojin f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59962</th>\n",
       "      <td>59962</td>\n",
       "      <td>Why do teams not clear the blast plant when do...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>team clear blast plant baron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59975</th>\n",
       "      <td>59975</td>\n",
       "      <td>I see people say this so often yet I never see...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>see people say often yet never see game board ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment  \\\n",
       "0          0  I think prestige points should not expire ever...   \n",
       "33        33  Only reason anyone even remembers Marth and Ik...   \n",
       "86        86  Only the affected team should get to chose, mi...   \n",
       "93        93                       i love the yasuo crying face   \n",
       "150      150  Eve mains hate Blood Moon because it was a ski...   \n",
       "...      ...                                                ...   \n",
       "59917  59917  And they are a totally different beast when it...   \n",
       "59926  59926  Rick Fox is actually at a TV show set right no...   \n",
       "59960  59960  Renekton doesn't get outscaled midgame with Sh...   \n",
       "59962  59962  Why do teams not clear the blast plant when do...   \n",
       "59975  59975  I see people say this so often yet I never see...   \n",
       "\n",
       "             subreddit                                               prep  \n",
       "0      leagueoflegends  think prestige point expire ever skin buy avai...  \n",
       "33     leagueoflegends  reason anyone even remembers marth ike cause s...  \n",
       "86     leagueoflegends  affected team get chose misfit team doesnt get...  \n",
       "93     leagueoflegends                                love yasuo cry face  \n",
       "150    leagueoflegends  eve main hate blood moon wa skin always wanted...  \n",
       "...                ...                                                ...  \n",
       "59917  leagueoflegends                totally different beast come bo num  \n",
       "59926  leagueoflegends  rick fox actually tv show set right guess mean...  \n",
       "59960  leagueoflegends  renekton doesnt get outscaled midgame shojin f...  \n",
       "59962  leagueoflegends                       team clear blast plant baron  \n",
       "59975  leagueoflegends  see people say often yet never see game board ...  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df_lol=wc_df.loc[wc_df['subreddit']=='leagueoflegends']\n",
    "wc_df_lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num            1823\n",
       "game            677\n",
       "wa              562\n",
       "like            497\n",
       "get             420\n",
       "               ... \n",
       "explained         1\n",
       "allstars          1\n",
       "predictable       1\n",
       "pistol            1\n",
       "piglet            1\n",
       "Length: 7722, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df_lol_words=wc_df_lol['prep'].str.split(expand=True).stack().value_counts()\n",
    "wc_df_lol_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>https://i.imgur.com/DUdy0KL.jpg</td>\n",
       "      <td>funny</td>\n",
       "      <td>httpsiimgurcomdudy num kljpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>All music can broken down to structures. Point...</td>\n",
       "      <td>funny</td>\n",
       "      <td>music broken structure pointing structure kind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>I too bring my bow into the hospital after I’v...</td>\n",
       "      <td>funny</td>\n",
       "      <td>bring bow hospital ive shot dad shoulder arrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Go to the gym and eat a healthy diet. \\n\\nAnd ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>go gym eat healthy diet get sunlight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>Politicians too. Willing to roast each other, ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>politician willing roast oh shit dont sound an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59883</th>\n",
       "      <td>59883</td>\n",
       "      <td>Maybe hold your reaction till you get facts, h...</td>\n",
       "      <td>funny</td>\n",
       "      <td>maybe hold reaction till get fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59906</th>\n",
       "      <td>59906</td>\n",
       "      <td>I would've taken my gun out and shot that ball...</td>\n",
       "      <td>funny</td>\n",
       "      <td>wouldve taken gun shot balloon wa making escap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59915</th>\n",
       "      <td>59915</td>\n",
       "      <td>I most certainly would. 4 backhoes sitting in ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>certainly would num backhoe sitting yard komat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59983</th>\n",
       "      <td>59983</td>\n",
       "      <td>The only time colon broke that I can easily re...</td>\n",
       "      <td>funny</td>\n",
       "      <td>time colon broke easily recall watching animal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>59996</td>\n",
       "      <td>Unplug these things right now</td>\n",
       "      <td>funny</td>\n",
       "      <td>unplug thing right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment subreddit  \\\n",
       "9          9                    https://i.imgur.com/DUdy0KL.jpg     funny   \n",
       "23        23  All music can broken down to structures. Point...     funny   \n",
       "24        24  I too bring my bow into the hospital after I’v...     funny   \n",
       "45        45  Go to the gym and eat a healthy diet. \\n\\nAnd ...     funny   \n",
       "49        49  Politicians too. Willing to roast each other, ...     funny   \n",
       "...      ...                                                ...       ...   \n",
       "59883  59883  Maybe hold your reaction till you get facts, h...     funny   \n",
       "59906  59906  I would've taken my gun out and shot that ball...     funny   \n",
       "59915  59915  I most certainly would. 4 backhoes sitting in ...     funny   \n",
       "59983  59983  The only time colon broke that I can easily re...     funny   \n",
       "59996  59996                      Unplug these things right now     funny   \n",
       "\n",
       "                                                    prep  \n",
       "9                           httpsiimgurcomdudy num kljpg  \n",
       "23     music broken structure pointing structure kind...  \n",
       "24     bring bow hospital ive shot dad shoulder arrow...  \n",
       "45                  go gym eat healthy diet get sunlight  \n",
       "49     politician willing roast oh shit dont sound an...  \n",
       "...                                                  ...  \n",
       "59883                  maybe hold reaction till get fact  \n",
       "59906  wouldve taken gun shot balloon wa making escap...  \n",
       "59915  certainly would num backhoe sitting yard komat...  \n",
       "59983  time colon broke easily recall watching animal...  \n",
       "59996                                 unplug thing right  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df_funny=wc_df.loc[wc_df['subreddit']=='funny']\n",
    "wc_df_funny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Is it really that far fetched? It actually mak...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>really far fetched actually make perfect sense...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Do you believe in ancestral spirit? Maybe this...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>believe ancestral spirit maybe synchronicity h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>The JFK assassination.</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>jfk assassination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>Yes it was. Which I always found confusing, co...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>yes wa always found confusing considering wore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>As the story goes they were waiting for Muelle...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>story go waiting mueller wrap thats also fishy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59931</th>\n",
       "      <td>59931</td>\n",
       "      <td>Those Twitter comments smh</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>twitter comment smh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59937</th>\n",
       "      <td>59937</td>\n",
       "      <td>I practice meditation. It has really helped me...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>practice meditation ha really helped control a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>59942</td>\n",
       "      <td>[For the First Time Ever, Temperatures Reached...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>first time ever temperature reached num degree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59970</th>\n",
       "      <td>59970</td>\n",
       "      <td>Well... scooter guy. 80s. Vancouver BC. Down t...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>well scooter guy num vancouver bc num u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59988</th>\n",
       "      <td>59988</td>\n",
       "      <td>why is always the rudest people that are the d...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>always rudest people dumbest nevermind im sure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment   subreddit  \\\n",
       "11        11  Is it really that far fetched? It actually mak...  conspiracy   \n",
       "14        14  Do you believe in ancestral spirit? Maybe this...  conspiracy   \n",
       "15        15                             The JFK assassination.  conspiracy   \n",
       "47        47  Yes it was. Which I always found confusing, co...  conspiracy   \n",
       "78        78  As the story goes they were waiting for Muelle...  conspiracy   \n",
       "...      ...                                                ...         ...   \n",
       "59931  59931                         Those Twitter comments smh  conspiracy   \n",
       "59937  59937  I practice meditation. It has really helped me...  conspiracy   \n",
       "59942  59942  [For the First Time Ever, Temperatures Reached...  conspiracy   \n",
       "59970  59970  Well... scooter guy. 80s. Vancouver BC. Down t...  conspiracy   \n",
       "59988  59988  why is always the rudest people that are the d...  conspiracy   \n",
       "\n",
       "                                                    prep  \n",
       "11     really far fetched actually make perfect sense...  \n",
       "14     believe ancestral spirit maybe synchronicity h...  \n",
       "15                                     jfk assassination  \n",
       "47     yes wa always found confusing considering wore...  \n",
       "78     story go waiting mueller wrap thats also fishy...  \n",
       "...                                                  ...  \n",
       "59931                                twitter comment smh  \n",
       "59937  practice meditation ha really helped control a...  \n",
       "59942  first time ever temperature reached num degree...  \n",
       "59970            well scooter guy num vancouver bc num u  \n",
       "59988  always rudest people dumbest nevermind im sure...  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df_conspiracy=wc_df.loc[wc_df['subreddit']=='conspiracy']\n",
    "wc_df_conspiracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>https://youtu.be/zQJcfkDjhRg</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>httpsyoutubezqjcfkdjhrg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>That assumption one is doing a lot of work. Ea...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>assumption one lot work earth need unique form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>I would fuck their mother</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>would fuck mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>Every dog is the best</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>every dog best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>Big Rigs over the road racing  \\n\\n\\nET on ata...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>big rig road racing et atari ride hell retribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59891</th>\n",
       "      <td>59891</td>\n",
       "      <td>Breaking bad. Definitely.</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>breaking bad definitely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59899</th>\n",
       "      <td>59899</td>\n",
       "      <td>There's a lot of articles out there. Gotta sea...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>lot article gotta search engine one although a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59990</th>\n",
       "      <td>59990</td>\n",
       "      <td>Children are still dying from preventable dise...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>child still dying preventable disease around w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59993</th>\n",
       "      <td>59993</td>\n",
       "      <td>What's a good costume for a muscular girl with...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>whats good costume muscular girl visible ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>59999</td>\n",
       "      <td>Too broad dude, get ready for the shit my pant...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>broad dude get ready shit pant story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment  subreddit  \\\n",
       "20        20                       https://youtu.be/zQJcfkDjhRg  AskReddit   \n",
       "41        41  That assumption one is doing a lot of work. Ea...  AskReddit   \n",
       "65        65                          I would fuck their mother  AskReddit   \n",
       "67        67                              Every dog is the best  AskReddit   \n",
       "77        77  Big Rigs over the road racing  \\n\\n\\nET on ata...  AskReddit   \n",
       "...      ...                                                ...        ...   \n",
       "59891  59891                          Breaking bad. Definitely.  AskReddit   \n",
       "59899  59899  There's a lot of articles out there. Gotta sea...  AskReddit   \n",
       "59990  59990  Children are still dying from preventable dise...  AskReddit   \n",
       "59993  59993  What's a good costume for a muscular girl with...  AskReddit   \n",
       "59999  59999  Too broad dude, get ready for the shit my pant...  AskReddit   \n",
       "\n",
       "                                                    prep  \n",
       "20                               httpsyoutubezqjcfkdjhrg  \n",
       "41     assumption one lot work earth need unique form...  \n",
       "65                                     would fuck mother  \n",
       "67                                        every dog best  \n",
       "77     big rig road racing et atari ride hell retribu...  \n",
       "...                                                  ...  \n",
       "59891                            breaking bad definitely  \n",
       "59899  lot article gotta search engine one although a...  \n",
       "59990  child still dying preventable disease around w...  \n",
       "59993        whats good costume muscular girl visible ab  \n",
       "59999               broad dude get ready shit pant story  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df_AskReddit=wc_df.loc[wc_df['subreddit']=='AskReddit']\n",
    "wc_df_AskReddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num       770\n",
       "wa        357\n",
       "like      346\n",
       "one       213\n",
       "get       204\n",
       "people    203\n",
       "dont      198\n",
       "im        181\n",
       "would     166\n",
       "thats     162\n",
       "time      153\n",
       "know      148\n",
       "think     133\n",
       "ha        124\n",
       "thing     122\n",
       "make      115\n",
       "good      113\n",
       "go        110\n",
       "really    109\n",
       "look      105\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df_funny_words=wc_df_funny['prep'].str.split(expand=True).stack().value_counts()\n",
    "wc_df_funny_words[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num       1769\n",
       "wa         750\n",
       "people     564\n",
       "like       502\n",
       "dont       375\n",
       "one        344\n",
       "ha         332\n",
       "would      330\n",
       "think      308\n",
       "get        301\n",
       "trump      293\n",
       "know       283\n",
       "even       234\n",
       "im         233\n",
       "make       230\n",
       "year       218\n",
       "thing      217\n",
       "thats      209\n",
       "u          206\n",
       "gt         199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df_conspiracy_words=wc_df_conspiracy['prep'].str.split(expand=True).stack().value_counts()\n",
    "wc_df_conspiracy_words[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num       678\n",
       "wa        674\n",
       "like      388\n",
       "get       311\n",
       "one       301\n",
       "people    300\n",
       "would     263\n",
       "im        256\n",
       "dont      256\n",
       "time      228\n",
       "know      212\n",
       "think     187\n",
       "thing     185\n",
       "make      183\n",
       "go        160\n",
       "ha        145\n",
       "really    141\n",
       "got       140\n",
       "thats     140\n",
       "year      139\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_df_AskReddit_words=wc_df_AskReddit['prep'].str.split(expand=True).stack().value_counts()\n",
    "wc_df_AskReddit_words[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_df_ALL_words=wc_df['prep'].str.split(expand=True).stack().value_counts()\n",
    "wc_df_ALL_words[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_custom in [wc_df_funny,wc_df_conspiracy,wc_df_AskReddit,wc_df_lol,wc_df_wow]:\n",
    "\n",
    "    text = ' '\n",
    "    stopwords = set(STOPWORDS) \n",
    "\n",
    "    # iterate through the csv file \n",
    "    for x in df_custom.prep: \n",
    "\n",
    "        # typecaste each val to string \n",
    "        x = str(x) \n",
    "\n",
    "        # split the value \n",
    "        values = x.split() \n",
    "\n",
    "        # Converts each token into lowercase \n",
    "        for i in range(len(values)): \n",
    "            values[i] = values[i].lower() \n",
    "\n",
    "        for words in values: \n",
    "            text = text + words + ' '\n",
    "\n",
    "\n",
    "    wc = WordCloud(max_words= 100,\n",
    "                          width = 744, \n",
    "                          height = 544,\n",
    "                          background_color ='white',\n",
    "                          stopwords=stopwords, \n",
    "                          contour_width=3, \n",
    "                          contour_color='steelblue',\n",
    "                          min_font_size = 10).generate(text) \n",
    "\n",
    "    # plot the WordCloud image    \n",
    "    #plt.figure(figsize = (14, 14)) \n",
    "    #print(df_custom.subreddit)\n",
    "    #plt.imshow(wc) \n",
    "    #plt.axis(\"off\")\n",
    "    #plt.savefig('../images/reddit_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "text = ' '\n",
    "stopwords = set(STOPWORDS) \n",
    "  \n",
    "# iterate through the csv file \n",
    "for x in wc_df_funny[0:20].prep: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    x = str(x) \n",
    "  \n",
    "    # split the value \n",
    "    values = x.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(values)): \n",
    "        values[i] = values[i].lower() \n",
    "          \n",
    "    for words in values: \n",
    "        text = text + words + ' '\n",
    "  \n",
    "  \n",
    "wc = WordCloud(max_words= 100,\n",
    "                      width = 744, \n",
    "                      height = 544,\n",
    "                      background_color ='white',\n",
    "                      stopwords=stopwords, \n",
    "                      contour_width=3, \n",
    "                      contour_color='steelblue',\n",
    "                      min_font_size = 10).generate(text) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "#plt.figure(figsize = (14, 14)) \n",
    "#plt.imshow(wc) \n",
    "#plt.axis(\"off\")\n",
    "#plt.savefig('../images/reddit_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# natural language toolkit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tag import pos_tag_sents\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# SciKit-Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "#train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "\n",
    "\n",
    "comment_data = train\n",
    "\n",
    "#clean\n",
    "comment_data['prep'] = comment_data['comment'].str.replace(r'[^\\w\\s]+', '') # tira td que nao palavra e espaco em branco\n",
    "comment_data['prep'] = comment_data['prep'].str.lower()\n",
    "comment_data['prep'] = comment_data['prep'].str.replace('(\\d+)', ' num ')\n",
    "#comment_data['prep'] = comment_data['prep'].str.replace(r'http(?<=http).*', ' ')\n",
    "comment_data['prep'] = comment_data['prep'].str.replace(r'\\s+', \" \")\n",
    "comment_data['prep'] = comment_data['prep'].str.replace(\" +\", \" \")\n",
    "\n",
    "#comment_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "#clean\n",
    "test_data['prep'] = test_data['comment'].str.replace(r'[^\\w\\s]+', '')\n",
    "test_data['prep'] = test_data['prep'].str.lower()\n",
    "test_data['prep'] = test_data['prep'].str.replace('(\\d+)', ' num ')\n",
    "#test_data['prep'] = test_data['prep'].str.replace(r'http(?<=http).*', ' ')\n",
    "test_data['prep'] = test_data['prep'].str.replace(r'\\s+', \" \")\n",
    "test_data['prep'] = test_data['prep'].str.replace(\" +\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tt = TweetTokenizer()\n",
    "def lemmatize_col(row):\n",
    "    row = tt.tokenize(row)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in row])\n",
    "\n",
    "comment_data['prep'] = comment_data['prep'].apply(lemmatize_col)\n",
    "test_data['prep'] = test_data['prep'].apply(lemmatize_col) \n",
    "\n",
    "# stopwords\n",
    "stop = stopwords.words('english')\n",
    "comment_data['prep'] = comment_data['prep'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "test_data['prep'] = test_data['prep'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>https://i.imgur.com/DUdy0KL.jpg</td>\n",
       "      <td>funny</td>\n",
       "      <td>httpsiimgurcomdudy num kljpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>All music can broken down to structures. Point...</td>\n",
       "      <td>funny</td>\n",
       "      <td>music broken structure pointing structure kind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>I too bring my bow into the hospital after I’v...</td>\n",
       "      <td>funny</td>\n",
       "      <td>bring bow hospital ive shot dad shoulder arrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Go to the gym and eat a healthy diet. \\n\\nAnd ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>go gym eat healthy diet get sunlight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>Politicians too. Willing to roast each other, ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>politician willing roast oh shit dont sound an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59883</th>\n",
       "      <td>59883</td>\n",
       "      <td>Maybe hold your reaction till you get facts, h...</td>\n",
       "      <td>funny</td>\n",
       "      <td>maybe hold reaction till get fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59906</th>\n",
       "      <td>59906</td>\n",
       "      <td>I would've taken my gun out and shot that ball...</td>\n",
       "      <td>funny</td>\n",
       "      <td>wouldve taken gun shot balloon wa making escap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59915</th>\n",
       "      <td>59915</td>\n",
       "      <td>I most certainly would. 4 backhoes sitting in ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>certainly would num backhoe sitting yard komat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59983</th>\n",
       "      <td>59983</td>\n",
       "      <td>The only time colon broke that I can easily re...</td>\n",
       "      <td>funny</td>\n",
       "      <td>time colon broke easily recall watching animal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>59996</td>\n",
       "      <td>Unplug these things right now</td>\n",
       "      <td>funny</td>\n",
       "      <td>unplug thing right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment subreddit  \\\n",
       "9          9                    https://i.imgur.com/DUdy0KL.jpg     funny   \n",
       "23        23  All music can broken down to structures. Point...     funny   \n",
       "24        24  I too bring my bow into the hospital after I’v...     funny   \n",
       "45        45  Go to the gym and eat a healthy diet. \\n\\nAnd ...     funny   \n",
       "49        49  Politicians too. Willing to roast each other, ...     funny   \n",
       "...      ...                                                ...       ...   \n",
       "59883  59883  Maybe hold your reaction till you get facts, h...     funny   \n",
       "59906  59906  I would've taken my gun out and shot that ball...     funny   \n",
       "59915  59915  I most certainly would. 4 backhoes sitting in ...     funny   \n",
       "59983  59983  The only time colon broke that I can easily re...     funny   \n",
       "59996  59996                      Unplug these things right now     funny   \n",
       "\n",
       "                                                    prep  \n",
       "9                           httpsiimgurcomdudy num kljpg  \n",
       "23     music broken structure pointing structure kind...  \n",
       "24     bring bow hospital ive shot dad shoulder arrow...  \n",
       "45                  go gym eat healthy diet get sunlight  \n",
       "49     politician willing roast oh shit dont sound an...  \n",
       "...                                                  ...  \n",
       "59883                  maybe hold reaction till get fact  \n",
       "59906  wouldve taken gun shot balloon wa making escap...  \n",
       "59915  certainly would num backhoe sitting yard komat...  \n",
       "59983  time colon broke easily recall watching animal...  \n",
       "59996                                 unplug thing right  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CRIANDO FEATURES NEW_COMMENT\n",
    "\n",
    "train_funny=train.loc[train['subreddit']=='funny']\n",
    "train_funny\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>https://youtu.be/zQJcfkDjhRg</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>httpsyoutubezqjcfkdjhrg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>That assumption one is doing a lot of work. Ea...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>assumption one lot work earth need unique form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>I would fuck their mother</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>would fuck mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>Every dog is the best</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>every dog best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>Big Rigs over the road racing  \\n\\n\\nET on ata...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>big rig road racing et atari ride hell retribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59891</th>\n",
       "      <td>59891</td>\n",
       "      <td>Breaking bad. Definitely.</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>breaking bad definitely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59899</th>\n",
       "      <td>59899</td>\n",
       "      <td>There's a lot of articles out there. Gotta sea...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>lot article gotta search engine one although a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59990</th>\n",
       "      <td>59990</td>\n",
       "      <td>Children are still dying from preventable dise...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>child still dying preventable disease around w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59993</th>\n",
       "      <td>59993</td>\n",
       "      <td>What's a good costume for a muscular girl with...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>whats good costume muscular girl visible ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>59999</td>\n",
       "      <td>Too broad dude, get ready for the shit my pant...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>broad dude get ready shit pant story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment  subreddit  \\\n",
       "20        20                       https://youtu.be/zQJcfkDjhRg  AskReddit   \n",
       "41        41  That assumption one is doing a lot of work. Ea...  AskReddit   \n",
       "65        65                          I would fuck their mother  AskReddit   \n",
       "67        67                              Every dog is the best  AskReddit   \n",
       "77        77  Big Rigs over the road racing  \\n\\n\\nET on ata...  AskReddit   \n",
       "...      ...                                                ...        ...   \n",
       "59891  59891                          Breaking bad. Definitely.  AskReddit   \n",
       "59899  59899  There's a lot of articles out there. Gotta sea...  AskReddit   \n",
       "59990  59990  Children are still dying from preventable dise...  AskReddit   \n",
       "59993  59993  What's a good costume for a muscular girl with...  AskReddit   \n",
       "59999  59999  Too broad dude, get ready for the shit my pant...  AskReddit   \n",
       "\n",
       "                                                    prep  \n",
       "20                               httpsyoutubezqjcfkdjhrg  \n",
       "41     assumption one lot work earth need unique form...  \n",
       "65                                     would fuck mother  \n",
       "67                                        every dog best  \n",
       "77     big rig road racing et atari ride hell retribu...  \n",
       "...                                                  ...  \n",
       "59891                            breaking bad definitely  \n",
       "59899  lot article gotta search engine one although a...  \n",
       "59990  child still dying preventable disease around w...  \n",
       "59993        whats good costume muscular girl visible ab  \n",
       "59999               broad dude get ready shit pant story  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_Ask=train.loc[train['subreddit']=='AskReddit']\n",
    "train_Ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "      <th>new_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>https://youtu.be/zQJcfkDjhRg</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>httpsyoutubezqjcfkdjhrg</td>\n",
       "      <td>is AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>That assumption one is doing a lot of work. Ea...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>assumption one lot work earth need unique form...</td>\n",
       "      <td>is AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>I would fuck their mother</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>would fuck mother</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>Every dog is the best</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>every dog best</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>Big Rigs over the road racing  \\n\\n\\nET on ata...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>big rig road racing et atari ride hell retribu...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59891</th>\n",
       "      <td>59891</td>\n",
       "      <td>Breaking bad. Definitely.</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>breaking bad definitely</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59899</th>\n",
       "      <td>59899</td>\n",
       "      <td>There's a lot of articles out there. Gotta sea...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>lot article gotta search engine one although a...</td>\n",
       "      <td>is AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59990</th>\n",
       "      <td>59990</td>\n",
       "      <td>Children are still dying from preventable dise...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>child still dying preventable disease around w...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59993</th>\n",
       "      <td>59993</td>\n",
       "      <td>What's a good costume for a muscular girl with...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>whats good costume muscular girl visible ab</td>\n",
       "      <td>is AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>59999</td>\n",
       "      <td>Too broad dude, get ready for the shit my pant...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>broad dude get ready shit pant story</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment  subreddit  \\\n",
       "20        20                       https://youtu.be/zQJcfkDjhRg  AskReddit   \n",
       "41        41  That assumption one is doing a lot of work. Ea...  AskReddit   \n",
       "65        65                          I would fuck their mother  AskReddit   \n",
       "67        67                              Every dog is the best  AskReddit   \n",
       "77        77  Big Rigs over the road racing  \\n\\n\\nET on ata...  AskReddit   \n",
       "...      ...                                                ...        ...   \n",
       "59891  59891                          Breaking bad. Definitely.  AskReddit   \n",
       "59899  59899  There's a lot of articles out there. Gotta sea...  AskReddit   \n",
       "59990  59990  Children are still dying from preventable dise...  AskReddit   \n",
       "59993  59993  What's a good costume for a muscular girl with...  AskReddit   \n",
       "59999  59999  Too broad dude, get ready for the shit my pant...  AskReddit   \n",
       "\n",
       "                                                    prep   new_comment  \n",
       "20                               httpsyoutubezqjcfkdjhrg  is AskReddit  \n",
       "41     assumption one lot work earth need unique form...  is AskReddit  \n",
       "65                                     would fuck mother             .  \n",
       "67                                        every dog best             .  \n",
       "77     big rig road racing et atari ride hell retribu...             .  \n",
       "...                                                  ...           ...  \n",
       "59891                            breaking bad definitely             .  \n",
       "59899  lot article gotta search engine one although a...  is AskReddit  \n",
       "59990  child still dying preventable disease around w...             .  \n",
       "59993        whats good costume muscular girl visible ab  is AskReddit  \n",
       "59999               broad dude get ready shit pant story             .  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Ask['new_comment'] = np.where((train_Ask.prep.str.contains('how')|\n",
    "                                     train_Ask.prep.str.contains('since') |\n",
    "                                     train_Ask.prep.str.contains('http') |\n",
    "                                     train_Ask.prep.str.contains('https') |\n",
    "                                     train_Ask.prep.str.contains('ask') |\n",
    "                                     train_Ask.prep.str.contains('who') |\n",
    "                                     train_Ask.prep.str.contains('why') |\n",
    "                                     train_Ask.prep.str.contains('which') |\n",
    "                                     train_Ask.prep.str.contains('what') |\n",
    "                                     \n",
    "                                     train_Ask.prep.str.contains('jpg')|\n",
    "                                       train_Ask.prep.str.contains('jpeg') |\n",
    "                                       train_Ask.prep.str.contains('http') |\n",
    "\n",
    "                                       train_Ask.prep.str.contains('https') |\n",
    "\n",
    "                                       train_Ask.prep.str.contains('picture') |\n",
    "                                       train_Ask.prep.str.contains('gif') |\n",
    "\n",
    "                                     \n",
    "                                     \n",
    "                                     mexer pouco e so nas que estao ruins\n",
    "                                     \n",
    "                                     \n",
    "                                      np.where((train.prep.str.contains('http') |\n",
    "                                    # train.prep.str.contains('https') |    #nao precisa pois esta contido no http                               \n",
    "                                            \n",
    "                                       train.prep.str.contains('jpg')|\n",
    "                                       train.prep.str.contains('jpeg') |\n",
    "                                     \n",
    "\n",
    "                                       train.prep.str.contains('picture') |\n",
    "                                       train.prep.str.contains('gif') |\n",
    "                                     \n",
    "                                    ( train.prep.str.contains('http') & train.prep.str.contains('num')) |\n",
    "                                     \n",
    "                                  \n",
    "                                      #((train.prep.str.contains('https') & (train.prep.str.contains('num')) |\n",
    "                                     \n",
    "                                        (train.prep.str.contains('jpg') & train.prep.str.contains('num')) |\n",
    "                                          (train.prep.str.contains('jpeg') & train.prep.str.contains('num')) |\n",
    "                                            (train.prep.str.contains('picture') & train.prep.str.contains('num')) |\n",
    "                                              (train.prep.str.contains('gif') & train.prep.str.contains('num')) \n",
    "                                                \n",
    "                                                \n",
    "                                     \n",
    "\n",
    "\n",
    "                                      ),'seems' + ' ' + train.subreddit, '.')\n",
    "\n",
    "                                     \n",
    "                                     \n",
    "                                     \n",
    "\n",
    "\n",
    "                                       train_Ask.prep.str.contains('num') \n",
    "                                   \n",
    "\n",
    "\n",
    "                                      ),'is AskReddit', '.') \n",
    "\n",
    "train_Ask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "      <th>new_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>https://i.imgur.com/DUdy0KL.jpg</td>\n",
       "      <td>funny</td>\n",
       "      <td>httpsiimgurcomdudy num kljpg</td>\n",
       "      <td>is funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>All music can broken down to structures. Point...</td>\n",
       "      <td>funny</td>\n",
       "      <td>music broken structure pointing structure kind...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>I too bring my bow into the hospital after I’v...</td>\n",
       "      <td>funny</td>\n",
       "      <td>bring bow hospital ive shot dad shoulder arrow...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Go to the gym and eat a healthy diet. \\n\\nAnd ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>go gym eat healthy diet get sunlight</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>Politicians too. Willing to roast each other, ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>politician willing roast oh shit dont sound an...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59883</th>\n",
       "      <td>59883</td>\n",
       "      <td>Maybe hold your reaction till you get facts, h...</td>\n",
       "      <td>funny</td>\n",
       "      <td>maybe hold reaction till get fact</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59906</th>\n",
       "      <td>59906</td>\n",
       "      <td>I would've taken my gun out and shot that ball...</td>\n",
       "      <td>funny</td>\n",
       "      <td>wouldve taken gun shot balloon wa making escap...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59915</th>\n",
       "      <td>59915</td>\n",
       "      <td>I most certainly would. 4 backhoes sitting in ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>certainly would num backhoe sitting yard komat...</td>\n",
       "      <td>is funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59983</th>\n",
       "      <td>59983</td>\n",
       "      <td>The only time colon broke that I can easily re...</td>\n",
       "      <td>funny</td>\n",
       "      <td>time colon broke easily recall watching animal...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>59996</td>\n",
       "      <td>Unplug these things right now</td>\n",
       "      <td>funny</td>\n",
       "      <td>unplug thing right</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment subreddit  \\\n",
       "9          9                    https://i.imgur.com/DUdy0KL.jpg     funny   \n",
       "23        23  All music can broken down to structures. Point...     funny   \n",
       "24        24  I too bring my bow into the hospital after I’v...     funny   \n",
       "45        45  Go to the gym and eat a healthy diet. \\n\\nAnd ...     funny   \n",
       "49        49  Politicians too. Willing to roast each other, ...     funny   \n",
       "...      ...                                                ...       ...   \n",
       "59883  59883  Maybe hold your reaction till you get facts, h...     funny   \n",
       "59906  59906  I would've taken my gun out and shot that ball...     funny   \n",
       "59915  59915  I most certainly would. 4 backhoes sitting in ...     funny   \n",
       "59983  59983  The only time colon broke that I can easily re...     funny   \n",
       "59996  59996                      Unplug these things right now     funny   \n",
       "\n",
       "                                                    prep new_comment  \n",
       "9                           httpsiimgurcomdudy num kljpg    is funny  \n",
       "23     music broken structure pointing structure kind...           .  \n",
       "24     bring bow hospital ive shot dad shoulder arrow...           .  \n",
       "45                  go gym eat healthy diet get sunlight           .  \n",
       "49     politician willing roast oh shit dont sound an...           .  \n",
       "...                                                  ...         ...  \n",
       "59883                  maybe hold reaction till get fact           .  \n",
       "59906  wouldve taken gun shot balloon wa making escap...           .  \n",
       "59915  certainly would num backhoe sitting yard komat...    is funny  \n",
       "59983  time colon broke easily recall watching animal...           .  \n",
       "59996                                 unplug thing right           .  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_funny['new_comment'] = np.where((train_funny.prep.str.contains('jpg')|\n",
    "                                       train_funny.prep.str.contains('jpeg') |\n",
    "                                       train_funny.prep.str.contains('http') |\n",
    "\n",
    "                                       train_funny.prep.str.contains('https') |\n",
    "\n",
    "                                       train_funny.prep.str.contains('picture') |\n",
    "                                       train_funny.prep.str.contains('gif') |\n",
    "                                       train_funny.prep.str.contains('lmao') |\n",
    "                                       \n",
    "                                       \n",
    "                                       train_funny.prep.str.contains('lol') |\n",
    "                                       \n",
    "                                       train_funny.prep.str.contains('omg') |\n",
    "                                       \n",
    "                                       train_funny.prep.str.contains('haha') |\n",
    "                                       \n",
    "                                       \n",
    "                                       \n",
    "                                       train_funny.comment.str.contains('!!') |\n",
    "                                       train_funny.prep.str.contains('laugh') |\n",
    "                                       \n",
    "                                      \n",
    "\n",
    "                                       train_funny.prep.str.contains('num') \n",
    "                                       \n",
    "                                \n",
    "\n",
    "\n",
    "                                      ),'is funny', '.') \n",
    "\n",
    "train_funny\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "      <th>new_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Is it really that far fetched? It actually mak...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>really far fetched actually make perfect sense...</td>\n",
       "      <td>is conpiracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Do you believe in ancestral spirit? Maybe this...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>believe ancestral spirit maybe synchronicity h...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>The JFK assassination.</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>jfk assassination</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>Yes it was. Which I always found confusing, co...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>yes wa always found confusing considering wore...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>As the story goes they were waiting for Muelle...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>story go waiting mueller wrap thats also fishy...</td>\n",
       "      <td>is conpiracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59931</th>\n",
       "      <td>59931</td>\n",
       "      <td>Those Twitter comments smh</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>twitter comment smh</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59937</th>\n",
       "      <td>59937</td>\n",
       "      <td>I practice meditation. It has really helped me...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>practice meditation ha really helped control a...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>59942</td>\n",
       "      <td>[For the First Time Ever, Temperatures Reached...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>first time ever temperature reached num degree...</td>\n",
       "      <td>is conpiracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59970</th>\n",
       "      <td>59970</td>\n",
       "      <td>Well... scooter guy. 80s. Vancouver BC. Down t...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>well scooter guy num vancouver bc num u</td>\n",
       "      <td>is conpiracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59988</th>\n",
       "      <td>59988</td>\n",
       "      <td>why is always the rudest people that are the d...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>always rudest people dumbest nevermind im sure...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment   subreddit  \\\n",
       "11        11  Is it really that far fetched? It actually mak...  conspiracy   \n",
       "14        14  Do you believe in ancestral spirit? Maybe this...  conspiracy   \n",
       "15        15                             The JFK assassination.  conspiracy   \n",
       "47        47  Yes it was. Which I always found confusing, co...  conspiracy   \n",
       "78        78  As the story goes they were waiting for Muelle...  conspiracy   \n",
       "...      ...                                                ...         ...   \n",
       "59931  59931                         Those Twitter comments smh  conspiracy   \n",
       "59937  59937  I practice meditation. It has really helped me...  conspiracy   \n",
       "59942  59942  [For the First Time Ever, Temperatures Reached...  conspiracy   \n",
       "59970  59970  Well... scooter guy. 80s. Vancouver BC. Down t...  conspiracy   \n",
       "59988  59988  why is always the rudest people that are the d...  conspiracy   \n",
       "\n",
       "                                                    prep   new_comment  \n",
       "11     really far fetched actually make perfect sense...  is conpiracy  \n",
       "14     believe ancestral spirit maybe synchronicity h...             .  \n",
       "15                                     jfk assassination             .  \n",
       "47     yes wa always found confusing considering wore...             .  \n",
       "78     story go waiting mueller wrap thats also fishy...  is conpiracy  \n",
       "...                                                  ...           ...  \n",
       "59931                                twitter comment smh             .  \n",
       "59937  practice meditation ha really helped control a...             .  \n",
       "59942  first time ever temperature reached num degree...  is conpiracy  \n",
       "59970            well scooter guy num vancouver bc num u  is conpiracy  \n",
       "59988  always rudest people dumbest nevermind im sure...             .  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_conspiracy=train.loc[train['subreddit']=='conspiracy']\n",
    "\n",
    "\n",
    "train_conspiracy['new_comment'] = np.where((train_conspiracy.prep.str.contains('how')|\n",
    "                                     train_conspiracy.prep.str.contains('since') |\n",
    "                                     train_conspiracy.prep.str.contains('http') |\n",
    "                                     train_conspiracy.prep.str.contains('https') |                                   \n",
    "                                     train_conspiracy.prep.str.contains('what') |\n",
    "                                            \n",
    "                                       train_conspiracy.prep.str.contains('jpg')|\n",
    "                                       train_conspiracy.prep.str.contains('jpeg') |\n",
    "                                       train_conspiracy.prep.str.contains('http') |\n",
    "\n",
    "                                       train_conspiracy.prep.str.contains('https') |\n",
    "\n",
    "                                       train_conspiracy.prep.str.contains('picture') |\n",
    "                                       train_conspiracy.prep.str.contains('gif') |\n",
    "\n",
    "                           \n",
    "\n",
    "                                       train_conspiracy.prep.str.contains('num')\n",
    "                          \n",
    "\n",
    "\n",
    "                                      ),'is conpiracy', '.') \n",
    "\n",
    "train_conspiracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "      <th>new_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>https://i.imgur.com/DUdy0KL.jpg</td>\n",
       "      <td>funny</td>\n",
       "      <td>httpsiimgurcomdudy num kljpg</td>\n",
       "      <td>is funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>All music can broken down to structures. Point...</td>\n",
       "      <td>funny</td>\n",
       "      <td>music broken structure pointing structure kind...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>I too bring my bow into the hospital after I’v...</td>\n",
       "      <td>funny</td>\n",
       "      <td>bring bow hospital ive shot dad shoulder arrow...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Go to the gym and eat a healthy diet. \\n\\nAnd ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>go gym eat healthy diet get sunlight</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>Politicians too. Willing to roast each other, ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>politician willing roast oh shit dont sound an...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59891</th>\n",
       "      <td>59891</td>\n",
       "      <td>Breaking bad. Definitely.</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>breaking bad definitely</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59899</th>\n",
       "      <td>59899</td>\n",
       "      <td>There's a lot of articles out there. Gotta sea...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>lot article gotta search engine one although a...</td>\n",
       "      <td>is AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59990</th>\n",
       "      <td>59990</td>\n",
       "      <td>Children are still dying from preventable dise...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>child still dying preventable disease around w...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59993</th>\n",
       "      <td>59993</td>\n",
       "      <td>What's a good costume for a muscular girl with...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>whats good costume muscular girl visible ab</td>\n",
       "      <td>is AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>59999</td>\n",
       "      <td>Too broad dude, get ready for the shit my pant...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>broad dude get ready shit pant story</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment  subreddit  \\\n",
       "9          9                    https://i.imgur.com/DUdy0KL.jpg      funny   \n",
       "23        23  All music can broken down to structures. Point...      funny   \n",
       "24        24  I too bring my bow into the hospital after I’v...      funny   \n",
       "45        45  Go to the gym and eat a healthy diet. \\n\\nAnd ...      funny   \n",
       "49        49  Politicians too. Willing to roast each other, ...      funny   \n",
       "...      ...                                                ...        ...   \n",
       "59891  59891                          Breaking bad. Definitely.  AskReddit   \n",
       "59899  59899  There's a lot of articles out there. Gotta sea...  AskReddit   \n",
       "59990  59990  Children are still dying from preventable dise...  AskReddit   \n",
       "59993  59993  What's a good costume for a muscular girl with...  AskReddit   \n",
       "59999  59999  Too broad dude, get ready for the shit my pant...  AskReddit   \n",
       "\n",
       "                                                    prep   new_comment  \n",
       "9                           httpsiimgurcomdudy num kljpg      is funny  \n",
       "23     music broken structure pointing structure kind...             .  \n",
       "24     bring bow hospital ive shot dad shoulder arrow...             .  \n",
       "45                  go gym eat healthy diet get sunlight             .  \n",
       "49     politician willing roast oh shit dont sound an...             .  \n",
       "...                                                  ...           ...  \n",
       "59891                            breaking bad definitely             .  \n",
       "59899  lot article gotta search engine one although a...  is AskReddit  \n",
       "59990  child still dying preventable disease around w...             .  \n",
       "59993        whats good costume muscular girl visible ab  is AskReddit  \n",
       "59999               broad dude get ready shit pant story             .  \n",
       "\n",
       "[6000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_eng=train_funny.append(train_Ask)\n",
    "df_feat_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "      <th>new_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>https://i.imgur.com/DUdy0KL.jpg</td>\n",
       "      <td>funny</td>\n",
       "      <td>httpsiimgurcomdudy num kljpg</td>\n",
       "      <td>is funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>All music can broken down to structures. Point...</td>\n",
       "      <td>funny</td>\n",
       "      <td>music broken structure pointing structure kind...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>I too bring my bow into the hospital after I’v...</td>\n",
       "      <td>funny</td>\n",
       "      <td>bring bow hospital ive shot dad shoulder arrow...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Go to the gym and eat a healthy diet. \\n\\nAnd ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>go gym eat healthy diet get sunlight</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>Politicians too. Willing to roast each other, ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>politician willing roast oh shit dont sound an...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59931</th>\n",
       "      <td>59931</td>\n",
       "      <td>Those Twitter comments smh</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>twitter comment smh</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59937</th>\n",
       "      <td>59937</td>\n",
       "      <td>I practice meditation. It has really helped me...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>practice meditation ha really helped control a...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>59942</td>\n",
       "      <td>[For the First Time Ever, Temperatures Reached...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>first time ever temperature reached num degree...</td>\n",
       "      <td>is conpiracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59970</th>\n",
       "      <td>59970</td>\n",
       "      <td>Well... scooter guy. 80s. Vancouver BC. Down t...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>well scooter guy num vancouver bc num u</td>\n",
       "      <td>is conpiracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59988</th>\n",
       "      <td>59988</td>\n",
       "      <td>why is always the rudest people that are the d...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>always rudest people dumbest nevermind im sure...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment   subreddit  \\\n",
       "9          9                    https://i.imgur.com/DUdy0KL.jpg       funny   \n",
       "23        23  All music can broken down to structures. Point...       funny   \n",
       "24        24  I too bring my bow into the hospital after I’v...       funny   \n",
       "45        45  Go to the gym and eat a healthy diet. \\n\\nAnd ...       funny   \n",
       "49        49  Politicians too. Willing to roast each other, ...       funny   \n",
       "...      ...                                                ...         ...   \n",
       "59931  59931                         Those Twitter comments smh  conspiracy   \n",
       "59937  59937  I practice meditation. It has really helped me...  conspiracy   \n",
       "59942  59942  [For the First Time Ever, Temperatures Reached...  conspiracy   \n",
       "59970  59970  Well... scooter guy. 80s. Vancouver BC. Down t...  conspiracy   \n",
       "59988  59988  why is always the rudest people that are the d...  conspiracy   \n",
       "\n",
       "                                                    prep   new_comment  \n",
       "9                           httpsiimgurcomdudy num kljpg      is funny  \n",
       "23     music broken structure pointing structure kind...             .  \n",
       "24     bring bow hospital ive shot dad shoulder arrow...             .  \n",
       "45                  go gym eat healthy diet get sunlight             .  \n",
       "49     politician willing roast oh shit dont sound an...             .  \n",
       "...                                                  ...           ...  \n",
       "59931                                twitter comment smh             .  \n",
       "59937  practice meditation ha really helped control a...             .  \n",
       "59942  first time ever temperature reached num degree...  is conpiracy  \n",
       "59970            well scooter guy num vancouver bc num u  is conpiracy  \n",
       "59988  always rudest people dumbest nevermind im sure...             .  \n",
       "\n",
       "[9000 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_eng=df_feat_eng.append(train_conspiracy)\n",
    "df_feat_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "      <th>new_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I think prestige points should not expire ever...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>think prestige point expire ever skin buy avai...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Whats going to happen with them if they will b...</td>\n",
       "      <td>europe</td>\n",
       "      <td>whats going happen refused asilum appeal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Anecdotal evidence is anecdotal. Clearly by “e...</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>anecdotal evidence anecdotal clearly everyone ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Look dude, with all due respect, your music is...</td>\n",
       "      <td>Music</td>\n",
       "      <td>look dude due respect music isnt people look l...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hope he gets the doomhammer back!</td>\n",
       "      <td>wow</td>\n",
       "      <td>hope get doomhammer back</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>59995</td>\n",
       "      <td>Yo this guy Luka pretty good</td>\n",
       "      <td>nba</td>\n",
       "      <td>yo guy luka pretty good</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>59996</td>\n",
       "      <td>Unplug these things right now</td>\n",
       "      <td>funny</td>\n",
       "      <td>unplug thing right</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>59997</td>\n",
       "      <td>Well said. Do you think they’ll resonate with ...</td>\n",
       "      <td>movies</td>\n",
       "      <td>well said think theyll resonate future generat...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>59998</td>\n",
       "      <td>So we can impeach a president for lying? Pleas...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>impeach president lying please inform trump th...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>59999</td>\n",
       "      <td>Too broad dude, get ready for the shit my pant...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>broad dude get ready shit pant story</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment  \\\n",
       "0          0  I think prestige points should not expire ever...   \n",
       "1          1  Whats going to happen with them if they will b...   \n",
       "2          2  Anecdotal evidence is anecdotal. Clearly by “e...   \n",
       "3          3  Look dude, with all due respect, your music is...   \n",
       "4          4                  Hope he gets the doomhammer back!   \n",
       "...      ...                                                ...   \n",
       "59995  59995                       Yo this guy Luka pretty good   \n",
       "59996  59996                      Unplug these things right now   \n",
       "59997  59997  Well said. Do you think they’ll resonate with ...   \n",
       "59998  59998  So we can impeach a president for lying? Pleas...   \n",
       "59999  59999  Too broad dude, get ready for the shit my pant...   \n",
       "\n",
       "             subreddit                                               prep  \\\n",
       "0      leagueoflegends  think prestige point expire ever skin buy avai...   \n",
       "1               europe           whats going happen refused asilum appeal   \n",
       "2        gameofthrones  anecdotal evidence anecdotal clearly everyone ...   \n",
       "3                Music  look dude due respect music isnt people look l...   \n",
       "4                  wow                           hope get doomhammer back   \n",
       "...                ...                                                ...   \n",
       "59995              nba                            yo guy luka pretty good   \n",
       "59996            funny                                 unplug thing right   \n",
       "59997           movies  well said think theyll resonate future generat...   \n",
       "59998        worldnews  impeach president lying please inform trump th...   \n",
       "59999        AskReddit               broad dude get ready shit pant story   \n",
       "\n",
       "      new_comment  \n",
       "0                  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4                  \n",
       "...           ...  \n",
       "59995              \n",
       "59996           .  \n",
       "59997              \n",
       "59998              \n",
       "59999           .  \n",
       "\n",
       "[60000 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['new_comment']= df_feat_eng['new_comment']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train.new_comment=train.new_comment.fillna('')\n",
    "train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "      <th>new_comment</th>\n",
       "      <th>new_comment2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I think prestige points should not expire ever...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>think prestige point expire ever skin buy avai...</td>\n",
       "      <td></td>\n",
       "      <td>I think prestige points should not expire ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Whats going to happen with them if they will b...</td>\n",
       "      <td>europe</td>\n",
       "      <td>whats going happen refused asilum appeal</td>\n",
       "      <td></td>\n",
       "      <td>Whats going to happen with them if they will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Anecdotal evidence is anecdotal. Clearly by “e...</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>anecdotal evidence anecdotal clearly everyone ...</td>\n",
       "      <td></td>\n",
       "      <td>Anecdotal evidence is anecdotal. Clearly by “e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Look dude, with all due respect, your music is...</td>\n",
       "      <td>Music</td>\n",
       "      <td>look dude due respect music isnt people look l...</td>\n",
       "      <td></td>\n",
       "      <td>Look dude, with all due respect, your music is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hope he gets the doomhammer back!</td>\n",
       "      <td>wow</td>\n",
       "      <td>hope get doomhammer back</td>\n",
       "      <td></td>\n",
       "      <td>Hope he gets the doomhammer back!-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Trading for coaches has happened before</td>\n",
       "      <td>nfl</td>\n",
       "      <td>trading coach ha happened</td>\n",
       "      <td></td>\n",
       "      <td>Trading for coaches has happened before-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Considering what the kid has already seen, did...</td>\n",
       "      <td>movies</td>\n",
       "      <td>considering kid ha already seen didnt figure w...</td>\n",
       "      <td></td>\n",
       "      <td>Considering what the kid has already seen, did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Nah clearly it's Tom Bombadil</td>\n",
       "      <td>movies</td>\n",
       "      <td>nah clearly tom bombadil</td>\n",
       "      <td></td>\n",
       "      <td>Nah clearly it's Tom Bombadil-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Time to go play some Elite Dangerous in VR I t...</td>\n",
       "      <td>Music</td>\n",
       "      <td>time go play elite dangerous vr think thanks</td>\n",
       "      <td></td>\n",
       "      <td>Time to go play some Elite Dangerous in VR I t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>https://i.imgur.com/DUdy0KL.jpg</td>\n",
       "      <td>funny</td>\n",
       "      <td>httpsiimgurcomdudy num kljpg</td>\n",
       "      <td>is funny</td>\n",
       "      <td>https://i.imgur.com/DUdy0KL.jpg-is funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Does he know he’s a treasonous scumbag, and do...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>doe know treasonous scumbag doesnt care jenius...</td>\n",
       "      <td></td>\n",
       "      <td>Does he know he’s a treasonous scumbag, and do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Is it really that far fetched? It actually mak...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>really far fetched actually make perfect sense...</td>\n",
       "      <td>is conpiracy</td>\n",
       "      <td>Is it really that far fetched? It actually mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>O yeah of course I agree with that. Im speakin...</td>\n",
       "      <td>hockey</td>\n",
       "      <td>yeah course agree im speaking margin someone p...</td>\n",
       "      <td></td>\n",
       "      <td>O yeah of course I agree with that. Im speakin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Was going to say, this is a fallacy. A Spaniar...</td>\n",
       "      <td>europe</td>\n",
       "      <td>wa going say fallacy spaniard asked language s...</td>\n",
       "      <td></td>\n",
       "      <td>Was going to say, this is a fallacy. A Spaniar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Do you believe in ancestral spirit? Maybe this...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>believe ancestral spirit maybe synchronicity h...</td>\n",
       "      <td>.</td>\n",
       "      <td>Do you believe in ancestral spirit? Maybe this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>The JFK assassination.</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>jfk assassination</td>\n",
       "      <td>.</td>\n",
       "      <td>The JFK assassination.-.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>I love alcohol, and by no means want to comple...</td>\n",
       "      <td>trees</td>\n",
       "      <td>love alcohol mean want completely stop drinkin...</td>\n",
       "      <td></td>\n",
       "      <td>I love alcohol, and by no means want to comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Right at this moment they’re at worst the thir...</td>\n",
       "      <td>nba</td>\n",
       "      <td>right moment theyre worst third best team nba ...</td>\n",
       "      <td></td>\n",
       "      <td>Right at this moment they’re at worst the thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Greek here. Possibly the wording of the questi...</td>\n",
       "      <td>europe</td>\n",
       "      <td>greek possibly wording question culture civili...</td>\n",
       "      <td></td>\n",
       "      <td>Greek here. Possibly the wording of the questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Religion poisons everything</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>religion poison everything</td>\n",
       "      <td></td>\n",
       "      <td>Religion poisons everything-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>https://youtu.be/zQJcfkDjhRg</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>httpsyoutubezqjcfkdjhrg</td>\n",
       "      <td>is AskReddit</td>\n",
       "      <td>https://youtu.be/zQJcfkDjhRg-is AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>It's good that you're trying to change your me...</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "      <td>good youre trying change mentality suggestion ...</td>\n",
       "      <td></td>\n",
       "      <td>It's good that you're trying to change your me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>I starting singing it in my head right as you ...</td>\n",
       "      <td>Overwatch</td>\n",
       "      <td>starting singing head right started falling</td>\n",
       "      <td></td>\n",
       "      <td>I starting singing it in my head right as you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>All music can broken down to structures. Point...</td>\n",
       "      <td>funny</td>\n",
       "      <td>music broken structure pointing structure kind...</td>\n",
       "      <td>.</td>\n",
       "      <td>All music can broken down to structures. Point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>I too bring my bow into the hospital after I’v...</td>\n",
       "      <td>funny</td>\n",
       "      <td>bring bow hospital ive shot dad shoulder arrow...</td>\n",
       "      <td>.</td>\n",
       "      <td>I too bring my bow into the hospital after I’v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>op flexing his “let’s see how many things i ca...</td>\n",
       "      <td>europe</td>\n",
       "      <td>op flexing let see many thing steal muscle</td>\n",
       "      <td></td>\n",
       "      <td>op flexing his “let’s see how many things i ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>This is the internet, we can say *shit* on here.</td>\n",
       "      <td>Music</td>\n",
       "      <td>internet say shit</td>\n",
       "      <td></td>\n",
       "      <td>This is the internet, we can say *shit* on here.-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Just like you lot were meant to aye?</td>\n",
       "      <td>soccer</td>\n",
       "      <td>like lot meant aye</td>\n",
       "      <td></td>\n",
       "      <td>Just like you lot were meant to aye?-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Thanks for the clarification</td>\n",
       "      <td>Overwatch</td>\n",
       "      <td>thanks clarification</td>\n",
       "      <td></td>\n",
       "      <td>Thanks for the clarification-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Greinke is going to get shelled</td>\n",
       "      <td>baseball</td>\n",
       "      <td>greinke going get shelled</td>\n",
       "      <td></td>\n",
       "      <td>Greinke is going to get shelled-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Is... is that an alien inside of your piece? I...</td>\n",
       "      <td>trees</td>\n",
       "      <td>alien inside piece manage snag dire need run a...</td>\n",
       "      <td></td>\n",
       "      <td>Is... is that an alien inside of your piece? I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>I see what you mean. I genuinely think he *is ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>see mean genuinely think trying really really bad</td>\n",
       "      <td></td>\n",
       "      <td>I see what you mean. I genuinely think he *is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>I appreciate that, really.</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>appreciate really</td>\n",
       "      <td></td>\n",
       "      <td>I appreciate that, really.-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Only reason anyone even remembers Marth and Ik...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>reason anyone even remembers marth ike cause s...</td>\n",
       "      <td></td>\n",
       "      <td>Only reason anyone even remembers Marth and Ik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Oh we're doing it right now</td>\n",
       "      <td>baseball</td>\n",
       "      <td>oh right</td>\n",
       "      <td></td>\n",
       "      <td>Oh we're doing it right now-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Yes. But it’s not just stems in the bowl, you ...</td>\n",
       "      <td>trees</td>\n",
       "      <td>yes stem bowl add grinder weed well like someo...</td>\n",
       "      <td></td>\n",
       "      <td>Yes. But it’s not just stems in the bowl, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>God what a shitty character. Seriously I know ...</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>god shitty character seriously know standard h...</td>\n",
       "      <td></td>\n",
       "      <td>God what a shitty character. Seriously I know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>&amp;gt; video starts at 19:39 \\n\\nThat...I just.....</td>\n",
       "      <td>anime</td>\n",
       "      <td>gt video start num thati justaccidentally clic...</td>\n",
       "      <td></td>\n",
       "      <td>&amp;gt; video starts at 19:39 \\n\\nThat...I just.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Damn, why is Halloween a 4/10?</td>\n",
       "      <td>movies</td>\n",
       "      <td>damn halloween num</td>\n",
       "      <td></td>\n",
       "      <td>Damn, why is Halloween a 4/10?-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>So what the fuck happens if they suck get a lo...</td>\n",
       "      <td>nba</td>\n",
       "      <td>fuck happens suck get low draft pick pick star...</td>\n",
       "      <td></td>\n",
       "      <td>So what the fuck happens if they suck get a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>BABY SHARKS ARE ON THE ATTACK! Woooo LETS GO N...</td>\n",
       "      <td>baseball</td>\n",
       "      <td>baby shark attack woooo let go nats</td>\n",
       "      <td></td>\n",
       "      <td>BABY SHARKS ARE ON THE ATTACK! Woooo LETS GO N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>That assumption one is doing a lot of work. Ea...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>assumption one lot work earth need unique form...</td>\n",
       "      <td>is AskReddit</td>\n",
       "      <td>That assumption one is doing a lot of work. Ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>~~Make sure you apply some lube beforehand~~</td>\n",
       "      <td>anime</td>\n",
       "      <td>make sure apply lube beforehand</td>\n",
       "      <td></td>\n",
       "      <td>~~Make sure you apply some lube beforehand~~-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>Aw yea. Kumerow all over me</td>\n",
       "      <td>nfl</td>\n",
       "      <td>aw yea kumerow</td>\n",
       "      <td></td>\n",
       "      <td>Aw yea. Kumerow all over me-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>Ref is gonna need a battery change on his mic ...</td>\n",
       "      <td>nfl</td>\n",
       "      <td>ref gonna need battery change mic</td>\n",
       "      <td></td>\n",
       "      <td>Ref is gonna need a battery change on his mic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Go to the gym and eat a healthy diet. \\n\\nAnd ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>go gym eat healthy diet get sunlight</td>\n",
       "      <td>.</td>\n",
       "      <td>Go to the gym and eat a healthy diet. \\n\\nAnd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>I dont doubt it brother.</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "      <td>dont doubt brother</td>\n",
       "      <td></td>\n",
       "      <td>I dont doubt it brother.-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>Yes it was. Which I always found confusing, co...</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>yes wa always found confusing considering wore...</td>\n",
       "      <td>.</td>\n",
       "      <td>Yes it was. Which I always found confusing, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Just like the Netherlands</td>\n",
       "      <td>europe</td>\n",
       "      <td>like netherlands</td>\n",
       "      <td></td>\n",
       "      <td>Just like the Netherlands-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>Politicians too. Willing to roast each other, ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>politician willing roast oh shit dont sound an...</td>\n",
       "      <td>.</td>\n",
       "      <td>Politicians too. Willing to roast each other, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                            comment        subreddit  \\\n",
       "0    0  I think prestige points should not expire ever...  leagueoflegends   \n",
       "1    1  Whats going to happen with them if they will b...           europe   \n",
       "2    2  Anecdotal evidence is anecdotal. Clearly by “e...    gameofthrones   \n",
       "3    3  Look dude, with all due respect, your music is...            Music   \n",
       "4    4                  Hope he gets the doomhammer back!              wow   \n",
       "5    5            Trading for coaches has happened before              nfl   \n",
       "6    6  Considering what the kid has already seen, did...           movies   \n",
       "7    7                      Nah clearly it's Tom Bombadil           movies   \n",
       "8    8  Time to go play some Elite Dangerous in VR I t...            Music   \n",
       "9    9                    https://i.imgur.com/DUdy0KL.jpg            funny   \n",
       "10  10  Does he know he’s a treasonous scumbag, and do...        worldnews   \n",
       "11  11  Is it really that far fetched? It actually mak...       conspiracy   \n",
       "12  12  O yeah of course I agree with that. Im speakin...           hockey   \n",
       "13  13  Was going to say, this is a fallacy. A Spaniar...           europe   \n",
       "14  14  Do you believe in ancestral spirit? Maybe this...       conspiracy   \n",
       "15  15                             The JFK assassination.       conspiracy   \n",
       "16  16  I love alcohol, and by no means want to comple...            trees   \n",
       "17  17  Right at this moment they’re at worst the thir...              nba   \n",
       "18  18  Greek here. Possibly the wording of the questi...           europe   \n",
       "19  19                        Religion poisons everything        worldnews   \n",
       "20  20                       https://youtu.be/zQJcfkDjhRg        AskReddit   \n",
       "21  21  It's good that you're trying to change your me...  GlobalOffensive   \n",
       "22  22  I starting singing it in my head right as you ...        Overwatch   \n",
       "23  23  All music can broken down to structures. Point...            funny   \n",
       "24  24  I too bring my bow into the hospital after I’v...            funny   \n",
       "25  25  op flexing his “let’s see how many things i ca...           europe   \n",
       "26  26   This is the internet, we can say *shit* on here.            Music   \n",
       "27  27               Just like you lot were meant to aye?           soccer   \n",
       "28  28                       Thanks for the clarification        Overwatch   \n",
       "29  29                    Greinke is going to get shelled         baseball   \n",
       "30  30  Is... is that an alien inside of your piece? I...            trees   \n",
       "31  31  I see what you mean. I genuinely think he *is ...        worldnews   \n",
       "32  32                         I appreciate that, really.    gameofthrones   \n",
       "33  33  Only reason anyone even remembers Marth and Ik...  leagueoflegends   \n",
       "34  34                        Oh we're doing it right now         baseball   \n",
       "35  35  Yes. But it’s not just stems in the bowl, you ...            trees   \n",
       "36  36  God what a shitty character. Seriously I know ...    gameofthrones   \n",
       "37  37  &gt; video starts at 19:39 \\n\\nThat...I just.....            anime   \n",
       "38  38                     Damn, why is Halloween a 4/10?           movies   \n",
       "39  39  So what the fuck happens if they suck get a lo...              nba   \n",
       "40  40  BABY SHARKS ARE ON THE ATTACK! Woooo LETS GO N...         baseball   \n",
       "41  41  That assumption one is doing a lot of work. Ea...        AskReddit   \n",
       "42  42       ~~Make sure you apply some lube beforehand~~            anime   \n",
       "43  43                        Aw yea. Kumerow all over me              nfl   \n",
       "44  44  Ref is gonna need a battery change on his mic ...              nfl   \n",
       "45  45  Go to the gym and eat a healthy diet. \\n\\nAnd ...            funny   \n",
       "46  46                           I dont doubt it brother.  GlobalOffensive   \n",
       "47  47  Yes it was. Which I always found confusing, co...       conspiracy   \n",
       "48  48                          Just like the Netherlands           europe   \n",
       "49  49  Politicians too. Willing to roast each other, ...            funny   \n",
       "\n",
       "                                                 prep   new_comment  \\\n",
       "0   think prestige point expire ever skin buy avai...                 \n",
       "1            whats going happen refused asilum appeal                 \n",
       "2   anecdotal evidence anecdotal clearly everyone ...                 \n",
       "3   look dude due respect music isnt people look l...                 \n",
       "4                            hope get doomhammer back                 \n",
       "5                           trading coach ha happened                 \n",
       "6   considering kid ha already seen didnt figure w...                 \n",
       "7                            nah clearly tom bombadil                 \n",
       "8        time go play elite dangerous vr think thanks                 \n",
       "9                        httpsiimgurcomdudy num kljpg      is funny   \n",
       "10  doe know treasonous scumbag doesnt care jenius...                 \n",
       "11  really far fetched actually make perfect sense...  is conpiracy   \n",
       "12  yeah course agree im speaking margin someone p...                 \n",
       "13  wa going say fallacy spaniard asked language s...                 \n",
       "14  believe ancestral spirit maybe synchronicity h...             .   \n",
       "15                                  jfk assassination             .   \n",
       "16  love alcohol mean want completely stop drinkin...                 \n",
       "17  right moment theyre worst third best team nba ...                 \n",
       "18  greek possibly wording question culture civili...                 \n",
       "19                         religion poison everything                 \n",
       "20                            httpsyoutubezqjcfkdjhrg  is AskReddit   \n",
       "21  good youre trying change mentality suggestion ...                 \n",
       "22        starting singing head right started falling                 \n",
       "23  music broken structure pointing structure kind...             .   \n",
       "24  bring bow hospital ive shot dad shoulder arrow...             .   \n",
       "25         op flexing let see many thing steal muscle                 \n",
       "26                                  internet say shit                 \n",
       "27                                 like lot meant aye                 \n",
       "28                               thanks clarification                 \n",
       "29                          greinke going get shelled                 \n",
       "30  alien inside piece manage snag dire need run a...                 \n",
       "31  see mean genuinely think trying really really bad                 \n",
       "32                                  appreciate really                 \n",
       "33  reason anyone even remembers marth ike cause s...                 \n",
       "34                                           oh right                 \n",
       "35  yes stem bowl add grinder weed well like someo...                 \n",
       "36  god shitty character seriously know standard h...                 \n",
       "37  gt video start num thati justaccidentally clic...                 \n",
       "38                                 damn halloween num                 \n",
       "39  fuck happens suck get low draft pick pick star...                 \n",
       "40                baby shark attack woooo let go nats                 \n",
       "41  assumption one lot work earth need unique form...  is AskReddit   \n",
       "42                    make sure apply lube beforehand                 \n",
       "43                                     aw yea kumerow                 \n",
       "44                  ref gonna need battery change mic                 \n",
       "45               go gym eat healthy diet get sunlight             .   \n",
       "46                                 dont doubt brother                 \n",
       "47  yes wa always found confusing considering wore...             .   \n",
       "48                                   like netherlands                 \n",
       "49  politician willing roast oh shit dont sound an...             .   \n",
       "\n",
       "                                         new_comment2  \n",
       "0   I think prestige points should not expire ever...  \n",
       "1   Whats going to happen with them if they will b...  \n",
       "2   Anecdotal evidence is anecdotal. Clearly by “e...  \n",
       "3   Look dude, with all due respect, your music is...  \n",
       "4                  Hope he gets the doomhammer back!-  \n",
       "5            Trading for coaches has happened before-  \n",
       "6   Considering what the kid has already seen, did...  \n",
       "7                      Nah clearly it's Tom Bombadil-  \n",
       "8   Time to go play some Elite Dangerous in VR I t...  \n",
       "9            https://i.imgur.com/DUdy0KL.jpg-is funny  \n",
       "10  Does he know he’s a treasonous scumbag, and do...  \n",
       "11  Is it really that far fetched? It actually mak...  \n",
       "12  O yeah of course I agree with that. Im speakin...  \n",
       "13  Was going to say, this is a fallacy. A Spaniar...  \n",
       "14  Do you believe in ancestral spirit? Maybe this...  \n",
       "15                           The JFK assassination.-.  \n",
       "16  I love alcohol, and by no means want to comple...  \n",
       "17  Right at this moment they’re at worst the thir...  \n",
       "18  Greek here. Possibly the wording of the questi...  \n",
       "19                       Religion poisons everything-  \n",
       "20          https://youtu.be/zQJcfkDjhRg-is AskReddit  \n",
       "21  It's good that you're trying to change your me...  \n",
       "22  I starting singing it in my head right as you ...  \n",
       "23  All music can broken down to structures. Point...  \n",
       "24  I too bring my bow into the hospital after I’v...  \n",
       "25  op flexing his “let’s see how many things i ca...  \n",
       "26  This is the internet, we can say *shit* on here.-  \n",
       "27              Just like you lot were meant to aye?-  \n",
       "28                      Thanks for the clarification-  \n",
       "29                   Greinke is going to get shelled-  \n",
       "30  Is... is that an alien inside of your piece? I...  \n",
       "31  I see what you mean. I genuinely think he *is ...  \n",
       "32                        I appreciate that, really.-  \n",
       "33  Only reason anyone even remembers Marth and Ik...  \n",
       "34                       Oh we're doing it right now-  \n",
       "35  Yes. But it’s not just stems in the bowl, you ...  \n",
       "36  God what a shitty character. Seriously I know ...  \n",
       "37  &gt; video starts at 19:39 \\n\\nThat...I just.....  \n",
       "38                    Damn, why is Halloween a 4/10?-  \n",
       "39  So what the fuck happens if they suck get a lo...  \n",
       "40  BABY SHARKS ARE ON THE ATTACK! Woooo LETS GO N...  \n",
       "41  That assumption one is doing a lot of work. Ea...  \n",
       "42      ~~Make sure you apply some lube beforehand~~-  \n",
       "43                       Aw yea. Kumerow all over me-  \n",
       "44  Ref is gonna need a battery change on his mic ...  \n",
       "45  Go to the gym and eat a healthy diet. \\n\\nAnd ...  \n",
       "46                          I dont doubt it brother.-  \n",
       "47  Yes it was. Which I always found confusing, co...  \n",
       "48                         Just like the Netherlands-  \n",
       "49  Politicians too. Willing to roast each other, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['new_comment2']=train['comment']+'-'+train['new_comment']\n",
    "train[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        I think prestige points should not expire ever...\n",
       "1        Whats going to happen with them if they will b...\n",
       "2        Anecdotal evidence is anecdotal. Clearly by “e...\n",
       "3        Look dude, with all due respect, your music is...\n",
       "4                       Hope he gets the doomhammer back!-\n",
       "                               ...                        \n",
       "59995                        Yo this guy Luka pretty good-\n",
       "59996                      Unplug these things right now-.\n",
       "59997    Well said. Do you think they’ll resonate with ...\n",
       "59998    So we can impeach a president for lying? Pleas...\n",
       "59999    Too broad dude, get ready for the shit my pant...\n",
       "Name: new_comment2, Length: 60000, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "features=train['new_comment2']\n",
    "target = train['subreddit']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>prep</th>\n",
       "      <th>new_comment</th>\n",
       "      <th>new_comment2</th>\n",
       "      <th>new_comment2_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I think prestige points should not expire ever...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>think prestige point expire ever skin buy avai...</td>\n",
       "      <td></td>\n",
       "      <td>I think prestige points should not expire ever...</td>\n",
       "      <td>think prestige point expire ever skin buy avai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Whats going to happen with them if they will b...</td>\n",
       "      <td>europe</td>\n",
       "      <td>whats going happen refused asilum appeal</td>\n",
       "      <td></td>\n",
       "      <td>Whats going to happen with them if they will b...</td>\n",
       "      <td>whats going happen refused asilum appeal-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Anecdotal evidence is anecdotal. Clearly by “e...</td>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>anecdotal evidence anecdotal clearly everyone ...</td>\n",
       "      <td></td>\n",
       "      <td>Anecdotal evidence is anecdotal. Clearly by “e...</td>\n",
       "      <td>anecdotal evidence anecdotal clearly everyone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Look dude, with all due respect, your music is...</td>\n",
       "      <td>Music</td>\n",
       "      <td>look dude due respect music isnt people look l...</td>\n",
       "      <td></td>\n",
       "      <td>Look dude, with all due respect, your music is...</td>\n",
       "      <td>look dude due respect music isnt people look l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hope he gets the doomhammer back!</td>\n",
       "      <td>wow</td>\n",
       "      <td>hope get doomhammer back</td>\n",
       "      <td></td>\n",
       "      <td>Hope he gets the doomhammer back!-</td>\n",
       "      <td>hope get doomhammer back-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>59995</td>\n",
       "      <td>Yo this guy Luka pretty good</td>\n",
       "      <td>nba</td>\n",
       "      <td>yo guy luka pretty good</td>\n",
       "      <td></td>\n",
       "      <td>Yo this guy Luka pretty good-</td>\n",
       "      <td>yo guy luka pretty good-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>59996</td>\n",
       "      <td>Unplug these things right now</td>\n",
       "      <td>funny</td>\n",
       "      <td>unplug thing right</td>\n",
       "      <td>.</td>\n",
       "      <td>Unplug these things right now-.</td>\n",
       "      <td>unplug thing right-.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>59997</td>\n",
       "      <td>Well said. Do you think they’ll resonate with ...</td>\n",
       "      <td>movies</td>\n",
       "      <td>well said think theyll resonate future generat...</td>\n",
       "      <td></td>\n",
       "      <td>Well said. Do you think they’ll resonate with ...</td>\n",
       "      <td>well said think theyll resonate future generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>59998</td>\n",
       "      <td>So we can impeach a president for lying? Pleas...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>impeach president lying please inform trump th...</td>\n",
       "      <td></td>\n",
       "      <td>So we can impeach a president for lying? Pleas...</td>\n",
       "      <td>impeach president lying please inform trump th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>59999</td>\n",
       "      <td>Too broad dude, get ready for the shit my pant...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>broad dude get ready shit pant story</td>\n",
       "      <td>.</td>\n",
       "      <td>Too broad dude, get ready for the shit my pant...</td>\n",
       "      <td>broad dude get ready shit pant story-.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment  \\\n",
       "0          0  I think prestige points should not expire ever...   \n",
       "1          1  Whats going to happen with them if they will b...   \n",
       "2          2  Anecdotal evidence is anecdotal. Clearly by “e...   \n",
       "3          3  Look dude, with all due respect, your music is...   \n",
       "4          4                  Hope he gets the doomhammer back!   \n",
       "...      ...                                                ...   \n",
       "59995  59995                       Yo this guy Luka pretty good   \n",
       "59996  59996                      Unplug these things right now   \n",
       "59997  59997  Well said. Do you think they’ll resonate with ...   \n",
       "59998  59998  So we can impeach a president for lying? Pleas...   \n",
       "59999  59999  Too broad dude, get ready for the shit my pant...   \n",
       "\n",
       "             subreddit                                               prep  \\\n",
       "0      leagueoflegends  think prestige point expire ever skin buy avai...   \n",
       "1               europe           whats going happen refused asilum appeal   \n",
       "2        gameofthrones  anecdotal evidence anecdotal clearly everyone ...   \n",
       "3                Music  look dude due respect music isnt people look l...   \n",
       "4                  wow                           hope get doomhammer back   \n",
       "...                ...                                                ...   \n",
       "59995              nba                            yo guy luka pretty good   \n",
       "59996            funny                                 unplug thing right   \n",
       "59997           movies  well said think theyll resonate future generat...   \n",
       "59998        worldnews  impeach president lying please inform trump th...   \n",
       "59999        AskReddit               broad dude get ready shit pant story   \n",
       "\n",
       "      new_comment                                       new_comment2  \\\n",
       "0                  I think prestige points should not expire ever...   \n",
       "1                  Whats going to happen with them if they will b...   \n",
       "2                  Anecdotal evidence is anecdotal. Clearly by “e...   \n",
       "3                  Look dude, with all due respect, your music is...   \n",
       "4                                 Hope he gets the doomhammer back!-   \n",
       "...           ...                                                ...   \n",
       "59995                                  Yo this guy Luka pretty good-   \n",
       "59996           .                    Unplug these things right now-.   \n",
       "59997              Well said. Do you think they’ll resonate with ...   \n",
       "59998              So we can impeach a president for lying? Pleas...   \n",
       "59999           .  Too broad dude, get ready for the shit my pant...   \n",
       "\n",
       "                                       new_comment2_prep  \n",
       "0      think prestige point expire ever skin buy avai...  \n",
       "1              whats going happen refused asilum appeal-  \n",
       "2      anecdotal evidence anecdotal clearly everyone ...  \n",
       "3      look dude due respect music isnt people look l...  \n",
       "4                              hope get doomhammer back-  \n",
       "...                                                  ...  \n",
       "59995                           yo guy luka pretty good-  \n",
       "59996                               unplug thing right-.  \n",
       "59997  well said think theyll resonate future generat...  \n",
       "59998  impeach president lying please inform trump th...  \n",
       "59999             broad dude get ready shit pant story-.  \n",
       "\n",
       "[60000 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['new_comment2_prep']=train['prep']+'-'+train['new_comment']\n",
    "features_prep=train['new_comment2_prep']\n",
    "target = train['subreddit']\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<60000x58896 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1367111 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5286500000000001\n",
      "{'mean_fit_time': array([ 8.68239546, 63.82216992,  8.21497512, 71.07705617,  7.30583596,\n",
      "       65.04690614,  6.76906452, 60.44162979,  6.34766388, 43.6112803 ]), 'std_fit_time': array([ 0.48121734,  2.26974939,  0.34644865,  3.11993462,  0.7473942 ,\n",
      "        3.51532505,  0.30797966,  6.6746805 ,  0.65427454, 12.48336149]), 'mean_score_time': array([0.        , 2.1289463 , 0.        , 1.67688828, 0.        ,\n",
      "       1.48496294, 0.        , 1.47402387, 0.        , 0.59752498]), 'std_score_time': array([0.        , 0.14758079, 0.        , 0.13349226, 0.        ,\n",
      "       0.18959255, 0.        , 0.21922945, 0.        , 0.1612728 ]), 'param_clf__penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
      "                   'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf__loss': masked_array(data=['hinge', 'squared_hinge', 'hinge', 'squared_hinge',\n",
      "                   'hinge', 'squared_hinge', 'hinge', 'squared_hinge',\n",
      "                   'hinge', 'squared_hinge'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf__C': masked_array(data=[0.1, 0.1, 0.575, 0.575, 1.05, 1.05, 1.525, 1.525, 2.0,\n",
      "                   2.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf__penalty': 'l2', 'clf__loss': 'hinge', 'clf__C': 0.1}, {'clf__penalty': 'l2', 'clf__loss': 'squared_hinge', 'clf__C': 0.1}, {'clf__penalty': 'l2', 'clf__loss': 'hinge', 'clf__C': 0.575}, {'clf__penalty': 'l2', 'clf__loss': 'squared_hinge', 'clf__C': 0.575}, {'clf__penalty': 'l2', 'clf__loss': 'hinge', 'clf__C': 1.05}, {'clf__penalty': 'l2', 'clf__loss': 'squared_hinge', 'clf__C': 1.05}, {'clf__penalty': 'l2', 'clf__loss': 'hinge', 'clf__C': 1.525}, {'clf__penalty': 'l2', 'clf__loss': 'squared_hinge', 'clf__C': 1.525}, {'clf__penalty': 'l2', 'clf__loss': 'hinge', 'clf__C': 2.0}, {'clf__penalty': 'l2', 'clf__loss': 'squared_hinge', 'clf__C': 2.0}], 'split0_test_score': array([       nan, 0.5295    ,        nan, 0.53033333,        nan,\n",
      "       0.52133333,        nan, 0.51333333,        nan, 0.507     ]), 'split1_test_score': array([       nan, 0.52233333,        nan, 0.52258333,        nan,\n",
      "       0.51458333,        nan, 0.50808333,        nan, 0.50291667]), 'split2_test_score': array([       nan, 0.52825   ,        nan, 0.52833333,        nan,\n",
      "       0.51916667,        nan, 0.51375   ,        nan, 0.50675   ]), 'split3_test_score': array([       nan, 0.53708333,        nan, 0.53708333,        nan,\n",
      "       0.52933333,        nan, 0.52208333,        nan, 0.51775   ]), 'split4_test_score': array([       nan, 0.52508333,        nan, 0.52491667,        nan,\n",
      "       0.51833333,        nan, 0.51141667,        nan, 0.5055    ]), 'mean_test_score': array([       nan, 0.52845   ,        nan, 0.52865   ,        nan,\n",
      "       0.52055   ,        nan, 0.51373333,        nan, 0.50798333]), 'std_test_score': array([       nan, 0.00498849,        nan, 0.00499594,        nan,\n",
      "       0.00490283,        nan, 0.00462973,        nan, 0.00509341]), 'rank_test_score': array([ 6,  2,  7,  1,  8,  3,  9,  4, 10,  5], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Try TextBlob\n",
    "def textblob_tokenizer(str_input):\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    words = [token.stem() for token in tokens]\n",
    "    return words\n",
    "\n",
    "# Try NLTK's PorterStemmer\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "\n",
    "param_dist = { 'clf__penalty': ['l2'],\n",
    "              'clf__loss' : ['hinge', 'squared_hinge'],\n",
    "              'clf__C' : np.linspace(0.1,2,5),}\n",
    "\n",
    "\n",
    "pipeline_LinearSVC = Pipeline([\n",
    "                    #('vect', CountVectorizer(tokenizer = stemming_tokenizer)),\n",
    "\n",
    "                     ('vect', CountVectorizer()),#tokenizer = textblob_tokenizer)),#ngram_range=(1,2), min_df = 10, max_df = 1.)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('norm', Normalizer()),\n",
    "                     ('clf', LinearSVC(C=1.0, penalty='l2', max_iter=3000, dual=False,random_state=0))#LinearSVC(random_state=0))\n",
    "])\n",
    "\n",
    "  #  ('vect', feature_extraction.text.CountVectorizer(tokenizer = textblob_tokenizer))\n",
    "    #\n",
    "\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline_LinearSVC, param_dist, n_jobs=-1, verbose=1, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, target)\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "              \n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.cv_results_)\n",
    "\n",
    "#previsoes_test_pre_proc=grid_search.predict(test['comment'])\n",
    "\n",
    "#0.4337\n",
    "\n",
    "\n",
    "#com mew_comment2_prep sem grid 0.4720833333333333\n",
    "\n",
    "\n",
    "#com mew_comment2_prep com grid 0.0.48285\n",
    "\n",
    "#feature e grid 0.5216\n",
    "\n",
    "#feature_prep e grid 0.5206166666666667\n",
    "\n",
    "#feature_prep e grid l1 l2 \n",
    "\n",
    "\n",
    "#0.5359833333333334\n",
    "#0.5359833333333334\n",
    "\n",
    "#bruto cv3 0.5495833333333334\n",
    "\n",
    "#prep cv3 0.5488333333333334\n",
    "\n",
    "\n",
    "\n",
    "#bruto cv10 0.56965\n",
    "\n",
    "#prep cv10 0.5662833333333332\n",
    "\n",
    "#bruto cv5 0.5638666666666667\n",
    "\n",
    "#prep cv5 0.5609333333333334\n",
    "\n",
    "\n",
    "#muitas regras = overfit\n",
    "\n",
    "#bruto  textblob cv5 0.6045833333333335\n",
    "\n",
    "#bruto steeming cv5 0.5988166666666667\n",
    "\n",
    "#('vect', CountVectorizer(tokenizer = textblob_tokenizer,ngram_range=(1,2), min_df = 10, max_df = 1.)), = >0.5636\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "#com menos regras para funny conspiracy e AskReddit e textblob    0.52955\n",
    "\n",
    "#com menos regras para funny conspiracy e AskReddit e features_prep 0.5208166666666667\n",
    "\n",
    "\n",
    "#com menos regras para funny conspiracy e AskReddit e textblob features_prep 0.5234666666666665 \n",
    "\n",
    "#com menos regras para funny conspiracy e AskReddit  features_prep  0.5208166666666667\n",
    "\n",
    "\n",
    "#com menos regras para funny conspiracy e AskReddit  features    0.5286500000000001\n",
    "\n",
    "\n",
    "#text blob nao vale a pena\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### features_prep vai com test_prep\n",
    "\n",
    "features vai com test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 1124.24 seconds for 5 candidates parameter settings.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-5c1469449d13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m print(\"GridSearchCV took %.2f seconds for %d candidates\"\n\u001b[1;32m     25\u001b[0m       \" parameter settings.\" % ((time.time() - start_time), len(random_search.cv_results_['params'])))\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "def report(results, top=3):\n",
    "    for i in range(1, top+1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "#Logistic Regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm=Normalizer()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "\n",
    "param_dist = {'clf__penalty': ['l2'],\n",
    "              'clf__solver': ['liblinear'],\n",
    "              'clf__C': np.linspace(0.1,5,5)}\n",
    "clf = LogisticRegression(multi_class='auto')\n",
    "text_clf = Pipeline([('vect',CountVectorizer(stop_words='english', ngram_range=(1,2), min_df = 10, max_df = 1.)),('tfidf',TfidfTransformer()),('clf',clf)])\n",
    "random_search = GridSearchCV(text_clf, param_grid = param_dist, cv=10)\n",
    "start_time = time.time()\n",
    "random_search.fit(features, target)\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start_time), len(random_search.cv_results_['params'])))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, top=3):\n",
    "    for i in range(1, top+1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.487 (std: 0.008)\n",
      "Parameters: {'clf__C': 1.3250000000000002, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.485 (std: 0.007)\n",
      "Parameters: {'clf__C': 2.5500000000000003, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.483 (std: 0.007)\n",
      "Parameters: {'clf__C': 3.7750000000000004, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I think prestige points should not expire ever...\n",
       "1    Whats going to happen with them if they will b...\n",
       "2    Anecdotal evidence is anecdotal. Clearly by “e...\n",
       "3    Look dude, with all due respect, your music is...\n",
       "4                   Hope he gets the doomhammer back!-\n",
       "5             Trading for coaches has happened before-\n",
       "6    Considering what the kid has already seen, did...\n",
       "7                       Nah clearly it's Tom Bombadil-\n",
       "8    Time to go play some Elite Dangerous in VR I t...\n",
       "9             https://i.imgur.com/DUdy0KL.jpg-is funny\n",
       "Name: new_comment2, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "pipeline_LinearSVC = Pipeline([\n",
    "                    #('vect', CountVectorizer(tokenizer = stemming_tokenizer)),\n",
    "\n",
    "                     ('vect', CountVectorizer()),#tokenizer = textblob_tokenizer)),#ngram_range=(1,2), min_df = 10, max_df = 1.)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('norm', Normalizer()),\n",
    "                     ('clf', LinearSVC(dual=False,random_state=0))#LinearSVC(random_state=0))\n",
    "])\n",
    "\n",
    "  #  ('vect', feature_extraction.text.CountVectorizer(tokenizer = textblob_tokenizer))\n",
    "    #\n",
    "\n",
    "\n",
    "#grid_search = RandomizedSearchCV(pipeline_LinearSVC,{}, n_jobs=-1, verbose=1, cv=5, scoring='accuracy')\n",
    "#grid_search.fit(features, target)\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "              \n",
    "#print(grid_search.best_score_)\n",
    "#print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "previsores_train, previsores_valid, classe_train, classe_valid = train_test_split(features, target, test_size=0.20, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.012812531980490881, 0.9991364637917304, 'ovr', 1129] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 28.3240\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.03967680774631958, 0.5849350606030214, 'ovr', 3962] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 30.2748\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.022957798415261185, 0.5809725180523154, 'crammer_singer', 4049] \n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 28.5527\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.07783894579472973, 0.7443734643715278, 'crammer_singer', 3877] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 27.7885\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.0894606768897184, 0.17653979023280014, 'ovr', 1431] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 28.0000\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.05930659252325387, 0.704488687679921, 'ovr', 1515] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 26.1421\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.0686501241180656, 0.8511631047076357, 'ovr', 2321] \n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 27.6469\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.029849599625775, 0.5015210554774955, 'ovr', 4737] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 25.4256\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.029361485475953117, 0.3589978047277139, 'ovr', 3981] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 26.7013\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.09104484713447199, 0.36903710098874454, 'crammer_singer', 4159] \n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 23.7549\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.058930594759774746, 0.7297825240188381, 'ovr', 1695] \n",
      "\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 23.7207\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.054060096822313525, 0.788936593996784, 'ovr', 1469] \n",
      "\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 25.9218\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.05865554539469525, 0.9130617237590952, 'ovr', 4404] \n",
      "\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 23.9404\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.05384251558552909, 0.687068993857188, 'ovr', 4580] \n",
      "\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 23.6806\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.08833062078997188, 0.6613049863500481, 'crammer_singer', 2738] \n",
      "\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 25.1303\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.07527886003872512, 0.89320764667061, 'ovr', 1883] \n",
      "\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 26.2460\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.09494893092178128, 0.5049209201319466, 'crammer_singer', 2874] \n",
      "\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 26.3392\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.07715952264493699, 0.37122444586890413, 'crammer_singer', 3218] \n",
      "\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 29.0755\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.08859422133686753, 0.42154278400224987, 'crammer_singer', 2876] \n",
      "\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 30.1234\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.08316927573139611, 0.5961924470781578, 'ovr', 2049] \n",
      "\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 26.1056\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 21 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.04643120390541338, 0.3073265275352951, 'crammer_singer', 3959] \n",
      "\n",
      "Iteration No: 21 ended. Evaluation done at random point.\n",
      "Time taken: 26.9331\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 22 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.012427183770120274, 0.11789212045581604, 'ovr', 3069] \n",
      "\n",
      "Iteration No: 22 ended. Evaluation done at random point.\n",
      "Time taken: 25.5187\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 23 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.028871854398777725, 0.3085826180692, 'crammer_singer', 2879] \n",
      "\n",
      "Iteration No: 23 ended. Evaluation done at random point.\n",
      "Time taken: 26.1461\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 24 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.05857596856990165, 0.9726361734877071, 'crammer_singer', 1413] \n",
      "\n",
      "Iteration No: 24 ended. Evaluation done at random point.\n",
      "Time taken: 27.2682\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 25 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.07173918838662087, 0.6516532834550335, 'ovr', 4894] \n",
      "\n",
      "Iteration No: 25 ended. Evaluation done at random point.\n",
      "Time taken: 24.5690\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 26 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.013645608920545938, 0.1539259205609905, 'ovr', 1109] \n",
      "\n",
      "Iteration No: 26 ended. Evaluation done at random point.\n",
      "Time taken: 25.9467\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 27 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.06163293287787309, 0.13239949273873325, 'crammer_singer', 2235] \n",
      "\n",
      "Iteration No: 27 ended. Evaluation done at random point.\n",
      "Time taken: 26.5386\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 28 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.05681008938194803, 0.28296391119489145, 'ovr', 4859] \n",
      "\n",
      "Iteration No: 28 ended. Evaluation done at random point.\n",
      "Time taken: 24.9230\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 29 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.03711345298215674, 0.14501627729941838, 'crammer_singer', 4827] \n",
      "\n",
      "Iteration No: 29 ended. Evaluation done at random point.\n",
      "Time taken: 25.6138\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 30 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.08289810705692793, 0.24111225518147586, 'ovr', 3214] \n",
      "\n",
      "Iteration No: 30 ended. Evaluation done at random point.\n",
      "Time taken: 31.6844\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n"
     ]
    }
   ],
   "source": [
    "# pipeline e parametros\n",
    "def treinar_modelo (params):\n",
    "    penalty=params[0]\n",
    "    loss=params[1]\n",
    "    tol=params[2]\n",
    "    c=params[3]\n",
    "    multi_class=params[4]\n",
    "    max_iter=params[5]\n",
    "    \n",
    "    \n",
    "    print(params, '\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    mdl = pipeline_LinearSVC\n",
    "    mdl.fit(previsores_train,classe_train)\n",
    "    \n",
    "    p = mdl.predict(previsores_valid)\n",
    "    \n",
    "    return accuracy_score(classe_valid,p)\n",
    "space=[\n",
    "       ('l1','l2'),#penalty\n",
    "       ('hinge','squared_hinge'),#loss\n",
    "       (1e-7,1e-1),#tol\n",
    "       (0.1,1.0),#c\n",
    "       ('ovr','crammer_singer'),#multi_class\n",
    "       (1000,5000)#max_iter\n",
    "       ]\n",
    "\n",
    "resultado = dummy_minimize(treinar_modelo,space,random_state=1,verbose=1,n_calls=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.012812531980490883, 0.9991364637917305, 'ovr', 2586] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 25.3869\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.09355391352669613, 0.8616798250174156, 'ovr', 3098] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 26.5287\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.05344143745331082, 0.9225658221213098, 'ovr', 2723] \n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 31.5814\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.07159707999978485, 0.8224817535436286, 'ovr', 3073] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 33.1656\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.08296035297908246, 0.34574497679507266, 'ovr', 3682] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 24.3662\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.04117884671811742, 0.2777958081863031, 'ovr', 1568] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 25.5429\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.003417227701452787, 0.661626987829618, 'crammer_singer', 2194] \n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 24.2555\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.0073365098378427845, 0.5223146737943289, 'ovr', 4613] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 24.0408\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.008362392092402167, 0.9251752010767559, 'crammer_singer', 2196] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 25.6571\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5284\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.061393870385773805, 0.9608820910034702, 'ovr', 1924] \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-b6eb4868ab83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreinar_modelo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_random_starts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36mtell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_tell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36m_tell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"next_xs_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macq_func\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gp_hedge\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/skopt/learning/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mnoise_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_level_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fixed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             )\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGaussianProcessRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    232\u001b[0m             optima = [(self._constrained_optimization(obj_func,\n\u001b[1;32m    233\u001b[0m                                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                                                       self.kernel_.bounds))]\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# Additional runs are performed from log-uniform chosen initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    501\u001b[0m             opt_res = scipy.optimize.minimize(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m                 bounds=bounds)\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0m_check_optimize_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mtheta_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 618\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    306\u001b[0m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[1;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                                   finite_diff_rel_step=finite_diff_rel_step)\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0mfunc_and_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun_and_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0;32m--> 262\u001b[0;31m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                     lml, grad = self.log_marginal_likelihood(\n\u001b[0;32m--> 225\u001b[0;31m                         theta, eval_gradient=True, clone_kernel=False)\n\u001b[0m\u001b[1;32m    226\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcho_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Line 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;31m# Compute log-likelihood (compare line 7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcho_solve\u001b[0;34m(c_and_lower, b, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_and_lower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/.local/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         raise ValueError(\n\u001b[0;32m--> 486\u001b[0;31m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "gp_minimize(treinar_modelo,space,random_state=1,verbose=1,n_calls=30,n_random_starts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test=grid_search.predict(test['comment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hockey', 'europe', 'funny', ..., 'trees', 'movies',\n",
       "       'GlobalOffensive'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_test = pd.DataFrame(predict_test, columns=['Category'])\n",
    "\n",
    "predict_test['Id'] = predict_test.index\n",
    "\n",
    "predict_test = predict_test.reindex(columns=['Id', 'Category'])\n",
    "\n",
    "predict_test.to_csv('SVM_mandar_essa_60_test_brut_textblob.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features=train['new_comment2']\n",
    "target = train['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm=Normalizer()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "vect=CountVectorizer()\n",
    "tfidf=TfidfTransformer()\n",
    "\n",
    "\n",
    "features=vect.fit_transform(features)\n",
    "\n",
    "features=tfidf.fit_transform(features)\n",
    "\n",
    "features=norm.fit_transform(features)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "previsores_train, previsores_valid, classe_train, classe_valid = train_test_split(features, target, test_size=0.20, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.012812531980490881, 0.9991364637917304, 'ovr', 1129] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 4.6117\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.03967680774631958, 0.5849350606030214, 'ovr', 3962] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 4.0543\n",
      "Function value obtained: 0.5355\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.022957798415261185, 0.5809725180523154, 'crammer_singer', 4049] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 2.8683\n",
      "Function value obtained: 0.5367\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.07783894579472973, 0.7443734643715278, 'crammer_singer', 3877] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 2.0096\n",
      "Function value obtained: 0.5362\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.0894606768897184, 0.17653979023280014, 'ovr', 1431] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 2.1970\n",
      "Function value obtained: 0.5350\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.05930659252325387, 0.704488687679921, 'ovr', 1515] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 3.5832\n",
      "Function value obtained: 0.5321\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.0686501241180656, 0.8511631047076357, 'ovr', 2321] \n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 4.4288\n",
      "Function value obtained: 0.5373\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.029849599625775, 0.5015210554774955, 'ovr', 4737] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 3.5160\n",
      "Function value obtained: 0.5338\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.029361485475953117, 0.3589978047277139, 'ovr', 3981] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 3.2590\n",
      "Function value obtained: 0.5345\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.09104484713447199, 0.36903710098874454, 'crammer_singer', 4159] \n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 1.4439\n",
      "Function value obtained: 0.5370\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.058930594759774746, 0.7297825240188381, 'ovr', 1695] \n",
      "\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 4.2363\n",
      "Function value obtained: 0.5363\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.054060096822313525, 0.788936593996784, 'ovr', 1469] \n",
      "\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 4.1939\n",
      "Function value obtained: 0.5365\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.05865554539469525, 0.9130617237590952, 'ovr', 4404] \n",
      "\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 3.8033\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.05384251558552909, 0.687068993857188, 'ovr', 4580] \n",
      "\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 4.1236\n",
      "Function value obtained: 0.5357\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.08833062078997188, 0.6613049863500481, 'crammer_singer', 2738] \n",
      "\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 1.8401\n",
      "Function value obtained: 0.5359\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.07527886003872512, 0.89320764667061, 'ovr', 1883] \n",
      "\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 3.9199\n",
      "Function value obtained: 0.5362\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.09494893092178128, 0.5049209201319466, 'crammer_singer', 2874] \n",
      "\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 1.6299\n",
      "Function value obtained: 0.5381\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.07715952264493699, 0.37122444586890413, 'crammer_singer', 3218] \n",
      "\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 1.5320\n",
      "Function value obtained: 0.5392\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.08859422133686753, 0.42154278400224987, 'crammer_singer', 2876] \n",
      "\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 1.5546\n",
      "Function value obtained: 0.5373\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.08316927573139611, 0.5961924470781578, 'ovr', 2049] \n",
      "\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 3.4204\n",
      "Function value obtained: 0.5359\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 21 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.04643120390541338, 0.3073265275352951, 'crammer_singer', 3959] \n",
      "\n",
      "Iteration No: 21 ended. Evaluation done at random point.\n",
      "Time taken: 1.7293\n",
      "Function value obtained: 0.5377\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 22 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.012427183770120274, 0.11789212045581604, 'ovr', 3069] \n",
      "\n",
      "Iteration No: 22 ended. Evaluation done at random point.\n",
      "Time taken: 2.6365\n",
      "Function value obtained: 0.5324\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 23 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.028871854398777725, 0.3085826180692, 'crammer_singer', 2879] \n",
      "\n",
      "Iteration No: 23 ended. Evaluation done at random point.\n",
      "Time taken: 2.0749\n",
      "Function value obtained: 0.5371\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 24 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.05857596856990165, 0.9726361734877071, 'crammer_singer', 1413] \n",
      "\n",
      "Iteration No: 24 ended. Evaluation done at random point.\n",
      "Time taken: 2.7336\n",
      "Function value obtained: 0.5315\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 25 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.07173918838662087, 0.6516532834550335, 'ovr', 4894] \n",
      "\n",
      "Iteration No: 25 ended. Evaluation done at random point.\n",
      "Time taken: 4.3539\n",
      "Function value obtained: 0.5363\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 26 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.013645608920545938, 0.1539259205609905, 'ovr', 1109] \n",
      "\n",
      "Iteration No: 26 ended. Evaluation done at random point.\n",
      "Time taken: 2.6495\n",
      "Function value obtained: 0.5337\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 27 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.06163293287787309, 0.13239949273873325, 'crammer_singer', 2235] \n",
      "\n",
      "Iteration No: 27 ended. Evaluation done at random point.\n",
      "Time taken: 1.1528\n",
      "Function value obtained: 0.5347\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 28 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.05681008938194803, 0.28296391119489145, 'ovr', 4859] \n",
      "\n",
      "Iteration No: 28 ended. Evaluation done at random point.\n",
      "Time taken: 3.0729\n",
      "Function value obtained: 0.5342\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 29 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.03711345298215674, 0.14501627729941838, 'crammer_singer', 4827] \n",
      "\n",
      "Iteration No: 29 ended. Evaluation done at random point.\n",
      "Time taken: 1.7330\n",
      "Function value obtained: 0.5361\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 30 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.08289810705692793, 0.24111225518147586, 'ovr', 3214] \n",
      "\n",
      "Iteration No: 30 ended. Evaluation done at random point.\n",
      "Time taken: 2.7192\n",
      "Function value obtained: 0.5346\n",
      "Current minimum: 0.5282\n"
     ]
    }
   ],
   "source": [
    "#sem PIPE e COm Dummy\n",
    "\n",
    "\n",
    "\n",
    "# pipeline e parametros\n",
    "def treinar_modelo (params):\n",
    "    penalty=params[0]\n",
    "    loss=params[1]\n",
    "    tol=params[2]\n",
    "    c=params[3]\n",
    "    multi_class=params[4]\n",
    "    max_iter=params[5]\n",
    "    \n",
    "    \n",
    "    print(params, '\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    mdl =LinearSVC(C=c, max_iter=max_iter, loss=loss, tol=tol, multi_class=multi_class,random_state=0)\n",
    "    mdl.fit(previsores_train,classe_train)\n",
    "    \n",
    "    p = mdl.predict(previsores_valid)\n",
    "    \n",
    "    return accuracy_score(classe_valid,p)\n",
    "space=[\n",
    "       ('l1','l2'),#penalty\n",
    "       ('hinge','squared_hinge'),#loss\n",
    "       (1e-7,1e-1),#tol\n",
    "       (0.1,1.0),#c\n",
    "       ('ovr','crammer_singer'),#multi_class\n",
    "       (1000,5000)#max_iter\n",
    "       ]\n",
    "\n",
    "resultado = dummy_minimize(treinar_modelo,space,random_state=1,verbose=1,n_calls=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.012812531980490883, 0.9991364637917305, 'ovr', 2586] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 4.4071\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.09355391352669613, 0.8616798250174156, 'ovr', 3098] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 3.3423\n",
      "Function value obtained: 0.5293\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.05344143745331082, 0.9225658221213098, 'ovr', 2723] \n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 4.2376\n",
      "Function value obtained: 0.5381\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.07159707999978485, 0.8224817535436286, 'ovr', 3073] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 3.3886\n",
      "Function value obtained: 0.5307\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.08296035297908246, 0.34574497679507266, 'ovr', 3682] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 2.6121\n",
      "Function value obtained: 0.5347\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.04117884671811742, 0.2777958081863031, 'ovr', 1568] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 2.8284\n",
      "Function value obtained: 0.5342\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.003417227701452787, 0.661626987829618, 'crammer_singer', 2194] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 11.4691\n",
      "Function value obtained: 0.5357\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.0073365098378427845, 0.5223146737943289, 'ovr', 4613] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 6.3150\n",
      "Function value obtained: 0.5367\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.008362392092402167, 0.9251752010767559, 'crammer_singer', 2196] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 6.4989\n",
      "Function value obtained: 0.5314\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.061393870385773805, 0.9608820910034702, 'ovr', 1924] \n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 4.3803\n",
      "Function value obtained: 0.5288\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3089\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.1, 1.0, 'ovr', 1000] \n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.4481\n",
      "Function value obtained: 0.5285\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 0.1, 'crammer_singer', 1000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 101.6508\n",
      "Function value obtained: 0.5337\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.1514\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.4697\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3256\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.5874\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.6880\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.4102\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.4876\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.6225\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.8245\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.6514\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.7309\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.6997\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.0484\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.0137\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.8461\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.0118\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.5757\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          fun: 0.5280833333333333\n",
       "    func_vals: array([0.52816667, 0.52933333, 0.53808333, 0.53066667, 0.53475   ,\n",
       "       0.53416667, 0.53575   , 0.53666667, 0.53141667, 0.52875   ,\n",
       "       0.52808333, 0.5285    , 0.53375   , 0.52808333, 0.52808333,\n",
       "       0.52808333, 0.52808333, 0.52808333, 0.52808333, 0.52808333,\n",
       "       0.52808333, 0.52808333, 0.52808333, 0.52808333, 0.52808333,\n",
       "       0.52808333, 0.52808333, 0.52808333, 0.52808333, 0.52808333])\n",
       "       models: [GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845)]\n",
       " random_state: RandomState(MT19937) at 0x7F95BC6C0780\n",
       "        space: Space([Categorical(categories=('l1', 'l2'), prior=None),\n",
       "       Categorical(categories=('hinge', 'squared_hinge'), prior=None),\n",
       "       Real(low=1e-07, high=0.1, prior='uniform', transform='normalize'),\n",
       "       Real(low=0.1, high=1.0, prior='uniform', transform='normalize'),\n",
       "       Categorical(categories=('ovr', 'crammer_singer'), prior=None),\n",
       "       Integer(low=1000, high=5000, prior='uniform', transform='normalize')])\n",
       "        specs: {'args': {'model_queue_size': None, 'n_jobs': 1, 'kappa': 1.96, 'xi': 0.01, 'n_restarts_optimizer': 5, 'n_points': 10000, 'callback': None, 'verbose': 1, 'random_state': RandomState(MT19937) at 0x7F95BC6C0780, 'y0': None, 'x0': None, 'acq_optimizer': 'auto', 'acq_func': 'gp_hedge', 'n_random_starts': 10, 'n_calls': 30, 'base_estimator': GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), 'dimensions': Space([Categorical(categories=('l1', 'l2'), prior=None),\n",
       "       Categorical(categories=('hinge', 'squared_hinge'), prior=None),\n",
       "       Real(low=1e-07, high=0.1, prior='uniform', transform='normalize'),\n",
       "       Real(low=0.1, high=1.0, prior='uniform', transform='normalize'),\n",
       "       Categorical(categories=('ovr', 'crammer_singer'), prior=None),\n",
       "       Integer(low=1000, high=5000, prior='uniform', transform='normalize')]), 'func': <function treinar_modelo at 0x7f95b7702488>}, 'function': 'base_minimize'}\n",
       "            x: ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000]\n",
       "      x_iters: [['l2', 'squared_hinge', 0.012812531980490883, 0.9991364637917305, 'ovr', 2586], ['l1', 'squared_hinge', 0.09355391352669613, 0.8616798250174156, 'ovr', 3098], ['l1', 'hinge', 0.05344143745331082, 0.9225658221213098, 'ovr', 2723], ['l2', 'squared_hinge', 0.07159707999978485, 0.8224817535436286, 'ovr', 3073], ['l2', 'squared_hinge', 0.08296035297908246, 0.34574497679507266, 'ovr', 3682], ['l2', 'squared_hinge', 0.04117884671811742, 0.2777958081863031, 'ovr', 1568], ['l2', 'hinge', 0.003417227701452787, 0.661626987829618, 'crammer_singer', 2194], ['l1', 'hinge', 0.0073365098378427845, 0.5223146737943289, 'ovr', 4613], ['l1', 'squared_hinge', 0.008362392092402167, 0.9251752010767559, 'crammer_singer', 2196], ['l2', 'squared_hinge', 0.061393870385773805, 0.9608820910034702, 'ovr', 1924], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.1, 1.0, 'ovr', 1000], ['l1', 'squared_hinge', 1e-07, 0.1, 'crammer_singer', 1000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_minimize(treinar_modelo,space,random_state=1,verbose=1,n_calls=30,n_random_starts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.012812531980490883, 0.9991364637917305, 'ovr', 2586] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 4.8426\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.09355391352669613, 0.8616798250174156, 'ovr', 3098] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 3.8887\n",
      "Function value obtained: 0.5293\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.05344143745331082, 0.9225658221213098, 'ovr', 2723] \n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 4.6645\n",
      "Function value obtained: 0.5381\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.07159707999978485, 0.8224817535436286, 'ovr', 3073] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 3.7969\n",
      "Function value obtained: 0.5307\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.08296035297908246, 0.34574497679507266, 'ovr', 3682] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 2.8162\n",
      "Function value obtained: 0.5347\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.04117884671811742, 0.2777958081863031, 'ovr', 1568] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 2.9691\n",
      "Function value obtained: 0.5342\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.003417227701452787, 0.661626987829618, 'crammer_singer', 2194] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 11.2852\n",
      "Function value obtained: 0.5357\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "['l1', 'hinge', 0.0073365098378427845, 0.5223146737943289, 'ovr', 4613] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 6.9565\n",
      "Function value obtained: 0.5367\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.008362392092402167, 0.9251752010767559, 'crammer_singer', 2196] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 6.4379\n",
      "Function value obtained: 0.5314\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.061393870385773805, 0.9608820910034702, 'ovr', 1924] \n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 3.9415\n",
      "Function value obtained: 0.5288\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "['l2', 'squared_hinge', 0.04930601004851525, 0.5865404579412797, 'crammer_singer', 1181] \n",
      "\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 2.0039\n",
      "Function value obtained: 0.5368\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.002980232838103509, 0.894812928237481, 'crammer_singer', 2792] \n",
      "\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 9.8403\n",
      "Function value obtained: 0.5310\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.0538425155855291, 0.687068993857188, 'ovr', 3284] \n",
      "\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 3.9711\n",
      "Function value obtained: 0.5357\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.06902048975505576, 0.6829744597960129, 'ovr', 4053] \n",
      "\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 3.7094\n",
      "Function value obtained: 0.5363\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.08813419482921818, 0.11050227431280424, 'ovr', 1295] \n",
      "\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 2.1198\n",
      "Function value obtained: 0.5319\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.0355311007106066, 0.9476532538780804, 'ovr', 4052] \n",
      "\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 5.2220\n",
      "Function value obtained: 0.5377\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.07727393740384306, 0.23763684029862592, 'crammer_singer', 1036] \n",
      "\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 1.1605\n",
      "Function value obtained: 0.5368\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.07645928056479284, 0.5206534148323471, 'ovr', 4327] \n",
      "\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 3.3796\n",
      "Function value obtained: 0.5355\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "['l2', 'hinge', 0.047247556552542466, 0.7684883470783824, 'ovr', 2857] \n",
      "\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 4.3310\n",
      "Function value obtained: 0.5366\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "['l1', 'squared_hinge', 0.020856910308590246, 0.144373820277842, 'crammer_singer', 1689] \n",
      "\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 2.9196\n",
      "Function value obtained: 0.5370\n",
      "Current minimum: 0.5282\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.3551\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.1, 1.0, 'ovr', 1000] \n",
      "\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.2972\n",
      "Function value obtained: 0.5285\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.4335\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5281\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.035340694079044124, 1.0, 'ovr', 3309] \n",
      "\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.7096\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 3394] \n",
      "\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.2345\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.1, 1.0, 'ovr', 4064] \n",
      "\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.9800\n",
      "Function value obtained: 0.5285\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.030886650213263825, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.2747\n",
      "Function value obtained: 0.5279\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03991277509559933, 1.0, 'ovr', 1000] \n",
      "\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.3467\n",
      "Function value obtained: 0.5280\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.1757\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.03472391272210856, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.4176\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.6332\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03801388791701781, 1.0, 'ovr', 3330] \n",
      "\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.9590\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 4845] \n",
      "\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.4393\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.02596008662588774, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.6267\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 1000] \n",
      "\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.2260\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.021799440557215985, 1.0, 'ovr', 1000] \n",
      "\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.9226\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.9527\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.0356\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.01606745134597364, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.5303\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03281460504641197, 1.0, 'ovr', 1000] \n",
      "\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.7404\n",
      "Function value obtained: 0.5285\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.6520\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.4520\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.9239\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.0637\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03139092238855615, 1.0, 'ovr', 3643] \n",
      "\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.5690\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03331535126963768, 1.0, 'ovr', 3676] \n",
      "\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.7204\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.8703\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.5123\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.5366\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03563220864109156, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.3235\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 51 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 51 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.4248\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 52 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03537626800242927, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 52 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9351\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 53 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03546073515344346, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 53 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2297\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 54 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03546637931144115, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 54 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2203\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 55 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03553497633380589, 1.0, 'ovr', 3849] \n",
      "\n",
      "Iteration No: 55 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.6376\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 56 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03546615265606841, 1.0, 'ovr', 4981] \n",
      "\n",
      "Iteration No: 56 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.4715\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 57 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03546765774012168, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 57 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.0477\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 58 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03547016426079733, 1.0, 'ovr', 4755] \n",
      "\n",
      "Iteration No: 58 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1612\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 59 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03546743809090378, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 59 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.4541\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 60 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.04094146232145699, 1.0, 'ovr', 1000] \n",
      "\n",
      "Iteration No: 60 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.9821\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 61 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03129970141093304, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 61 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3923\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 62 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.031295461358076204, 1.0, 'ovr', 3668] \n",
      "\n",
      "Iteration No: 62 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1341\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 63 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03129523785251406, 1.0, 'ovr', 2578] \n",
      "\n",
      "Iteration No: 63 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7054\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 64 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03129646068635452, 1.0, 'crammer_singer', 5000] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 64 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.4057\n",
      "Function value obtained: 0.5319\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 65 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03129430983404321, 1.0, 'ovr', 4407] \n",
      "\n",
      "Iteration No: 65 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1042\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 66 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03129354026443392, 1.0, 'ovr', 3532] \n",
      "\n",
      "Iteration No: 66 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1979\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 67 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03129549085671713, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 67 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.6029\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 68 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.005410345963912789, 1.0, 'ovr', 4610] \n",
      "\n",
      "Iteration No: 68 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3710\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 69 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.035480393163100594, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 69 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2291\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 70 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.031586582453215085, 0.5850996429153427, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 70 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.1924\n",
      "Function value obtained: 0.5327\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 71 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03548771816804913, 1.0, 'ovr', 2864] \n",
      "\n",
      "Iteration No: 71 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.6299\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 72 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03548124999366079, 1.0, 'ovr', 4341] \n",
      "\n",
      "Iteration No: 72 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1444\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 73 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03548606363961593, 1.0, 'ovr', 2970] \n",
      "\n",
      "Iteration No: 73 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.4481\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 74 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.0359987189245442, 0.6565892965431952, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 74 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.6497\n",
      "Function value obtained: 0.5328\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 75 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.002481299911025909, 0.7950807548126773, 'ovr', 2173] \n",
      "\n",
      "Iteration No: 75 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.6134\n",
      "Function value obtained: 0.5306\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 76 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03548849918614725, 1.0, 'ovr', 2280] \n",
      "\n",
      "Iteration No: 76 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.7588\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 77 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.035476327688392456, 1.0, 'ovr', 3473] \n",
      "\n",
      "Iteration No: 77 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3812\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 78 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.0025490314405116443, 0.9880062163234479, 'ovr', 3580] \n",
      "\n",
      "Iteration No: 78 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3824\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 79 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.008117138037227032, 0.9189645044977409, 'ovr', 1269] \n",
      "\n",
      "Iteration No: 79 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.5209\n",
      "Function value obtained: 0.5288\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 80 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03129478113411747, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 80 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3928\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 81 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.035478076824980886, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 81 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.5770\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 82 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03549296173515708, 1.0, 'ovr', 1326] \n",
      "\n",
      "Iteration No: 82 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.5555\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 83 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03546993734869964, 1.0, 'ovr', 5000] \n",
      "\n",
      "Iteration No: 83 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0934\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 84 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.0105639065415063, 1.0, 'ovr', 4056] \n",
      "\n",
      "Iteration No: 84 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.6153\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 85 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03549095098825688, 1.0, 'ovr', 2330] \n",
      "\n",
      "Iteration No: 85 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3450\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 86 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.1, 0.4302449811119333, 'crammer_singer', 4095] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 86 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.6247\n",
      "Function value obtained: 0.5376\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 87 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.06586760761571718, 0.9828247126403987, 'ovr', 1759] \n",
      "\n",
      "Iteration No: 87 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.8099\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 88 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.01812310106931588, 0.6406429154593035, 'ovr', 1244] \n",
      "\n",
      "Iteration No: 88 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.7751\n",
      "Function value obtained: 0.5327\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 89 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.024266128213620196, 1.0, 'ovr', 2487] \n",
      "\n",
      "Iteration No: 89 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.5973\n",
      "Function value obtained: 0.5281\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 90 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.035495526282950475, 1.0, 'ovr', 1370] \n",
      "\n",
      "Iteration No: 90 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4479\n",
      "Function value obtained: 0.5278\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 91 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.06465391845024836, 1.0, 'ovr', 3963] \n",
      "\n",
      "Iteration No: 91 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3452\n",
      "Function value obtained: 0.5287\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 92 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.0671819517095842, 0.9934435931939379, 'ovr', 1000] \n",
      "\n",
      "Iteration No: 92 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.9177\n",
      "Function value obtained: 0.5282\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 93 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.06614739926846855, 0.8924340896888469, 'ovr', 1000] \n",
      "\n",
      "Iteration No: 93 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3339\n",
      "Function value obtained: 0.5295\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 94 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.03573192952810117, 0.9979936641433199, 'ovr', 1905] \n",
      "\n",
      "Iteration No: 94 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.8943\n",
      "Function value obtained: 0.5286\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 95 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.008945221087336802, 0.9826541724755893, 'ovr', 2484] \n",
      "\n",
      "Iteration No: 95 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7924\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 96 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.002569286000579423, 0.9790199208916331, 'ovr', 2859] \n",
      "\n",
      "Iteration No: 96 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.7523\n",
      "Function value obtained: 0.5285\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 97 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.012581234014450876, 0.9746187145987946, 'ovr', 1012] \n",
      "\n",
      "Iteration No: 97 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3886\n",
      "Function value obtained: 0.5284\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 98 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.07065195080286042, 0.9541741978729922, 'ovr', 4403] \n",
      "\n",
      "Iteration No: 98 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3977\n",
      "Function value obtained: 0.5285\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 99 started. Searching for the next optimal point.\n",
      "['l1', 'squared_hinge', 0.09706983523594145, 0.9547203639288608, 'ovr', 3141] \n",
      "\n",
      "Iteration No: 99 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.5406\n",
      "Function value obtained: 0.5288\n",
      "Current minimum: 0.5278\n",
      "Iteration No: 100 started. Searching for the next optimal point.\n",
      "['l2', 'squared_hinge', 0.07282377987803466, 0.9838809801591734, 'ovr', 2060] \n",
      "\n",
      "Iteration No: 100 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1647\n",
      "Function value obtained: 0.5283\n",
      "Current minimum: 0.5278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          fun: 0.5278333333333334\n",
       "    func_vals: array([0.52816667, 0.52933333, 0.53808333, 0.53066667, 0.53475   ,\n",
       "       0.53416667, 0.53575   , 0.53666667, 0.53141667, 0.52875   ,\n",
       "       0.53683333, 0.531     , 0.53566667, 0.53625   , 0.53191667,\n",
       "       0.53766667, 0.53683333, 0.5355    , 0.53658333, 0.537     ,\n",
       "       0.52808333, 0.5285    , 0.52808333, 0.52783333, 0.52808333,\n",
       "       0.5285    , 0.52791667, 0.528     , 0.52808333, 0.52825   ,\n",
       "       0.52808333, 0.52816667, 0.52808333, 0.52816667, 0.52808333,\n",
       "       0.52825   , 0.52808333, 0.52808333, 0.52825   , 0.5285    ,\n",
       "       0.52808333, 0.52808333, 0.52808333, 0.52808333, 0.52783333,\n",
       "       0.52841667, 0.52808333, 0.52808333, 0.52808333, 0.52783333,\n",
       "       0.52808333, 0.52783333, 0.52783333, 0.52783333, 0.52783333,\n",
       "       0.52783333, 0.52783333, 0.52783333, 0.52783333, 0.52825   ,\n",
       "       0.52783333, 0.52783333, 0.52783333, 0.53191667, 0.52783333,\n",
       "       0.52783333, 0.52783333, 0.52816667, 0.52783333, 0.53275   ,\n",
       "       0.52783333, 0.52783333, 0.52783333, 0.53283333, 0.53058333,\n",
       "       0.52783333, 0.52783333, 0.52841667, 0.52875   , 0.52783333,\n",
       "       0.52783333, 0.52783333, 0.52783333, 0.52816667, 0.52783333,\n",
       "       0.53758333, 0.52808333, 0.53275   , 0.52808333, 0.52783333,\n",
       "       0.52866667, 0.52816667, 0.5295    , 0.52858333, 0.52841667,\n",
       "       0.5285    , 0.52841667, 0.5285    , 0.52875   , 0.52833333])\n",
       "       models: [GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845)]\n",
       " random_state: RandomState(MT19937) at 0x7F95BC79F990\n",
       "        space: Space([Categorical(categories=('l1', 'l2'), prior=None),\n",
       "       Categorical(categories=('hinge', 'squared_hinge'), prior=None),\n",
       "       Real(low=1e-07, high=0.1, prior='uniform', transform='normalize'),\n",
       "       Real(low=0.1, high=1.0, prior='uniform', transform='normalize'),\n",
       "       Categorical(categories=('ovr', 'crammer_singer'), prior=None),\n",
       "       Integer(low=1000, high=5000, prior='uniform', transform='normalize')])\n",
       "        specs: {'args': {'model_queue_size': None, 'n_jobs': 1, 'kappa': 1.96, 'xi': 0.01, 'n_restarts_optimizer': 5, 'n_points': 10000, 'callback': None, 'verbose': 1, 'random_state': RandomState(MT19937) at 0x7F95BC79F990, 'y0': None, 'x0': None, 'acq_optimizer': 'auto', 'acq_func': 'gp_hedge', 'n_random_starts': 20, 'n_calls': 100, 'base_estimator': GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=1791095845), 'dimensions': Space([Categorical(categories=('l1', 'l2'), prior=None),\n",
       "       Categorical(categories=('hinge', 'squared_hinge'), prior=None),\n",
       "       Real(low=1e-07, high=0.1, prior='uniform', transform='normalize'),\n",
       "       Real(low=0.1, high=1.0, prior='uniform', transform='normalize'),\n",
       "       Categorical(categories=('ovr', 'crammer_singer'), prior=None),\n",
       "       Integer(low=1000, high=5000, prior='uniform', transform='normalize')]), 'func': <function treinar_modelo at 0x7f95b7702488>}, 'function': 'base_minimize'}\n",
       "            x: ['l1', 'squared_hinge', 0.035340694079044124, 1.0, 'ovr', 3309]\n",
       "      x_iters: [['l2', 'squared_hinge', 0.012812531980490883, 0.9991364637917305, 'ovr', 2586], ['l1', 'squared_hinge', 0.09355391352669613, 0.8616798250174156, 'ovr', 3098], ['l1', 'hinge', 0.05344143745331082, 0.9225658221213098, 'ovr', 2723], ['l2', 'squared_hinge', 0.07159707999978485, 0.8224817535436286, 'ovr', 3073], ['l2', 'squared_hinge', 0.08296035297908246, 0.34574497679507266, 'ovr', 3682], ['l2', 'squared_hinge', 0.04117884671811742, 0.2777958081863031, 'ovr', 1568], ['l2', 'hinge', 0.003417227701452787, 0.661626987829618, 'crammer_singer', 2194], ['l1', 'hinge', 0.0073365098378427845, 0.5223146737943289, 'ovr', 4613], ['l1', 'squared_hinge', 0.008362392092402167, 0.9251752010767559, 'crammer_singer', 2196], ['l2', 'squared_hinge', 0.061393870385773805, 0.9608820910034702, 'ovr', 1924], ['l2', 'squared_hinge', 0.04930601004851525, 0.5865404579412797, 'crammer_singer', 1181], ['l1', 'squared_hinge', 0.002980232838103509, 0.894812928237481, 'crammer_singer', 2792], ['l2', 'hinge', 0.0538425155855291, 0.687068993857188, 'ovr', 3284], ['l2', 'hinge', 0.06902048975505576, 0.6829744597960129, 'ovr', 4053], ['l1', 'squared_hinge', 0.08813419482921818, 0.11050227431280424, 'ovr', 1295], ['l2', 'hinge', 0.0355311007106066, 0.9476532538780804, 'ovr', 4052], ['l2', 'hinge', 0.07727393740384306, 0.23763684029862592, 'crammer_singer', 1036], ['l2', 'hinge', 0.07645928056479284, 0.5206534148323471, 'ovr', 4327], ['l2', 'hinge', 0.047247556552542466, 0.7684883470783824, 'ovr', 2857], ['l1', 'squared_hinge', 0.020856910308590246, 0.144373820277842, 'crammer_singer', 1689], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.1, 1.0, 'ovr', 1000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.035340694079044124, 1.0, 'ovr', 3309], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 3394], ['l1', 'squared_hinge', 0.1, 1.0, 'ovr', 4064], ['l1', 'squared_hinge', 0.030886650213263825, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03991277509559933, 1.0, 'ovr', 1000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l2', 'squared_hinge', 0.03472391272210856, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03801388791701781, 1.0, 'ovr', 3330], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 4845], ['l1', 'squared_hinge', 0.02596008662588774, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 1000], ['l1', 'squared_hinge', 0.021799440557215985, 1.0, 'ovr', 1000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.01606745134597364, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03281460504641197, 1.0, 'ovr', 1000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03139092238855615, 1.0, 'ovr', 3643], ['l1', 'squared_hinge', 0.03331535126963768, 1.0, 'ovr', 3676], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03563220864109156, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 1e-07, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03537626800242927, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03546073515344346, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03546637931144115, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03553497633380589, 1.0, 'ovr', 3849], ['l1', 'squared_hinge', 0.03546615265606841, 1.0, 'ovr', 4981], ['l1', 'squared_hinge', 0.03546765774012168, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03547016426079733, 1.0, 'ovr', 4755], ['l1', 'squared_hinge', 0.03546743809090378, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.04094146232145699, 1.0, 'ovr', 1000], ['l1', 'squared_hinge', 0.03129970141093304, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.031295461358076204, 1.0, 'ovr', 3668], ['l1', 'squared_hinge', 0.03129523785251406, 1.0, 'ovr', 2578], ['l1', 'squared_hinge', 0.03129646068635452, 1.0, 'crammer_singer', 5000], ['l1', 'squared_hinge', 0.03129430983404321, 1.0, 'ovr', 4407], ['l1', 'squared_hinge', 0.03129354026443392, 1.0, 'ovr', 3532], ['l1', 'squared_hinge', 0.03129549085671713, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.005410345963912789, 1.0, 'ovr', 4610], ['l1', 'squared_hinge', 0.035480393163100594, 1.0, 'ovr', 5000], ['l2', 'squared_hinge', 0.031586582453215085, 0.5850996429153427, 'ovr', 5000], ['l1', 'squared_hinge', 0.03548771816804913, 1.0, 'ovr', 2864], ['l1', 'squared_hinge', 0.03548124999366079, 1.0, 'ovr', 4341], ['l1', 'squared_hinge', 0.03548606363961593, 1.0, 'ovr', 2970], ['l1', 'squared_hinge', 0.0359987189245442, 0.6565892965431952, 'ovr', 5000], ['l1', 'squared_hinge', 0.002481299911025909, 0.7950807548126773, 'ovr', 2173], ['l1', 'squared_hinge', 0.03548849918614725, 1.0, 'ovr', 2280], ['l1', 'squared_hinge', 0.035476327688392456, 1.0, 'ovr', 3473], ['l2', 'squared_hinge', 0.0025490314405116443, 0.9880062163234479, 'ovr', 3580], ['l2', 'squared_hinge', 0.008117138037227032, 0.9189645044977409, 'ovr', 1269], ['l1', 'squared_hinge', 0.03129478113411747, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.035478076824980886, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.03549296173515708, 1.0, 'ovr', 1326], ['l1', 'squared_hinge', 0.03546993734869964, 1.0, 'ovr', 5000], ['l1', 'squared_hinge', 0.0105639065415063, 1.0, 'ovr', 4056], ['l1', 'squared_hinge', 0.03549095098825688, 1.0, 'ovr', 2330], ['l1', 'squared_hinge', 0.1, 0.4302449811119333, 'crammer_singer', 4095], ['l2', 'squared_hinge', 0.06586760761571718, 0.9828247126403987, 'ovr', 1759], ['l1', 'squared_hinge', 0.01812310106931588, 0.6406429154593035, 'ovr', 1244], ['l1', 'squared_hinge', 0.024266128213620196, 1.0, 'ovr', 2487], ['l1', 'squared_hinge', 0.035495526282950475, 1.0, 'ovr', 1370], ['l2', 'squared_hinge', 0.06465391845024836, 1.0, 'ovr', 3963], ['l2', 'squared_hinge', 0.0671819517095842, 0.9934435931939379, 'ovr', 1000], ['l2', 'squared_hinge', 0.06614739926846855, 0.8924340896888469, 'ovr', 1000], ['l1', 'squared_hinge', 0.03573192952810117, 0.9979936641433199, 'ovr', 1905], ['l2', 'squared_hinge', 0.008945221087336802, 0.9826541724755893, 'ovr', 2484], ['l1', 'squared_hinge', 0.002569286000579423, 0.9790199208916331, 'ovr', 2859], ['l1', 'squared_hinge', 0.012581234014450876, 0.9746187145987946, 'ovr', 1012], ['l2', 'squared_hinge', 0.07065195080286042, 0.9541741978729922, 'ovr', 4403], ['l1', 'squared_hinge', 0.09706983523594145, 0.9547203639288608, 'ovr', 3141], ['l2', 'squared_hinge', 0.07282377987803466, 0.9838809801591734, 'ovr', 2060]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_minimize(treinar_modelo,space,random_state=1,verbose=1,n_calls=100,n_random_starts=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier\n",
    "\n",
    "\n",
    "clf=LinearSVC(C=1.0, penalty='l2', max_iter=3000, dual=False,random_state=0)\n",
    "\n",
    "clf.fit(previsores_train,classe_train)\n",
    "\n",
    "label_predict=clf.predict(previsores_valid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracia:  0.5281666666666667\n"
     ]
    }
   ],
   "source": [
    "acuracia=accuracy_score(classe_valid,label_predict)\n",
    "print('acuracia: ',acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''acuracia:  0.49725\n",
    "    \n",
    "    0.4856666666666667\n",
    "    \n",
    "    0.4984166666666667\n",
    "    \n",
    "    acuracia:  0.5029166666666667\n",
    "    \n",
    "    acuracia:  0.4900833333333333\n",
    "'''\n",
    "acuracia:  0.5216666666666666\n",
    "acuracia:  0.52175 sem normalizer\n",
    "acuracia:  0.5400833333333334 sem norm funny + conspiracy\n",
    "acuracia:  0.5400833333333334 com norm funny + conspiracy\n",
    "\n",
    "0.5740833333333333 prep conp + ask+ funny\n",
    "\n",
    "acuracia:  0.56825 prep conp + ask+ funny\n",
    "    \n",
    "    \n",
    "com menos coisas nas 3 categorias acuracia:  0.5281666666666667\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test=vect.fit_transform(test['comment'])\n",
    "\n",
    "features_test=tfidf.fit_transform(features_test)\n",
    "\n",
    "features_test=norm.fit_transform(features_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "features_test1=csr_matrix(features_test,(20000, 58895)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#features_test\n",
    "previsoes_test=clf.predict(features_test1)\n",
    "previsoes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "previsoes_test = pd.DataFrame(previsoes_test, columns=['Category'])\n",
    "\n",
    "previsoes_test['Id'] = previsoes_test.index\n",
    "\n",
    "previsoes_test = previsoes_test.reindex(columns=['Id', 'Category'])\n",
    "\n",
    "previsoes_test.to_csv('linear_svc_20jul.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>previsao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>hockey</td>\n",
       "      <td>hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>movies</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58303</th>\n",
       "      <td>baseball</td>\n",
       "      <td>baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8870</th>\n",
       "      <td>europe</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40228</th>\n",
       "      <td>Overwatch</td>\n",
       "      <td>Overwatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47049</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31629</th>\n",
       "      <td>trees</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50430</th>\n",
       "      <td>anime</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21574</th>\n",
       "      <td>baseball</td>\n",
       "      <td>baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10617</th>\n",
       "      <td>anime</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit   previsao\n",
       "3048      hockey     hockey\n",
       "19563     movies     movies\n",
       "58303   baseball   baseball\n",
       "8870      europe     europe\n",
       "40228  Overwatch  Overwatch\n",
       "...          ...        ...\n",
       "47049        nfl        nfl\n",
       "31629      trees      funny\n",
       "50430      anime      anime\n",
       "21574   baseball   baseball\n",
       "10617      anime      anime\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe_valid2 = pd.DataFrame(classe_valid)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classe_valid2['previsao']=label_predict\n",
    "classe_valid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>previsao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Music</td>\n",
       "      <td>trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>630</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit previsao\n",
       "count      12000    12000\n",
       "unique        20       20\n",
       "top        Music    trees\n",
       "freq         630      745"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe_valid2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [AskReddit, GlobalOffensive, Music, Overwatch, anime, baseball, canada, conspiracy, europe, funny, gameofthrones, hockey, leagueoflegends, movies, nba, nfl, soccer, trees, worldnews, wow]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe_valid = pd.DataFrame(classe_valid,columns=['subreddit'])\n",
    "classe_valid\n",
    "classe_valid.groupby(['subreddit']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1\n",
       "subreddit           \n",
       "AskReddit        590\n",
       "GlobalOffensive  592\n",
       "Music            630\n",
       "Overwatch        608\n",
       "anime            608\n",
       "baseball         601\n",
       "canada           588\n",
       "conspiracy       541\n",
       "europe           595\n",
       "funny            609\n",
       "gameofthrones    589\n",
       "hockey           623\n",
       "leagueoflegends  618\n",
       "movies           584\n",
       "nba              599\n",
       "nfl              604\n",
       "soccer           613\n",
       "trees            618\n",
       "worldnews        590\n",
       "wow              600"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe_valid['1']=1\n",
    "classe_valid.groupby(['subreddit']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>previsao</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>hockey</td>\n",
       "      <td>hockey</td>\n",
       "      <td>3048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>movies</td>\n",
       "      <td>movies</td>\n",
       "      <td>19563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58303</th>\n",
       "      <td>baseball</td>\n",
       "      <td>baseball</td>\n",
       "      <td>58303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8870</th>\n",
       "      <td>europe</td>\n",
       "      <td>europe</td>\n",
       "      <td>8870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40228</th>\n",
       "      <td>Overwatch</td>\n",
       "      <td>Overwatch</td>\n",
       "      <td>40228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47049</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nfl</td>\n",
       "      <td>47049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31629</th>\n",
       "      <td>trees</td>\n",
       "      <td>funny</td>\n",
       "      <td>31629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50430</th>\n",
       "      <td>anime</td>\n",
       "      <td>anime</td>\n",
       "      <td>50430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21574</th>\n",
       "      <td>baseball</td>\n",
       "      <td>baseball</td>\n",
       "      <td>21574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10617</th>\n",
       "      <td>anime</td>\n",
       "      <td>anime</td>\n",
       "      <td>10617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit   previsao     Id\n",
       "3048      hockey     hockey   3048\n",
       "19563     movies     movies  19563\n",
       "58303   baseball   baseball  58303\n",
       "8870      europe     europe   8870\n",
       "40228  Overwatch  Overwatch  40228\n",
       "...          ...        ...    ...\n",
       "47049        nfl        nfl  47049\n",
       "31629      trees      funny  31629\n",
       "50430      anime      anime  50430\n",
       "21574   baseball   baseball  21574\n",
       "10617      anime      anime  10617\n",
       "\n",
       "[12000 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe_valid2['Id'] = classe_valid2.index\n",
    "classe_valid2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_valid2['igual']= np.where(classe_valid2['previsao']==classe_valid2['subreddit'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>igual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>18543759</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>17636754</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>17133584</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>16230416</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>17330563</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>17760953</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>19110665</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>17883785</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>17244947</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>18210804</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>19345930</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>18140416</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>18678996</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>18732233</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>17980673</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>17411862</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>17815772</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>18454745</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>17762439</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>18027439</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id  igual\n",
       "subreddit                       \n",
       "funny            18543759    186\n",
       "AskReddit        17636754    214\n",
       "worldnews        17133584    228\n",
       "conspiracy       16230416    254\n",
       "canada           17330563    277\n",
       "europe           17760953    296\n",
       "Music            19110665    307\n",
       "gameofthrones    17883785    308\n",
       "movies           17244947    324\n",
       "trees            18210804    335\n",
       "hockey           19345930    337\n",
       "GlobalOffensive  18140416    339\n",
       "soccer           18678996    345\n",
       "anime            18732233    350\n",
       "nfl              17980673    350\n",
       "nba              17411862    355\n",
       "baseball         17815772    376\n",
       "Overwatch        18454745    384\n",
       "leagueoflegends  17762439    386\n",
       "wow              18027439    387"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acertos=classe_valid2.groupby(['subreddit']).sum()\n",
    "acertos.sort_values(by='igual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1\n",
       "subreddit           \n",
       "AskReddit        590\n",
       "GlobalOffensive  592\n",
       "Music            630\n",
       "Overwatch        608\n",
       "anime            608\n",
       "baseball         601\n",
       "canada           588\n",
       "conspiracy       541\n",
       "europe           595\n",
       "funny            609\n",
       "gameofthrones    589\n",
       "hockey           623\n",
       "leagueoflegends  618\n",
       "movies           584\n",
       "nba              599\n",
       "nfl              604\n",
       "soccer           613\n",
       "trees            618\n",
       "worldnews        590\n",
       "wow              600"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=classe_valid.groupby(['subreddit']).count()\n",
    "count.sort_values(by='subreddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>igual</th>\n",
       "      <th>count_subreddit</th>\n",
       "      <th>%_acertos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>18543759</td>\n",
       "      <td>186</td>\n",
       "      <td>609</td>\n",
       "      <td>0.305419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AskReddit</th>\n",
       "      <td>17636754</td>\n",
       "      <td>214</td>\n",
       "      <td>590</td>\n",
       "      <td>0.362712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>17133584</td>\n",
       "      <td>228</td>\n",
       "      <td>590</td>\n",
       "      <td>0.386441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy</th>\n",
       "      <td>16230416</td>\n",
       "      <td>254</td>\n",
       "      <td>541</td>\n",
       "      <td>0.469501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>17330563</td>\n",
       "      <td>277</td>\n",
       "      <td>588</td>\n",
       "      <td>0.471088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>19110665</td>\n",
       "      <td>307</td>\n",
       "      <td>630</td>\n",
       "      <td>0.487302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>17760953</td>\n",
       "      <td>296</td>\n",
       "      <td>595</td>\n",
       "      <td>0.497479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gameofthrones</th>\n",
       "      <td>17883785</td>\n",
       "      <td>308</td>\n",
       "      <td>589</td>\n",
       "      <td>0.522920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockey</th>\n",
       "      <td>19345930</td>\n",
       "      <td>337</td>\n",
       "      <td>623</td>\n",
       "      <td>0.540931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>18210804</td>\n",
       "      <td>335</td>\n",
       "      <td>618</td>\n",
       "      <td>0.542071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>17244947</td>\n",
       "      <td>324</td>\n",
       "      <td>584</td>\n",
       "      <td>0.554795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <td>18678996</td>\n",
       "      <td>345</td>\n",
       "      <td>613</td>\n",
       "      <td>0.562806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalOffensive</th>\n",
       "      <td>18140416</td>\n",
       "      <td>339</td>\n",
       "      <td>592</td>\n",
       "      <td>0.572635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>18732233</td>\n",
       "      <td>350</td>\n",
       "      <td>608</td>\n",
       "      <td>0.575658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>17980673</td>\n",
       "      <td>350</td>\n",
       "      <td>604</td>\n",
       "      <td>0.579470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>17411862</td>\n",
       "      <td>355</td>\n",
       "      <td>599</td>\n",
       "      <td>0.592654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leagueoflegends</th>\n",
       "      <td>17762439</td>\n",
       "      <td>386</td>\n",
       "      <td>618</td>\n",
       "      <td>0.624595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball</th>\n",
       "      <td>17815772</td>\n",
       "      <td>376</td>\n",
       "      <td>601</td>\n",
       "      <td>0.625624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overwatch</th>\n",
       "      <td>18454745</td>\n",
       "      <td>384</td>\n",
       "      <td>608</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>18027439</td>\n",
       "      <td>387</td>\n",
       "      <td>600</td>\n",
       "      <td>0.645000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id  igual  count_subreddit  %_acertos\n",
       "subreddit                                                   \n",
       "funny            18543759    186              609   0.305419\n",
       "AskReddit        17636754    214              590   0.362712\n",
       "worldnews        17133584    228              590   0.386441\n",
       "conspiracy       16230416    254              541   0.469501\n",
       "canada           17330563    277              588   0.471088\n",
       "Music            19110665    307              630   0.487302\n",
       "europe           17760953    296              595   0.497479\n",
       "gameofthrones    17883785    308              589   0.522920\n",
       "hockey           19345930    337              623   0.540931\n",
       "trees            18210804    335              618   0.542071\n",
       "movies           17244947    324              584   0.554795\n",
       "soccer           18678996    345              613   0.562806\n",
       "GlobalOffensive  18140416    339              592   0.572635\n",
       "anime            18732233    350              608   0.575658\n",
       "nfl              17980673    350              604   0.579470\n",
       "nba              17411862    355              599   0.592654\n",
       "leagueoflegends  17762439    386              618   0.624595\n",
       "baseball         17815772    376              601   0.625624\n",
       "Overwatch        18454745    384              608   0.631579\n",
       "wow              18027439    387              600   0.645000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "acertos['count_subreddit']=count['1']\n",
    "acertos['%_acertos']=acertos['igual']/acertos['count_subreddit']\n",
    "\n",
    "acertos.sort_values(by='%_acertos',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>previsao</th>\n",
       "      <th>Id</th>\n",
       "      <th>igual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35490</th>\n",
       "      <td>funny</td>\n",
       "      <td>europe</td>\n",
       "      <td>35490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45995</th>\n",
       "      <td>funny</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>45995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56925</th>\n",
       "      <td>funny</td>\n",
       "      <td>funny</td>\n",
       "      <td>56925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15274</th>\n",
       "      <td>funny</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>15274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8110</th>\n",
       "      <td>funny</td>\n",
       "      <td>anime</td>\n",
       "      <td>8110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41342</th>\n",
       "      <td>funny</td>\n",
       "      <td>europe</td>\n",
       "      <td>41342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8017</th>\n",
       "      <td>funny</td>\n",
       "      <td>funny</td>\n",
       "      <td>8017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33673</th>\n",
       "      <td>funny</td>\n",
       "      <td>funny</td>\n",
       "      <td>33673</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41983</th>\n",
       "      <td>funny</td>\n",
       "      <td>soccer</td>\n",
       "      <td>41983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54302</th>\n",
       "      <td>funny</td>\n",
       "      <td>europe</td>\n",
       "      <td>54302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>609 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit   previsao     Id  igual\n",
       "35490     funny     europe  35490      0\n",
       "45995     funny  worldnews  45995      0\n",
       "56925     funny      funny  56925      1\n",
       "15274     funny  AskReddit  15274      0\n",
       "8110      funny      anime   8110      0\n",
       "...         ...        ...    ...    ...\n",
       "41342     funny     europe  41342      0\n",
       "8017      funny      funny   8017      1\n",
       "33673     funny      funny  33673      1\n",
       "41983     funny     soccer  41983      0\n",
       "54302     funny     europe  54302      0\n",
       "\n",
       "[609 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funny=classe_valid2.loc[train['subreddit']=='funny']\n",
    "funny\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35490    Exactly. I see a lot of people say stuff like,...\n",
       "45995    The obesity I 100% agree with, but Johnson is ...\n",
       "15274    I think you're misunderstanding the purpose of...\n",
       "8110     Oh God why did you show me that? I could've go...\n",
       "54044    Oh no!\\n\\nOn a side note, I'm really impressed...\n",
       "                               ...                        \n",
       "22580    Dear Bank of America,  \\nLast week, Darkmuscle...\n",
       "51232    It appears he only became aware of the fake th...\n",
       "41342                       You are now banned from r/Sino\n",
       "41983    Is that... Ponce De Leon’s mythical fountain o...\n",
       "54302                            This is russian I knew it\n",
       "Name: comment, Length: 423, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errou=funny.loc[funny['igual']==0]\n",
    "errou=errou.join(train,lsuffix='_caller', rsuffix='_other')\n",
    "errou=errou[['Id','subreddit_caller','previsao','comment']]\n",
    "errou_comment=errou['comment']\n",
    "errou_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35490    Exactly. I see a lot of people say stuff like,...\n",
       "45995    The obesity I 100% agree with, but Johnson is ...\n",
       "15274    I think you're misunderstanding the purpose of...\n",
       "8110     Oh God why did you show me that? I could've go...\n",
       "54044    Oh no!\\n\\nOn a side note, I'm really impressed...\n",
       "                               ...                        \n",
       "22580    Dear Bank of America,  \\nLast week, Darkmuscle...\n",
       "51232    It appears he only became aware of the fake th...\n",
       "41342                       You are now banned from r/Sino\n",
       "41983    Is that... Ponce De Leon’s mythical fountain o...\n",
       "54302                            This is russian I knew it\n",
       "Name: comment, Length: 423, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errou_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criacao da VAR TOTAL OF WORDS\n",
    "\n",
    "errou['comment'].count()\n",
    "\n",
    "\n",
    "errou['totalwords'] = errou['comment'].str.count(' ') + 1\n",
    "\n",
    "errou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errou['totalwords'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bons=funny.loc[funny['igual']==1]\n",
    "bons=bons.join(train,lsuffix='_caller', rsuffix='_other')\n",
    "bons=bons[['Id','subreddit_caller','previsao','comment']]\n",
    "\n",
    "\n",
    "bons['comment'].count()\n",
    "\n",
    "\n",
    "bons['totalwords'] = bons['comment'].str.count(' ') + 1\n",
    "\n",
    "bons\n",
    "\n",
    "\n",
    "bons['totalwords'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "\n",
    "\n",
    "\n",
    "#clean\n",
    "bons['prep'] = bons['comment'].str.replace(r'[^\\w\\s]+', '') # tira td que nao palavra e espaco em branco\n",
    "bons['prep'] = bons['prep'].str.lower()\n",
    "bons['prep'] = bons['prep'].str.replace('(\\d+)', ' num ')\n",
    "bons['prep'] = bons['prep'].str.replace(r'http(?<=http).*', ' ')\n",
    "bons['prep'] = bons['prep'].str.replace(r'\\s+', \" \")\n",
    "bons['prep'] = bons['prep'].str.replace(\" +\", \" \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#clean\n",
    "errou['prep'] = errou['comment'].str.replace(r'[^\\w\\s]+', '')\n",
    "errou['prep'] = errou['prep'].str.lower()\n",
    "errou['prep'] = errou['prep'].str.replace('(\\d+)', ' num ')\n",
    "errou['prep'] = errou['prep'].str.replace(r'http(?<=http).*', ' ')\n",
    "errou['prep'] = errou['prep'].str.replace(r'\\s+', \" \")\n",
    "errou['prep'] = errou['prep'].str.replace(\" +\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tt = TweetTokenizer()\n",
    "def lemmatize_col(row):\n",
    "    row = tt.tokenize(row)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in row])\n",
    "\n",
    "bons['prep'] = bons['prep'].apply(lemmatize_col)\n",
    "errou['prep'] = errou['prep'].apply(lemmatize_col) \n",
    "\n",
    "# stopwords\n",
    "stop = stopwords.words('english')\n",
    "bons['prep'] = bons['prep'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "errou['prep'] = errou['prep'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bons_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errou_words=errou['prep'].str.split(expand=True).stack().value_counts()\n",
    "errou_words[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gerar arquivo \n",
    "\n",
    "previsoes_test = pd.DataFrame(previsoes_test, columns=['Category'])\n",
    "\n",
    "previsoes_test['Id'] = previsoes_test.index\n",
    "\n",
    "previsoes_test = previsoes_test.reindex(columns=['Id', 'Category'])\n",
    "\n",
    "previsoes_test.to_csv('linear_svc_17jul_2.csv', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
