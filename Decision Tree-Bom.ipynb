{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "\n",
    "# natural language toolkit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tag import pos_tag_sents\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# SciKit-Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "#train\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "\n",
    "\n",
    "comment_data = train\n",
    "\n",
    "#clean\n",
    "comment_data['prep'] = comment_data['comment'].str.replace(r'[^\\w\\s]+', '') # tira td que nao palavra e espaco em branco\n",
    "comment_data['prep'] = comment_data['prep'].str.lower()\n",
    "comment_data['prep'] = comment_data['prep'].str.replace('(\\d+)', ' num ')\n",
    "comment_data['prep'] = comment_data['prep'].str.replace(r'http(?<=http).*', ' ')\n",
    "comment_data['prep'] = comment_data['prep'].str.replace(r'\\s+', \" \")\n",
    "comment_data['prep'] = comment_data['prep'].str.replace(\" +\", \" \")\n",
    "\n",
    "#comment_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data = test\n",
    "#clean\n",
    "test_data['prep'] = test_data['comment'].str.replace(r'[^\\w\\s]+', '')\n",
    "test_data['prep'] = test_data['prep'].str.lower()\n",
    "test_data['prep'] = test_data['prep'].str.replace('(\\d+)', ' num ')\n",
    "test_data['prep'] = test_data['prep'].str.replace(r'http(?<=http).*', ' ')\n",
    "test_data['prep'] = test_data['prep'].str.replace(r'\\s+', \" \")\n",
    "test_data['prep'] = test_data['prep'].str.replace(\" +\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tt = TweetTokenizer()\n",
    "def lemmatize_col(row):\n",
    "    row = tt.tokenize(row)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in row])\n",
    "\n",
    "comment_data['prep'] = comment_data['prep'].apply(lemmatize_col)\n",
    "test_data['prep'] = test_data['prep'].apply(lemmatize_col)\n",
    "\n",
    "# stopwords\n",
    "stop = stopwords.words('english')\n",
    "comment_data['prep'] = comment_data['prep'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "test_data['prep'] = test_data['prep'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = comment_data['prep'].to_numpy()\n",
    "clean_labels = comment_data['subreddit'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#com pre proc\n",
    "\n",
    "clean_data\n",
    "clean_labels\n",
    "\n",
    "clean_test=test_data['prep']\n",
    "#features_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### com preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 10.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28099999999999997\n",
      "{'mean_fit_time': array([109.53653725,  78.25729593,  70.16194574,  80.4855183 ,\n",
      "        58.46328163,  60.53703634,  60.54092733,  61.12919172,\n",
      "        90.86585164,  84.41392016]), 'std_fit_time': array([ 0.67646766, 17.79949636,  8.16119288,  0.67793147,  0.2942137 ,\n",
      "        1.62034554,  0.29106425,  1.38394375,  1.22073467,  4.20848265]), 'mean_score_time': array([1.4823854 , 1.37764843, 1.47404965, 1.53144844, 1.42962011,\n",
      "       1.41660412, 1.37138255, 2.0242219 , 2.19510587, 1.99014982]), 'std_score_time': array([0.1018871 , 0.02819107, 0.1103874 , 0.01523926, 0.06072799,\n",
      "       0.09494082, 0.10242028, 0.10251352, 0.10093275, 0.65521162]), 'param_clf__criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf__min_samples_split': masked_array(data=[2, 12, 22, 32, 42, 52, 62, 72, 82, 92],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf__criterion': 'gini', 'clf__min_samples_split': 2}, {'clf__criterion': 'gini', 'clf__min_samples_split': 12}, {'clf__criterion': 'gini', 'clf__min_samples_split': 22}, {'clf__criterion': 'gini', 'clf__min_samples_split': 32}, {'clf__criterion': 'gini', 'clf__min_samples_split': 42}, {'clf__criterion': 'gini', 'clf__min_samples_split': 52}, {'clf__criterion': 'gini', 'clf__min_samples_split': 62}, {'clf__criterion': 'gini', 'clf__min_samples_split': 72}, {'clf__criterion': 'gini', 'clf__min_samples_split': 82}, {'clf__criterion': 'gini', 'clf__min_samples_split': 92}], 'split0_test_score': array([0.26255, 0.26615, 0.2674 , 0.27055, 0.27235, 0.2721 , 0.2739 ,\n",
      "       0.2763 , 0.27465, 0.2764 ]), 'split1_test_score': array([0.26935, 0.27225, 0.27615, 0.27745, 0.2785 , 0.2806 , 0.28085,\n",
      "       0.28305, 0.2852 , 0.28485]), 'split2_test_score': array([0.26965, 0.26905, 0.27385, 0.2754 , 0.27745, 0.27705, 0.28005,\n",
      "       0.28205, 0.2797 , 0.28175]), 'mean_test_score': array([0.26718333, 0.26915   , 0.27246667, 0.27446667, 0.2761    ,\n",
      "       0.27658333, 0.27826667, 0.28046667, 0.27985   , 0.281     ]), 'std_test_score': array([0.00327855, 0.00249132, 0.00370368, 0.00289319, 0.00268608,\n",
      "       0.00348576, 0.00310492, 0.00297443, 0.00430833, 0.00349022]), 'rank_test_score': array([10,  9,  8,  7,  6,  5,  4,  2,  3,  1], dtype=int32)}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clean_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a3fea6b3139d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprevisoes_test_pre_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_test' is not defined"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm=Normalizer()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_dist = {'clf__criterion': ['gini'],\n",
    "             'clf__min_samples_split': range(2,100,10)}\n",
    "\n",
    "\n",
    "\n",
    "pipeline_DecisionTreeClassifier = Pipeline([\n",
    "                     ('vect', CountVectorizer(ngram_range=(1,2), min_df = 10, max_df = 1.)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('norm', Normalizer()),\n",
    "                     ('clf', DecisionTreeClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_DecisionTreeClassifier, param_grid = param_dist, n_jobs=-1, verbose=1, cv=3, scoring='accuracy')\n",
    "grid_search.fit(clean_data, clean_labels)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.cv_results_)\n",
    "\n",
    "previsoes_test_pre_proc=grid_search.predict(clean_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anotar resultados 0.2675666666666667\\n\\ncv=10 ...0.2770166666666667'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''anotar resultados 0.2675666666666667\n",
    "\n",
    "cv=10 ...0.2770166666666667'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Holy shit a shot counter.</td>\n",
       "      <td>think prestige point expire ever skin buy avai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It doesn't matter that it isn't hard to rememb...</td>\n",
       "      <td>whats going happen refused asilum appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I find it funny that this is downvoted</td>\n",
       "      <td>anecdotal evidence anecdotal clearly everyone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>They are really getting ridicoulous with all t...</td>\n",
       "      <td>look dude due respect music isnt people look l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>He's Eden's best friend</td>\n",
       "      <td>hope get doomhammer back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>19995</td>\n",
       "      <td>These officials are almost as incompetent as o...</td>\n",
       "      <td>see one frame smile num chilling many goosebump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19996</td>\n",
       "      <td>honestly the Patriot act really fucked our com...</td>\n",
       "      <td>people spend time money movie dont want see ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19997</td>\n",
       "      <td>My friend is now looking online for a thanos c...</td>\n",
       "      <td>said let watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>19998</td>\n",
       "      <td>I really liked Thor Ragnarok and both Guardian...</td>\n",
       "      <td>im sure count second enterprise term battle star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>19999</td>\n",
       "      <td>last info changes everything.</td>\n",
       "      <td>would assume ru back okc gimme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment  \\\n",
       "0          0                          Holy shit a shot counter.   \n",
       "1          1  It doesn't matter that it isn't hard to rememb...   \n",
       "2          2             I find it funny that this is downvoted   \n",
       "3          3  They are really getting ridicoulous with all t...   \n",
       "4          4                            He's Eden's best friend   \n",
       "...      ...                                                ...   \n",
       "19995  19995  These officials are almost as incompetent as o...   \n",
       "19996  19996  honestly the Patriot act really fucked our com...   \n",
       "19997  19997  My friend is now looking online for a thanos c...   \n",
       "19998  19998  I really liked Thor Ragnarok and both Guardian...   \n",
       "19999  19999                      last info changes everything.   \n",
       "\n",
       "                                                    prep  \n",
       "0      think prestige point expire ever skin buy avai...  \n",
       "1               whats going happen refused asilum appeal  \n",
       "2      anecdotal evidence anecdotal clearly everyone ...  \n",
       "3      look dude due respect music isnt people look l...  \n",
       "4                               hope get doomhammer back  \n",
       "...                                                  ...  \n",
       "19995    see one frame smile num chilling many goosebump  \n",
       "19996  people spend time money movie dont want see ty...  \n",
       "19997                                     said let watch  \n",
       "19998   im sure count second enterprise term battle star  \n",
       "19999                     would assume ru back okc gimme  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Holy shit a shot counter.</td>\n",
       "      <td>think prestige point expire ever skin buy avai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It doesn't matter that it isn't hard to rememb...</td>\n",
       "      <td>whats going happen refused asilum appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I find it funny that this is downvoted</td>\n",
       "      <td>anecdotal evidence anecdotal clearly everyone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>They are really getting ridicoulous with all t...</td>\n",
       "      <td>look dude due respect music isnt people look l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>He's Eden's best friend</td>\n",
       "      <td>hope get doomhammer back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>19995</td>\n",
       "      <td>These officials are almost as incompetent as o...</td>\n",
       "      <td>see one frame smile num chilling many goosebump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19996</td>\n",
       "      <td>honestly the Patriot act really fucked our com...</td>\n",
       "      <td>people spend time money movie dont want see ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19997</td>\n",
       "      <td>My friend is now looking online for a thanos c...</td>\n",
       "      <td>said let watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>19998</td>\n",
       "      <td>I really liked Thor Ragnarok and both Guardian...</td>\n",
       "      <td>im sure count second enterprise term battle star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>19999</td>\n",
       "      <td>last info changes everything.</td>\n",
       "      <td>would assume ru back okc gimme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            comment  \\\n",
       "0          0                          Holy shit a shot counter.   \n",
       "1          1  It doesn't matter that it isn't hard to rememb...   \n",
       "2          2             I find it funny that this is downvoted   \n",
       "3          3  They are really getting ridicoulous with all t...   \n",
       "4          4                            He's Eden's best friend   \n",
       "...      ...                                                ...   \n",
       "19995  19995  These officials are almost as incompetent as o...   \n",
       "19996  19996  honestly the Patriot act really fucked our com...   \n",
       "19997  19997  My friend is now looking online for a thanos c...   \n",
       "19998  19998  I really liked Thor Ragnarok and both Guardian...   \n",
       "19999  19999                      last info changes everything.   \n",
       "\n",
       "                                                    prep  \n",
       "0      think prestige point expire ever skin buy avai...  \n",
       "1               whats going happen refused asilum appeal  \n",
       "2      anecdotal evidence anecdotal clearly everyone ...  \n",
       "3      look dude due respect music isnt people look l...  \n",
       "4                               hope get doomhammer back  \n",
       "...                                                  ...  \n",
       "19995    see one frame smile num chilling many goosebump  \n",
       "19996  people spend time money movie dont want see ty...  \n",
       "19997                                     said let watch  \n",
       "19998   im sure count second enterprise term battle star  \n",
       "19999                     would assume ru back okc gimme  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        I think prestige points should not expire ever...\n",
       "1        Whats going to happen with them if they will b...\n",
       "2        Anecdotal evidence is anecdotal. Clearly by “e...\n",
       "3        Look dude, with all due respect, your music is...\n",
       "4                        Hope he gets the doomhammer back!\n",
       "                               ...                        \n",
       "59995                         Yo this guy Luka pretty good\n",
       "59996                        Unplug these things right now\n",
       "59997    Well said. Do you think they’ll resonate with ...\n",
       "59998    So we can impeach a president for lying? Pleas...\n",
       "59999    Too broad dude, get ready for the shit my pant...\n",
       "Name: comment, Length: 60000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SEM PRE PROC\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "#print(train)\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "features_train=train['comment']\n",
    "\n",
    "target_train=train['subreddit']\n",
    "\n",
    "\n",
    "\n",
    "features_test=test['comment']\n",
    "\n",
    "\n",
    "features_train\n",
    "#target_train\n",
    "\n",
    "#test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                Holy shit a shot counter.\n",
       "1        It doesn't matter that it isn't hard to rememb...\n",
       "2                   I find it funny that this is downvoted\n",
       "3        They are really getting ridicoulous with all t...\n",
       "4                                  He's Eden's best friend\n",
       "                               ...                        \n",
       "19995    These officials are almost as incompetent as o...\n",
       "19996    honestly the Patriot act really fucked our com...\n",
       "19997    My friend is now looking online for a thanos c...\n",
       "19998    I really liked Thor Ragnarok and both Guardian...\n",
       "19999                        last info changes everything.\n",
       "Name: comment, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sem preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21385\n",
      "{'mean_fit_time': array([115.29111938]), 'std_fit_time': array([26.91406565]), 'mean_score_time': array([0.47483046]), 'std_score_time': array([0.23469801]), 'params': [{}], 'split0_test_score': array([0.20516667]), 'split1_test_score': array([0.218]), 'split2_test_score': array([0.2145]), 'split3_test_score': array([0.21333333]), 'split4_test_score': array([0.2065]), 'split5_test_score': array([0.2185]), 'split6_test_score': array([0.21816667]), 'split7_test_score': array([0.21966667]), 'split8_test_score': array([0.20833333]), 'split9_test_score': array([0.21633333]), 'mean_test_score': array([0.21385]), 'std_test_score': array([0.00507962]), 'rank_test_score': array([1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm=Normalizer()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "pipeline_DecisionTreeClassifier = Pipeline([\n",
    "                     ('vect', CountVectorizer()),\n",
    "                     ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('norm', Normalizer()),\n",
    "                     ('clf', DecisionTreeClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_DecisionTreeClassifier, {}, n_jobs=-1, verbose=1, cv=10, scoring='accuracy')\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.cv_results_)\n",
    "\n",
    "previsoes_test=grid_search.predict(features_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results  0.2060666666666667\\n\\nresults cv=5 ...0.20988333333333334\\n\\nresults cv=10 ...0.21385'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''results  0.2060666666666667\n",
    "\n",
    "results cv=5 ...0.20988333333333334\n",
    "\n",
    "results cv=10 ...0.21385'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#gerar arquivo \\n\\nprevisoes_test = pd.DataFrame(previsoes_test, columns=['Category'])\\n\\nprevisoes_test['Id'] = previsoes_test.index\\n\\nprevisoes_test = previsoes_test.reindex(columns=['Id', 'Category'])\\n\\nprevisoes_test.to_csv('decision_tree_17jul.csv', index=False)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#gerar arquivo \n",
    "\n",
    "previsoes_test = pd.DataFrame(previsoes_test, columns=['Category'])\n",
    "\n",
    "previsoes_test['Id'] = previsoes_test.index\n",
    "\n",
    "previsoes_test = previsoes_test.reindex(columns=['Id', 'Category'])\n",
    "\n",
    "previsoes_test.to_csv('decision_tree_17jul.csv', index=False)\n",
    "'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
