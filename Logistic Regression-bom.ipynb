{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "\n",
    "# natural language toolkit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tag import pos_tag_sents\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# SciKit-Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "#train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "\n",
    "\n",
    "comment_data = train\n",
    "\n",
    "#clean\n",
    "comment_data['prep'] = comment_data['comment'].str.replace(r'[^\\w\\s]+', '') # tira td que nao palavra e espaco em branco\n",
    "comment_data['prep'] = comment_data['prep'].str.lower()\n",
    "comment_data['prep'] = comment_data['prep'].str.replace('(\\d+)', ' num ')\n",
    "comment_data['prep'] = comment_data['prep'].str.replace(r'http(?<=http).*', ' ')\n",
    "comment_data['prep'] = comment_data['prep'].str.replace(r'\\s+', \" \")\n",
    "comment_data['prep'] = comment_data['prep'].str.replace(\" +\", \" \")\n",
    "\n",
    "#comment_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data = test\n",
    "#clean\n",
    "test_data['prep'] = test_data['comment'].str.replace(r'[^\\w\\s]+', '')\n",
    "test_data['prep'] = test_data['prep'].str.lower()\n",
    "test_data['prep'] = test_data['prep'].str.replace('(\\d+)', ' num ')\n",
    "test_data['prep'] = test_data['prep'].str.replace(r'http(?<=http).*', ' ')\n",
    "test_data['prep'] = test_data['prep'].str.replace(r'\\s+', \" \")\n",
    "test_data['prep'] = test_data['prep'].str.replace(\" +\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tt = TweetTokenizer()\n",
    "def lemmatize_col(row):\n",
    "    row = tt.tokenize(row)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in row])\n",
    "\n",
    "comment_data['prep'] = comment_data['prep'].apply(lemmatize_col)\n",
    "test_data['prep'] = test_data['prep'].apply(lemmatize_col)\n",
    "\n",
    "# stopwords\n",
    "stop = stopwords.words('english')\n",
    "comment_data['prep'] = comment_data['prep'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "test_data['prep'] = test_data['prep'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = comment_data['prep'].to_numpy()\n",
    "clean_labels = comment_data['subreddit'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#com pre proc\n",
    "\n",
    "clean_data\n",
    "clean_labels\n",
    "\n",
    "clean_test=test_data['prep']\n",
    "#features_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### com pre proc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, top=3):\n",
    "    for i in range(1, top+1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 1462.70 seconds for 5 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.455 (std: 0.005)\n",
      "Parameters: {'clf__C': 1.3250000000000002, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.453 (std: 0.005)\n",
      "Parameters: {'clf__C': 2.5500000000000003, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.450 (std: 0.006)\n",
      "Parameters: {'clf__C': 3.7750000000000004, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Logistic Regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm=Normalizer()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "\n",
    "param_dist = {'clf__penalty': ['l2'],\n",
    "              'clf__solver': ['liblinear'],\n",
    "              'clf__C': np.linspace(0.1,5,5)}\n",
    "clf = LogisticRegression(multi_class='auto')\n",
    "text_clf = Pipeline([('vect',CountVectorizer(stop_words='english', ngram_range=(1,2), min_df = 10, max_df = 1.)),('tfidf',TfidfTransformer()),('clf',clf)])\n",
    "random_search = GridSearchCV(text_clf, param_grid = param_dist, cv=10)\n",
    "start_time = time.time()\n",
    "random_search.fit(clean_data, clean_labels)\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start_time), len(random_search.cv_results_['params'])))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GridSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start_time), len(random_search.cv_results_['params'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.9min finished\n",
      "/home/gabriel/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47614999999999996\n",
      "{'mean_fit_time': array([61.58336327]), 'std_fit_time': array([15.70865445]), 'mean_score_time': array([0.43635411]), 'std_score_time': array([0.12109717]), 'params': [{}], 'split0_test_score': array([0.47316667]), 'split1_test_score': array([0.47366667]), 'split2_test_score': array([0.47516667]), 'split3_test_score': array([0.4695]), 'split4_test_score': array([0.4705]), 'split5_test_score': array([0.47633333]), 'split6_test_score': array([0.478]), 'split7_test_score': array([0.48883333]), 'split8_test_score': array([0.4785]), 'split9_test_score': array([0.47783333]), 'mean_test_score': array([0.47615]), 'std_test_score': array([0.00514644]), 'rank_test_score': array([1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm=Normalizer()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_dist = {'clf__penalty': ['l2'],\n",
    "              'clf__solver': ['liblinear'],\n",
    "              'clf__C': np.linspace(0.1,5,5)}\n",
    "\n",
    "\n",
    "pipeline_LogisticRegression = Pipeline([\n",
    "                     ('vect', CountVectorizer()),\n",
    "                     ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('norm', Normalizer()),\n",
    "                     ('clf', LogisticRegression(multi_class='auto', random_state=0))\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_LogisticRegression, {}, n_jobs=-1, verbose=1, cv=10, scoring='accuracy')\n",
    "grid_search.fit(clean_data, clean_labels)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.cv_results_)\n",
    "\n",
    "previsoes_test_pre_proc=grid_search.predict(clean_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncv=5 ...0.4705333333333333\\n\\ncv=10... 0.47614999999999996'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cv=5 ...0.4705333333333333\n",
    "\n",
    "cv=10... 0.47614999999999996'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        I think prestige points should not expire ever...\n",
       "1        Whats going to happen with them if they will b...\n",
       "2        Anecdotal evidence is anecdotal. Clearly by “e...\n",
       "3        Look dude, with all due respect, your music is...\n",
       "4                        Hope he gets the doomhammer back!\n",
       "                               ...                        \n",
       "59995                         Yo this guy Luka pretty good\n",
       "59996                        Unplug these things right now\n",
       "59997    Well said. Do you think they’ll resonate with ...\n",
       "59998    So we can impeach a president for lying? Pleas...\n",
       "59999    Too broad dude, get ready for the shit my pant...\n",
       "Name: comment, Length: 60000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SEM PRE PROC\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "#print(train)\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "features_train=train['comment']\n",
    "\n",
    "target_train=train['subreddit']\n",
    "\n",
    "\n",
    "\n",
    "features_test=test['comment']\n",
    "\n",
    "\n",
    "features_train\n",
    "#target_train\n",
    "\n",
    "#test.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### sem preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  3.4min finished\n",
      "/home/gabriel/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47783333333333344\n",
      "{'mean_fit_time': array([71.05292385]), 'std_fit_time': array([14.59525171]), 'mean_score_time': array([0.76388927]), 'std_score_time': array([0.24300821]), 'params': [{}], 'split0_test_score': array([0.4805]), 'split1_test_score': array([0.48266667]), 'split2_test_score': array([0.475]), 'split3_test_score': array([0.4595]), 'split4_test_score': array([0.47016667]), 'split5_test_score': array([0.48033333]), 'split6_test_score': array([0.48316667]), 'split7_test_score': array([0.49133333]), 'split8_test_score': array([0.47566667]), 'split9_test_score': array([0.48]), 'mean_test_score': array([0.47783333]), 'std_test_score': array([0.00812233]), 'rank_test_score': array([1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "pipeline_LogisticRegression = Pipeline([\n",
    "                     ('vect', CountVectorizer()),\n",
    "                     ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('norm', Normalizer()),\n",
    "                     ('clf', LogisticRegression(random_state=0))\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_LogisticRegression, {}, n_jobs=-1, verbose=1, cv=10, scoring='accuracy')\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.cv_results_)\n",
    "\n",
    "previsoes_test=grid_search.predict(features_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresults cv=5 ...0.4705333333333333\\n\\nresults cv=10 ... 0.47783333333333344'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "results cv=5 ...0.4705333333333333\n",
    "\n",
    "results cv=10 ... 0.47783333333333344'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#gerar arquivo \\n\\nprevisoes_test = pd.DataFrame(previsoes_test, columns=['Category'])\\n\\nprevisoes_test['Id'] = previsoes_test.index\\n\\nprevisoes_test = previsoes_test.reindex(columns=['Id', 'Category'])\\n\\nprevisoes_test.to_csv('logistic_regression_17jul.csv', index=False)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#gerar arquivo \n",
    "\n",
    "previsoes_test = pd.DataFrame(previsoes_test, columns=['Category'])\n",
    "\n",
    "previsoes_test['Id'] = previsoes_test.index\n",
    "\n",
    "previsoes_test = previsoes_test.reindex(columns=['Id', 'Category'])\n",
    "\n",
    "previsoes_test.to_csv('logistic_regression_17jul.csv', index=False)'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
