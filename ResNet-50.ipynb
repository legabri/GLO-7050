{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fk1C3Py2DHnq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from urllib.request import urlopen,urlretrieve\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "#from resnets_utils import *\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.datasets import load_files   \n",
    "from keras.utils import np_utils\n",
    "from glob import glob\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras import optimizers\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZHTTymuONIF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "\n",
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3\n",
    "\n",
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [12288, 1])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNPVYGYLMPEv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "VAFRYI-7WGGW",
    "outputId": "892eab6d-9ebf-427f-f7f8-62ad4dbf5fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRJTgDDND6wJ"
   },
   "outputs": [],
   "source": [
    "img_height,img_width = 64,64 \n",
    "num_classes = 10\n",
    "#If imagenet weights are being loaded, \n",
    "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
    "base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_ihcci-D67b"
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "62P7R6ldh2Wg",
    "outputId": "67c28783-d920-4c6a-bd9b-0eea4b9f7bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0052s vs `on_test_batch_end` time: 0.0115s). Check your callbacks.\n",
      "1000/1000 - 45s - loss: 0.1094 - accuracy: 0.9669 - val_loss: 0.4750 - val_accuracy: 0.8991\n",
      "Epoch 2/100\n",
      "1000/1000 - 44s - loss: 0.1099 - accuracy: 0.9664 - val_loss: 0.4348 - val_accuracy: 0.9065\n",
      "Epoch 3/100\n",
      "1000/1000 - 44s - loss: 0.1858 - accuracy: 0.9453 - val_loss: 2.2090 - val_accuracy: 0.7735\n",
      "Epoch 4/100\n",
      "1000/1000 - 44s - loss: 0.2459 - accuracy: 0.9319 - val_loss: 0.4731 - val_accuracy: 0.8831\n",
      "Epoch 5/100\n",
      "1000/1000 - 44s - loss: 0.1228 - accuracy: 0.9595 - val_loss: 0.4469 - val_accuracy: 0.8946\n",
      "Epoch 6/100\n",
      "1000/1000 - 44s - loss: 0.1088 - accuracy: 0.9667 - val_loss: 0.5189 - val_accuracy: 0.8896\n",
      "Epoch 7/100\n",
      "1000/1000 - 44s - loss: 0.0974 - accuracy: 0.9696 - val_loss: 0.4900 - val_accuracy: 0.8951\n",
      "Epoch 8/100\n",
      "1000/1000 - 44s - loss: 0.1039 - accuracy: 0.9673 - val_loss: 0.4630 - val_accuracy: 0.8939\n",
      "Epoch 9/100\n",
      "1000/1000 - 44s - loss: 0.1059 - accuracy: 0.9669 - val_loss: 0.4595 - val_accuracy: 0.9001\n",
      "Epoch 10/100\n",
      "1000/1000 - 44s - loss: 0.1084 - accuracy: 0.9658 - val_loss: 0.6486 - val_accuracy: 0.8546\n",
      "Epoch 11/100\n",
      "1000/1000 - 44s - loss: 0.1111 - accuracy: 0.9655 - val_loss: 0.5197 - val_accuracy: 0.8896\n",
      "Epoch 12/100\n",
      "1000/1000 - 44s - loss: 0.1022 - accuracy: 0.9662 - val_loss: 0.5289 - val_accuracy: 0.8906\n",
      "Epoch 13/100\n",
      "1000/1000 - 44s - loss: 0.0923 - accuracy: 0.9684 - val_loss: 0.5127 - val_accuracy: 0.8905\n",
      "Epoch 14/100\n",
      "1000/1000 - 44s - loss: 0.1453 - accuracy: 0.9581 - val_loss: 0.4905 - val_accuracy: 0.8805\n",
      "Epoch 15/100\n",
      "1000/1000 - 44s - loss: 0.1273 - accuracy: 0.9591 - val_loss: 0.4637 - val_accuracy: 0.8929\n",
      "Epoch 16/100\n",
      "1000/1000 - 44s - loss: 0.0937 - accuracy: 0.9687 - val_loss: 0.4074 - val_accuracy: 0.9071\n",
      "Epoch 17/100\n",
      "1000/1000 - 44s - loss: 0.0950 - accuracy: 0.9702 - val_loss: 0.4669 - val_accuracy: 0.8960\n",
      "Epoch 18/100\n",
      "1000/1000 - 44s - loss: 0.0906 - accuracy: 0.9695 - val_loss: 0.4325 - val_accuracy: 0.9018\n",
      "Epoch 19/100\n",
      "1000/1000 - 44s - loss: 0.0947 - accuracy: 0.9693 - val_loss: 0.5728 - val_accuracy: 0.8669\n",
      "Epoch 20/100\n",
      "1000/1000 - 44s - loss: 0.0947 - accuracy: 0.9682 - val_loss: 0.5106 - val_accuracy: 0.8861\n",
      "Epoch 21/100\n",
      "1000/1000 - 44s - loss: 0.0945 - accuracy: 0.9699 - val_loss: 0.4245 - val_accuracy: 0.9044\n",
      "Epoch 22/100\n",
      "1000/1000 - 44s - loss: 0.0998 - accuracy: 0.9702 - val_loss: 0.4480 - val_accuracy: 0.8965\n",
      "Epoch 23/100\n",
      "1000/1000 - 44s - loss: 0.1668 - accuracy: 0.9538 - val_loss: 0.5239 - val_accuracy: 0.8740\n",
      "Epoch 24/100\n",
      "1000/1000 - 44s - loss: 0.1019 - accuracy: 0.9674 - val_loss: 0.4099 - val_accuracy: 0.9020\n",
      "Epoch 25/100\n",
      "1000/1000 - 44s - loss: 0.1108 - accuracy: 0.9655 - val_loss: 0.4082 - val_accuracy: 0.9031\n",
      "Epoch 26/100\n",
      "1000/1000 - 44s - loss: 0.0926 - accuracy: 0.9709 - val_loss: 0.4793 - val_accuracy: 0.8985\n",
      "Epoch 27/100\n",
      "1000/1000 - 44s - loss: 0.1448 - accuracy: 0.9567 - val_loss: 0.4555 - val_accuracy: 0.8946\n",
      "Epoch 28/100\n",
      "1000/1000 - 44s - loss: 0.0854 - accuracy: 0.9718 - val_loss: 0.4385 - val_accuracy: 0.9051\n",
      "Epoch 29/100\n",
      "1000/1000 - 44s - loss: 0.0838 - accuracy: 0.9723 - val_loss: 0.4830 - val_accuracy: 0.8946\n",
      "Epoch 30/100\n",
      "1000/1000 - 44s - loss: 0.0812 - accuracy: 0.9724 - val_loss: 0.5218 - val_accuracy: 0.8901\n",
      "Epoch 31/100\n",
      "1000/1000 - 44s - loss: 0.0860 - accuracy: 0.9725 - val_loss: 0.4620 - val_accuracy: 0.8916\n",
      "Epoch 32/100\n",
      "1000/1000 - 44s - loss: 0.0856 - accuracy: 0.9707 - val_loss: 0.5158 - val_accuracy: 0.8834\n",
      "Epoch 33/100\n",
      "1000/1000 - 44s - loss: 0.0919 - accuracy: 0.9699 - val_loss: 0.5361 - val_accuracy: 0.8817\n",
      "Epoch 34/100\n",
      "1000/1000 - 44s - loss: 0.0910 - accuracy: 0.9720 - val_loss: 0.4408 - val_accuracy: 0.9010\n",
      "Epoch 35/100\n",
      "1000/1000 - 44s - loss: 0.0841 - accuracy: 0.9716 - val_loss: 0.5414 - val_accuracy: 0.8924\n",
      "Epoch 36/100\n",
      "1000/1000 - 44s - loss: 0.0811 - accuracy: 0.9732 - val_loss: 0.4737 - val_accuracy: 0.8996\n",
      "Epoch 37/100\n",
      "1000/1000 - 44s - loss: 0.1176 - accuracy: 0.9674 - val_loss: 0.4658 - val_accuracy: 0.8984\n",
      "Epoch 38/100\n",
      "1000/1000 - 44s - loss: 0.2128 - accuracy: 0.9455 - val_loss: 0.5075 - val_accuracy: 0.8859\n",
      "Epoch 39/100\n",
      "1000/1000 - 44s - loss: 0.1030 - accuracy: 0.9667 - val_loss: 0.4630 - val_accuracy: 0.8972\n",
      "Epoch 40/100\n",
      "1000/1000 - 44s - loss: 0.0829 - accuracy: 0.9746 - val_loss: 0.4630 - val_accuracy: 0.8985\n",
      "Epoch 41/100\n",
      "1000/1000 - 44s - loss: 0.0728 - accuracy: 0.9774 - val_loss: 0.6245 - val_accuracy: 0.8734\n",
      "Epoch 42/100\n",
      "1000/1000 - 44s - loss: 0.0910 - accuracy: 0.9710 - val_loss: 0.4540 - val_accuracy: 0.9026\n",
      "Epoch 43/100\n",
      "1000/1000 - 44s - loss: 0.0791 - accuracy: 0.9753 - val_loss: 0.4520 - val_accuracy: 0.9046\n",
      "Epoch 44/100\n",
      "1000/1000 - 44s - loss: 0.0900 - accuracy: 0.9728 - val_loss: 0.4515 - val_accuracy: 0.9057\n",
      "Epoch 45/100\n",
      "1000/1000 - 44s - loss: 0.0935 - accuracy: 0.9703 - val_loss: 0.5212 - val_accuracy: 0.8848\n",
      "Epoch 46/100\n",
      "1000/1000 - 44s - loss: 0.0864 - accuracy: 0.9724 - val_loss: 0.4333 - val_accuracy: 0.9044\n",
      "Epoch 47/100\n",
      "1000/1000 - 44s - loss: 0.0821 - accuracy: 0.9737 - val_loss: 0.4582 - val_accuracy: 0.9016\n",
      "Epoch 48/100\n",
      "1000/1000 - 44s - loss: 0.0854 - accuracy: 0.9737 - val_loss: 0.4918 - val_accuracy: 0.8953\n",
      "Epoch 49/100\n",
      "1000/1000 - 44s - loss: 0.0822 - accuracy: 0.9735 - val_loss: 0.4206 - val_accuracy: 0.9078\n",
      "Epoch 50/100\n",
      "1000/1000 - 44s - loss: 0.2021 - accuracy: 0.9461 - val_loss: 0.4975 - val_accuracy: 0.8876\n",
      "Epoch 51/100\n",
      "1000/1000 - 44s - loss: 0.1546 - accuracy: 0.9581 - val_loss: 0.4689 - val_accuracy: 0.8863\n",
      "Epoch 52/100\n",
      "1000/1000 - 44s - loss: 0.1002 - accuracy: 0.9694 - val_loss: 0.4383 - val_accuracy: 0.8979\n",
      "Epoch 53/100\n",
      "1000/1000 - 44s - loss: 0.0697 - accuracy: 0.9769 - val_loss: 0.4291 - val_accuracy: 0.9040\n",
      "Epoch 54/100\n",
      "1000/1000 - 44s - loss: 0.1071 - accuracy: 0.9668 - val_loss: 0.4092 - val_accuracy: 0.9070\n",
      "Epoch 55/100\n",
      "1000/1000 - 44s - loss: 0.1630 - accuracy: 0.9536 - val_loss: 0.5069 - val_accuracy: 0.8836\n",
      "Epoch 56/100\n",
      "1000/1000 - 44s - loss: 0.0937 - accuracy: 0.9717 - val_loss: 0.4961 - val_accuracy: 0.8907\n",
      "Epoch 57/100\n",
      "1000/1000 - 44s - loss: 0.2261 - accuracy: 0.9493 - val_loss: 2.3932 - val_accuracy: 0.8622\n",
      "Epoch 58/100\n",
      "1000/1000 - 44s - loss: 0.1433 - accuracy: 0.9625 - val_loss: 3.7253 - val_accuracy: 0.6221\n",
      "Epoch 59/100\n",
      "1000/1000 - 44s - loss: 0.1583 - accuracy: 0.9551 - val_loss: 14.4017 - val_accuracy: 0.8290\n",
      "Epoch 60/100\n",
      "1000/1000 - 44s - loss: 0.0949 - accuracy: 0.9709 - val_loss: 5.1918 - val_accuracy: 0.8696\n",
      "Epoch 61/100\n",
      "1000/1000 - 44s - loss: 0.0780 - accuracy: 0.9743 - val_loss: 2.4199 - val_accuracy: 0.8866\n",
      "Epoch 62/100\n",
      "1000/1000 - 44s - loss: 0.0731 - accuracy: 0.9776 - val_loss: 0.7665 - val_accuracy: 0.8846\n",
      "Epoch 63/100\n",
      "1000/1000 - 44s - loss: 0.0749 - accuracy: 0.9742 - val_loss: 0.4528 - val_accuracy: 0.9011\n",
      "Epoch 64/100\n",
      "1000/1000 - 44s - loss: 0.0752 - accuracy: 0.9749 - val_loss: 0.5182 - val_accuracy: 0.8924\n",
      "Epoch 65/100\n",
      "1000/1000 - 44s - loss: 0.0925 - accuracy: 0.9710 - val_loss: 0.6288 - val_accuracy: 0.8670\n",
      "Epoch 66/100\n",
      "1000/1000 - 44s - loss: 0.0883 - accuracy: 0.9723 - val_loss: 0.4853 - val_accuracy: 0.9013\n",
      "Epoch 67/100\n",
      "1000/1000 - 44s - loss: 0.0838 - accuracy: 0.9748 - val_loss: 0.4498 - val_accuracy: 0.9024\n",
      "Epoch 68/100\n",
      "1000/1000 - 44s - loss: 0.0735 - accuracy: 0.9761 - val_loss: 0.4698 - val_accuracy: 0.9011\n",
      "Epoch 69/100\n",
      "1000/1000 - 44s - loss: 0.0712 - accuracy: 0.9767 - val_loss: 0.6329 - val_accuracy: 0.8991\n",
      "Epoch 70/100\n",
      "1000/1000 - 44s - loss: 0.0691 - accuracy: 0.9777 - val_loss: 1.4579 - val_accuracy: 0.8890\n",
      "Epoch 71/100\n",
      "1000/1000 - 44s - loss: 0.0689 - accuracy: 0.9774 - val_loss: 0.4517 - val_accuracy: 0.9015\n",
      "Epoch 72/100\n",
      "1000/1000 - 44s - loss: 0.0946 - accuracy: 0.9698 - val_loss: 0.4519 - val_accuracy: 0.9010\n",
      "Epoch 73/100\n",
      "1000/1000 - 44s - loss: 0.0682 - accuracy: 0.9776 - val_loss: 0.4991 - val_accuracy: 0.8935\n",
      "Epoch 74/100\n",
      "1000/1000 - 44s - loss: 0.0667 - accuracy: 0.9788 - val_loss: 0.5620 - val_accuracy: 0.8799\n",
      "Epoch 75/100\n",
      "1000/1000 - 44s - loss: 0.0714 - accuracy: 0.9780 - val_loss: 0.4672 - val_accuracy: 0.8974\n",
      "Epoch 76/100\n",
      "1000/1000 - 44s - loss: 0.0688 - accuracy: 0.9786 - val_loss: 0.5787 - val_accuracy: 0.8717\n",
      "Epoch 77/100\n",
      "1000/1000 - 44s - loss: 0.0676 - accuracy: 0.9772 - val_loss: 0.5231 - val_accuracy: 0.8898\n",
      "Epoch 78/100\n",
      "1000/1000 - 44s - loss: 0.0639 - accuracy: 0.9793 - val_loss: 0.4308 - val_accuracy: 0.9029\n",
      "Epoch 79/100\n",
      "1000/1000 - 44s - loss: 0.0714 - accuracy: 0.9787 - val_loss: 0.5742 - val_accuracy: 0.8744\n",
      "Epoch 80/100\n",
      "1000/1000 - 44s - loss: 0.0691 - accuracy: 0.9776 - val_loss: 2.4471 - val_accuracy: 0.8643\n",
      "Epoch 81/100\n",
      "1000/1000 - 44s - loss: 0.0801 - accuracy: 0.9744 - val_loss: 1.7585 - val_accuracy: 0.8907\n",
      "Epoch 82/100\n",
      "1000/1000 - 44s - loss: 0.0836 - accuracy: 0.9747 - val_loss: 0.6000 - val_accuracy: 0.8773\n",
      "Epoch 83/100\n",
      "1000/1000 - 44s - loss: 0.0694 - accuracy: 0.9781 - val_loss: 0.4751 - val_accuracy: 0.9030\n",
      "Epoch 84/100\n",
      "1000/1000 - 44s - loss: 0.2096 - accuracy: 0.9469 - val_loss: 0.6633 - val_accuracy: 0.8702\n",
      "Epoch 85/100\n",
      "1000/1000 - 44s - loss: 0.1356 - accuracy: 0.9634 - val_loss: 1.6503 - val_accuracy: 0.8955\n",
      "Epoch 86/100\n",
      "1000/1000 - 44s - loss: 0.0983 - accuracy: 0.9721 - val_loss: 2.6348 - val_accuracy: 0.8761\n",
      "Epoch 87/100\n",
      "1000/1000 - 44s - loss: 0.0776 - accuracy: 0.9772 - val_loss: 1.3145 - val_accuracy: 0.8947\n",
      "Epoch 88/100\n",
      "1000/1000 - 44s - loss: 0.0700 - accuracy: 0.9780 - val_loss: 9.7213 - val_accuracy: 0.8731\n",
      "Epoch 89/100\n",
      "1000/1000 - 44s - loss: 0.0593 - accuracy: 0.9809 - val_loss: 0.6019 - val_accuracy: 0.8826\n",
      "Epoch 90/100\n",
      "1000/1000 - 44s - loss: 0.0909 - accuracy: 0.9732 - val_loss: 0.5155 - val_accuracy: 0.8901\n",
      "Epoch 91/100\n",
      "1000/1000 - 44s - loss: 0.0642 - accuracy: 0.9798 - val_loss: 0.9600 - val_accuracy: 0.8953\n",
      "Epoch 92/100\n",
      "1000/1000 - 44s - loss: 0.0606 - accuracy: 0.9800 - val_loss: 0.5368 - val_accuracy: 0.8996\n",
      "Epoch 93/100\n",
      "1000/1000 - 44s - loss: 0.0638 - accuracy: 0.9797 - val_loss: 0.4365 - val_accuracy: 0.9091\n",
      "Epoch 94/100\n",
      "1000/1000 - 44s - loss: 0.0775 - accuracy: 0.9773 - val_loss: 1.0700 - val_accuracy: 0.8878\n",
      "Epoch 95/100\n",
      "1000/1000 - 44s - loss: 0.0557 - accuracy: 0.9811 - val_loss: 1.6005 - val_accuracy: 0.8866\n",
      "Epoch 96/100\n",
      "1000/1000 - 44s - loss: 0.0584 - accuracy: 0.9803 - val_loss: 0.4631 - val_accuracy: 0.9039\n",
      "Epoch 97/100\n",
      "1000/1000 - 44s - loss: 0.0710 - accuracy: 0.9786 - val_loss: 0.4545 - val_accuracy: 0.9093\n",
      "Epoch 98/100\n",
      "1000/1000 - 44s - loss: 0.0703 - accuracy: 0.9776 - val_loss: 1.1549 - val_accuracy: 0.8917\n",
      "Epoch 99/100\n",
      "1000/1000 - 44s - loss: 0.0560 - accuracy: 0.9807 - val_loss: 3.9878 - val_accuracy: 0.8608\n",
      "Epoch 100/100\n",
      "1000/1000 - 44s - loss: 0.0573 - accuracy: 0.9814 - val_loss: 2.5015 - val_accuracy: 0.8799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4e61cc01d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from models import VGG16Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data loading\n",
    "X_train = pd.read_pickle('/content/drive/My Drive/train.pkl')[..., np.newaxis]\n",
    "y_train = pd.read_csv('/content/drive/My Drive/train_y.csv', index_col=0)\n",
    "X_test = pd.read_pickle('/content/drive/My Drive/test.pkl')[..., np.newaxis]\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,  # mudei aqui antes era 30\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2)\n",
    "    #featurewise_center=True) # acc val lixo \n",
    "    #featurewise_std_normalization=True) #acc val lixo\n",
    "    #zca_whitening=True)#, !!!! esse parametro sobrepoe o featurewise_std_normalization\n",
    "    #width_shift_range=0.2, \n",
    "    #height_shift_range=0.2,\n",
    "    #horizontal_flip=True, \n",
    "    #vertical_flip=True) \n",
    "'''\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "datagen = ImageDataGenerator(rotation_range=90)\n",
    "\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n",
    "datagen.fit(X_test)\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "# Training and validation split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "#sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy']) #estava usando esse o ADAM\n",
    "#model.compile(optimizer=SGD(learning_rate=0.005, momentum=0.8, decay=0.00003125), loss='categorical_crossentropy', metrics=['accuracy'])#agora vous usar SG Vincent\n",
    "\n",
    "\n",
    "# Model training\n",
    "#model = VGG16Model()\n",
    "callback = EarlyStopping(monitor='val_accuracy', patience=50, verbose=1)\n",
    "model.fit(datagen.flow(X_train, y_train),batch_size=64, validation_data=(X_valid, y_valid), epochs=100, callbacks=[callback], verbose=2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sYUye_8h2Tx"
   },
   "outputs": [],
   "source": [
    "# Model testing\n",
    "predictions = pd.DataFrame(np.argmax(model.predict(X_test), axis=1), columns=['label'])\n",
    "predictions.index.name = 'id'\n",
    "predictions.to_csv('/content/drive/My Drive/results_resnet_keras_original_bs_externo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crtU6f4cMRLJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ResNet-Keras",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
